{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate DQN model from Deepmind Atari paper\n",
    "\n",
    "References:   \n",
    "Paper: https://arxiv.org/pdf/1312.5602.pdf    \n",
    "Pytorch tutorial: https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant packages\n",
    "import torch\n",
    "from collections import namedtuple, deque\n",
    "import random\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "import gym\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience Replay   \n",
    "Data structure to store past experiences and sample some examples for training, the idea is to ***\"alleviate the problems of correlated data and non-stationary distributions\"***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use named tuple to represent Experience referred in paper\n",
    "Experience = namedtuple('Experience', [\"state\", \"action\", \"reward\", \"successor\", \"done\"])\n",
    "\n",
    "class ReplayMemory():\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "        \n",
    "    def push(self, *args):\n",
    "        \"\"\"add new experience\"\"\"\n",
    "        self.memory.append(Experience(*args))\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"randomly sample experiences from Replay Memory\"\"\"\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Override default len() method\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model  \n",
    "Build model based on the paper's description \n",
    "> The input to the neural network consists is an 84 × 84 × 4 image produced by φ. The first hidden layer convolves **16 8 × 8 filters with stride 4** with the input image and applies a **rectifier nonlinearity**. The second hidden layer convolves **32 4 × 4 filters with stride 2**, again followed by a **rectifier nonlinearity**. The final hidden layer is fully-connected and consists of **256 rectifier units**. The output layer is a fully- connected linear layer with a **single output for each valid action**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_model(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DQN_model, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(input_shape[0], 16, kernel_size=(8,8), stride=4)\n",
    "        self.layer2 = nn.Conv2d(16, 32, (4,4), stride=2)\n",
    "        # output shape after EACH convo would be ((dimension - filter size)/stride +1) **2 (for 2 sides)\n",
    "                                                                            # * 4 (stack) * output_channel\n",
    "        dim_size = (((84-8)/4 + 1)-4)/2+1\n",
    "        self.layer3 = nn.Linear(int((dim_size)**2 * 32), 256)\n",
    "        self.output = nn.Linear(256, n_actions) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare environment   \n",
    "The paper specifies several preprocessing steps to apply to the raw frames\n",
    ">210 × 160 pixel images with a 128 color palette, can be computationally demanding, so we apply a basic preprocessing step aimed at reducing the input dimensionality. The raw frames are preprocessed by first converting their RGB representation to **gray-scale** and **down-sampling it to a 110×84 image**. The final input representation is obtained by cropping an 84 × 84 region of the image that roughly captures the playing area.\n",
    "\n",
    "Using gym, we can apply **GrayScaleObservation** wrapper to get gray-scale representation, and instead of cropping to game play section, a **resize wrapper** is applied\n",
    "\n",
    "<br>\n",
    "\n",
    "> For the experiments in this paper, the function φ from algorithm 1 applies this preprocessing to the **last 4 frames of a history and stacks them** to produce the input to the Q-function.\n",
    "\n",
    "For this, we can apply **FrameStack** wrapper to get a stacks of 4 frames\n",
    "\n",
    "<br>\n",
    "\n",
    "> Since the scale of scores varies greatly from game to game, we fixed all positive rewards to be 1 and all negative rewards to be −1, leaving 0 rewards unchanged.\n",
    "\n",
    "\n",
    "Lastly, we can apply **ClipReward** wrapper to crop reward to specified range\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation shape:  (4, 84, 84)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.4+069f8bd)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gym.wrappers import GrayScaleObservation, ResizeObservation, FrameStack\n",
    "from gym.utils.env_checker import check_env\n",
    "\n",
    "# Wrapper to clip reward, taken from documentation\n",
    "class ClipReward(gym.RewardWrapper):\n",
    "    def __init__(self, env, min_reward, max_reward):\n",
    "        super().__init__(env)\n",
    "        self.min_reward = min_reward\n",
    "        self.max_reward = max_reward\n",
    "        self.reward_range = (min_reward, max_reward)\n",
    "    \n",
    "    def reward(self, reward):\n",
    "        return np.clip(reward, self.min_reward, self.max_reward)\n",
    "    \n",
    "# observation wrapper for cropping\n",
    "class AtariCropping(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"A gym wrapper that crops, scales image into the desired shapes and optionally grayscales it.\"\"\"\n",
    "        super().__init__(env)\n",
    "        \n",
    "        old_shape = env.observation_space.shape\n",
    "        # get new shape after cropping\n",
    "        new_shape = (old_shape[0]-50,) + old_shape[1:]\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=new_shape)\n",
    "\n",
    "    def observation(self, img):\n",
    "        \"\"\"what happens to each observation\"\"\"\n",
    "        # crop image (top and bottom, top from 34, bottom remove last 16)\n",
    "        img = img[34:-16, :, :]\n",
    "              \n",
    "        return img\n",
    "\n",
    "def generate_env(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    env = ClipReward(env, -1, 1)\n",
    "    env = AtariCropping(env)\n",
    "    # gray scale frame\n",
    "    env = GrayScaleObservation(env, keep_dim=False)\n",
    "    # resize frame to 84×84 image\n",
    "    env = ResizeObservation(env, (84, 84))\n",
    "    # stack 4 frames (equivalent to what phi does in paper) \n",
    "    env = FrameStack(env, num_stack=4)\n",
    "    \n",
    "    return env\n",
    "    \n",
    "env = generate_env(\"Breakout-v4\")\n",
    "env.reset()\n",
    "observation, reward, done, _ = env.step(env.action_space.sample())\n",
    "print(\"Observation shape: \", env.observation_space.shape)\n",
    "\n",
    "# visualize frames in each step \n",
    "_, axs = plt.subplots(1, 4, figsize=(10,10))\n",
    "for i, image in enumerate(observation):\n",
    "    axs[i].imshow(image, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to determine action\n",
    "Apply $\\epsilon$ greedy algorithm to choose action   \n",
    "* Choose random action at probability $\\epsilon$\n",
    "* Choose optimal action (determined by model) at probability (1-$\\epsilon$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def choose_action(model, state, device, epsilon=0.1):\n",
    "    if random.random()<=epsilon: #exploration\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "#         squeeze to remove last dim of 1 (for gray scaled val) and add 1 dim at first (1 input instead of batch)\n",
    "        state = torch.Tensor(state).squeeze().unsqueeze(0).to(device)\n",
    "        # predict\n",
    "        pred = model(state)\n",
    "        return int(torch.argmax(pred.squeeze()).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function  \n",
    "As mentioned in the paper, the function to optimize would be the following\n",
    "> $$L_i(θ_i) = E_{s,a∼ρ(·)} [(y_i − Q (s, a; θ_i))]^2 $$\n",
    "> where: $$y_i = E_{s′∼\\mathcal{E}} [r + γ max_{a′} Q(s′, a′; θ_{i−1})|s, a]$$\n",
    "\n",
    "Notation translation:\n",
    "- θ refers to weights of model, $θ_i$ refers to model (with weights) at iteration i\n",
    "- $Q (s, a; θ_i)$ (prediction) is Q value at (s, a) estimated by model\n",
    "- $y_i$ (target function) is calculated using Bellman equation, but future reward (aka Q(s', a')) is (again) estimated by the model\n",
    "\n",
    "Code translation:\n",
    "- $Q (s, a; θ_i)$ is calculated by plug in state for model to predict, and get the output at action a (state and action sampled from experience replay)\n",
    "- $max_{a′} Q(s′, a′; θ_{i−1}$ in $y_i$ is calculated by plug in successor state, then get the max output out of all actions\n",
    "- loss is square root of $y_i$ (expected Q) - $Q (s, a; θ_i)$ (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, replay_memory, batch_size, discount, target_model=None, device=\"mps\"):\n",
    "    batch = replay_memory.sample(batch_size)\n",
    "\n",
    "#     Transpose batch, ref: https://stackoverflow.com/questions/19339/transpose-unzip-function-inverse-of-zip/19343#19343\n",
    "    batch = Experience(*zip(*batch))\n",
    "    \n",
    "#     convert to a single np.array for faster tensor conversion\n",
    "    state = np.array(batch.state)\n",
    "    successor = np.array(batch.successor)\n",
    "            \n",
    "    # Tensor-ify state, action, reward, successor, done (use torch tensor to have grad)\n",
    "    state = torch.Tensor(state).squeeze().div_(255).to(device)\n",
    "    action = torch.Tensor(batch.action).to(device)\n",
    "    reward = torch.Tensor(batch.reward).to(device)\n",
    "    successor = torch.Tensor(successor).squeeze().to(device)\n",
    "    done = torch.tensor(batch.done, dtype=torch.int32).to(device)\n",
    "\n",
    "    # use model to get old qs and successor qs\n",
    "    old_qs = model(state)\n",
    "    # if target model is provided -> use that to compute successor instead\n",
    "    successor_qs = model(successor) if target_model is None else target_model(successor) \n",
    "    \n",
    "#   check for exploding/diminissing problem\n",
    "#     print(torch.isnan(old_qs).any())\n",
    "        \n",
    "    # get the list of actions in shape 1xbatch_size, and use it as indices for old_qs\n",
    "    action = action.unsqueeze(1).type(torch.int64)\n",
    "    # get predicted qs at action, return tensor of list of batch_size items\n",
    "    old_qs = old_qs.gather(1, action).squeeze()\n",
    "    # get max q in successor to estimate future reward\n",
    "    successor_qs = successor_qs.max(1)[0]\n",
    "            \n",
    "    # compute expected qs\n",
    "    # multiplying (1-done) would result in not adding future reward when at end state (done==1)\n",
    "    expected_qs = reward + successor_qs*discount*(1-done)\n",
    "        \n",
    "    # compute loss, return mean loss of batch \n",
    "    loss = (expected_qs - old_qs).pow(2).mean()\n",
    "    \n",
    "#     print(\"Old Qs \", old_qs)\n",
    "#     print(\"Expected Qs \", expected_qs)\n",
    "#     print(\"Loss \", loss.item())\n",
    "    \n",
    "    \n",
    "    # improvement for stability - use different loss \n",
    "    # loss_func = nn.HuberLoss()\n",
    "    # loss = loss_func(old_qs, expected_qs)\n",
    "    \n",
    "    # return predicted qs for visualization\n",
    "    return loss, old_qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = \"BreakoutDeterministic-v4\"\n",
    "LEARNING_RATE = 0.00001 if ENV == \"BreakoutDeterministic-v4\" else 0.00025\n",
    "REPLAY_LEN = 1000000\n",
    "BATCH_SIZE = 32\n",
    "EPISODES = 16000\n",
    "DISCOUNT = 0.99 #aka gamma in Bellman's equation\n",
    "SAVE_FREQ = 50 #number of episodes in-between saves\n",
    "START_EPSILON= 1\n",
    "END_EPSILON= 0.1\n",
    "DECAY_FRAMES=1000000\n",
    "USE_TARGET_MODEL=False # whether to have target model or not\n",
    "UPDATE_TARGET=1000 #frames to run before updating the target model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up variables before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Current Atari environment: BreakoutDeterministic-v4\n",
      "Initial length of replay memory: 32\n"
     ]
    }
   ],
   "source": [
    "# check for mps, cuda or cpu\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "model = DQN_model(env.observation_space.shape, env.action_space.n).to(device)\n",
    "target_model = None\n",
    "if USE_TARGET_MODEL:\n",
    "    target_model = DQN_model(env.observation_space.shape, env.action_space.n).to(device)\n",
    "    target_model.load_state_dict(model.state_dict())\n",
    "\n",
    "# optimizer based on paper\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# optimizer for first training (not-so-happy accident =)))\n",
    "# optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# recommended (less computational heavy compared to RMSprop)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "# array to store info per episodes\n",
    "episodes = []\n",
    "losses = []\n",
    "rewards = []\n",
    "pred_qs = []\n",
    "\n",
    "# count to keep track of episodes and frames (for epsilon decay)\n",
    "count = 0\n",
    "frames = 0\n",
    "\n",
    "# build env\n",
    "env = generate_env(ENV)\n",
    "print(f\"Current Atari environment: {ENV}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "\n",
    "# Initialize replay memory with len of replay buffer\n",
    "curr_state = env.reset()\n",
    "curr_state = np.asarray(curr_state) #convert to np array\n",
    "replay_memory = ReplayMemory(capacity=REPLAY_LEN)\n",
    "for i in range(BATCH_SIZE):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, _ = env.step(action)\n",
    "    \n",
    "    observation = np.asarray(observation) #convert to np array\n",
    "    replay_memory.push(curr_state, action, reward, observation, done)\n",
    "    \n",
    "    # update curr state\n",
    "    curr_state = observation\n",
    "    \n",
    "print(f\"Initial length of replay memory: {len(replay_memory)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:0 Action 1 Loss: 6.07483 Reward: 0.0 Epsilon: 1.0\n",
      "Done with episode 1 in 157 frames\n",
      "Loss: 6.074832916259766 Episode total reward: 1.0 Predicted Qs: 0.03268670290708542\n",
      "Actions chosen counts:  {0: 39, 1: 36, 2: 42, 3: 40}\n",
      "----------------\n",
      "Frame:200 Action 1 Loss: 0.00252 Reward: 0.0 Epsilon: 0.99982\n",
      "Done with episode 2 in 290 frames\n",
      "Loss: 0.024869341403245926 Episode total reward: 0.0 Predicted Qs: 0.02806287631392479\n",
      "Actions chosen counts:  {0: 27, 1: 38, 2: 42, 3: 26}\n",
      "----------------\n",
      "Frame:400 Action 0 Loss: 0.00188 Reward: 0.0 Epsilon: 0.9996400000000001\n",
      "Done with episode 3 in 457 frames\n",
      "Loss: 0.023097427561879158 Episode total reward: 1.0 Predicted Qs: 0.02695380710065365\n",
      "Actions chosen counts:  {0: 40, 1: 48, 2: 36, 3: 43}\n",
      "----------------\n",
      "Done with episode 4 in 596 frames\n",
      "Loss: 0.02277669683098793 Episode total reward: 0.0 Predicted Qs: 0.02432878315448761\n",
      "Actions chosen counts:  {0: 34, 1: 38, 2: 34, 3: 33}\n",
      "----------------\n",
      "Frame:600 Action 1 Loss: 0.00138 Reward: 0.0 Epsilon: 0.9994599999999999\n",
      "Frame:800 Action 0 Loss: 0.00205 Reward: 0.0 Epsilon: 0.99928\n",
      "Done with episode 5 in 829 frames\n",
      "Loss: 0.04298224300146103 Episode total reward: 2.0 Predicted Qs: 0.024237725883722305\n",
      "Actions chosen counts:  {0: 69, 1: 56, 2: 47, 3: 61}\n",
      "----------------\n",
      "Frame:1000 Action 1 Loss: 0.00111 Reward: 0.0 Epsilon: 0.9991\n",
      "Done with episode 6 in 1023 frames\n",
      "Loss: 0.03286154568195343 Episode total reward: 2.0 Predicted Qs: 0.02395189180970192\n",
      "Actions chosen counts:  {0: 49, 1: 51, 2: 40, 3: 54}\n",
      "----------------\n",
      "Frame:1200 Action 1 Loss: 0.00767 Reward: 0.0 Epsilon: 0.99892\n",
      "Done with episode 7 in 1212 frames\n",
      "Loss: 0.04424964636564255 Episode total reward: 1.0 Predicted Qs: 0.023664791136980057\n",
      "Actions chosen counts:  {0: 47, 1: 49, 2: 50, 3: 43}\n",
      "----------------\n",
      "Frame:1400 Action 3 Loss: 0.00121 Reward: 0.0 Epsilon: 0.9987400000000001\n",
      "Done with episode 8 in 1440 frames\n",
      "Loss: 0.039214782416820526 Episode total reward: 3.0 Predicted Qs: 0.023454420268535614\n",
      "Actions chosen counts:  {0: 64, 1: 56, 2: 63, 3: 45}\n",
      "----------------\n",
      "Done with episode 9 in 1564 frames\n",
      "Loss: 0.057165853679180145 Episode total reward: 0.0 Predicted Qs: 0.02338382974267006\n",
      "Actions chosen counts:  {0: 25, 1: 31, 2: 32, 3: 36}\n",
      "----------------\n",
      "Frame:1600 Action 0 Loss: 0.00262 Reward: 0.0 Epsilon: 0.99856\n",
      "Done with episode 10 in 1771 frames\n",
      "Loss: 0.02977798506617546 Episode total reward: 2.0 Predicted Qs: 0.022771816700696945\n",
      "Actions chosen counts:  {0: 60, 1: 54, 2: 55, 3: 38}\n",
      "----------------\n",
      "Frame:1800 Action 0 Loss: 0.00452 Reward: 0.0 Epsilon: 0.9983799999999999\n",
      "Done with episode 11 in 1901 frames\n",
      "Loss: 0.047845955938100815 Episode total reward: 0.0 Predicted Qs: 0.023079022765159607\n",
      "Actions chosen counts:  {0: 29, 1: 32, 2: 38, 3: 31}\n",
      "----------------\n",
      "Frame:2000 Action 0 Loss: 0.00155 Reward: 0.0 Epsilon: 0.9982\n",
      "Done with episode 12 in 2067 frames\n",
      "Loss: 0.040946535766124725 Episode total reward: 1.0 Predicted Qs: 0.023125948384404182\n",
      "Actions chosen counts:  {0: 45, 1: 30, 2: 47, 3: 44}\n",
      "----------------\n",
      "Frame:2200 Action 3 Loss: 0.01722 Reward: 0.0 Epsilon: 0.99802\n",
      "Done with episode 13 in 2284 frames\n",
      "Loss: 0.0346759632229805 Episode total reward: 2.0 Predicted Qs: 0.022123027592897415\n",
      "Actions chosen counts:  {0: 59, 1: 51, 2: 63, 3: 44}\n",
      "----------------\n",
      "Frame:2400 Action 3 Loss: 0.00028 Reward: 0.0 Epsilon: 0.9978400000000001\n",
      "Done with episode 14 in 2460 frames\n",
      "Loss: 0.0348329171538353 Episode total reward: 1.0 Predicted Qs: 0.021959614008665085\n",
      "Actions chosen counts:  {0: 46, 1: 47, 2: 49, 3: 34}\n",
      "----------------\n",
      "Frame:2600 Action 1 Loss: 0.00142 Reward: 0.0 Epsilon: 0.99766\n",
      "Done with episode 15 in 2625 frames\n",
      "Loss: 0.017101066187024117 Episode total reward: 1.0 Predicted Qs: 0.02143791876733303\n",
      "Actions chosen counts:  {0: 39, 1: 36, 2: 45, 3: 45}\n",
      "----------------\n",
      "Done with episode 16 in 2769 frames\n",
      "Loss: 0.026928165927529335 Episode total reward: 0.0 Predicted Qs: 0.021091151982545853\n",
      "Actions chosen counts:  {0: 37, 1: 42, 2: 28, 3: 37}\n",
      "----------------\n",
      "Frame:2800 Action 0 Loss: 0.00332 Reward: 0.0 Epsilon: 0.9974799999999999\n",
      "Done with episode 17 in 2914 frames\n",
      "Loss: 0.03016434796154499 Episode total reward: 0.0 Predicted Qs: 0.021184973418712616\n",
      "Actions chosen counts:  {0: 43, 1: 34, 2: 35, 3: 33}\n",
      "----------------\n",
      "Frame:3000 Action 2 Loss: 0.00123 Reward: 0.0 Epsilon: 0.9973\n",
      "Done with episode 18 in 3090 frames\n",
      "Loss: 0.02186127007007599 Episode total reward: 1.0 Predicted Qs: 0.0212046280503273\n",
      "Actions chosen counts:  {0: 39, 1: 57, 2: 39, 3: 41}\n",
      "----------------\n",
      "Frame:3200 Action 1 Loss: 0.0004 Reward: 0.0 Epsilon: 0.99712\n",
      "Done with episode 19 in 3351 frames\n",
      "Loss: 0.025844112038612366 Episode total reward: 3.0 Predicted Qs: 0.0211240965873003\n",
      "Actions chosen counts:  {0: 52, 1: 77, 2: 69, 3: 63}\n",
      "----------------\n",
      "Frame:3400 Action 1 Loss: 0.00201 Reward: 0.0 Epsilon: 0.99694\n",
      "Done with episode 20 in 3510 frames\n",
      "Loss: 0.024885451421141624 Episode total reward: 1.0 Predicted Qs: 0.020805083215236664\n",
      "Actions chosen counts:  {0: 42, 1: 42, 2: 34, 3: 41}\n",
      "----------------\n",
      "Frame:3600 Action 0 Loss: 0.00027 Reward: 0.0 Epsilon: 0.99676\n",
      "Done with episode 21 in 3648 frames\n",
      "Loss: 0.022419704124331474 Episode total reward: 0.0 Predicted Qs: 0.020676055923104286\n",
      "Actions chosen counts:  {0: 31, 1: 34, 2: 42, 3: 31}\n",
      "----------------\n",
      "Frame:3800 Action 3 Loss: 0.00185 Reward: 0.0 Epsilon: 0.99658\n",
      "Done with episode 22 in 3832 frames\n",
      "Loss: 0.023608218878507614 Episode total reward: 1.0 Predicted Qs: 0.02072443626821041\n",
      "Actions chosen counts:  {0: 45, 1: 51, 2: 48, 3: 40}\n",
      "----------------\n",
      "Frame:4000 Action 3 Loss: 0.00261 Reward: 0.0 Epsilon: 0.9964\n",
      "Done with episode 23 in 4011 frames\n",
      "Loss: 0.022797714918851852 Episode total reward: 1.0 Predicted Qs: 0.02060937136411667\n",
      "Actions chosen counts:  {0: 41, 1: 48, 2: 43, 3: 47}\n",
      "----------------\n",
      "Done with episode 24 in 4186 frames\n",
      "Loss: 0.01003403402864933 Episode total reward: 1.0 Predicted Qs: 0.020530927926301956\n",
      "Actions chosen counts:  {0: 49, 1: 51, 2: 32, 3: 43}\n",
      "----------------\n",
      "Frame:4200 Action 3 Loss: 0.00048 Reward: 0.0 Epsilon: 0.99622\n",
      "Done with episode 25 in 4316 frames\n",
      "Loss: 0.01545264944434166 Episode total reward: 0.0 Predicted Qs: 0.020681055262684822\n",
      "Actions chosen counts:  {0: 40, 1: 31, 2: 30, 3: 29}\n",
      "----------------\n",
      "Frame:4400 Action 0 Loss: 0.00069 Reward: 0.0 Epsilon: 0.99604\n",
      "Done with episode 26 in 4523 frames\n",
      "Loss: 0.02335500903427601 Episode total reward: 2.0 Predicted Qs: 0.020602580159902573\n",
      "Actions chosen counts:  {0: 57, 1: 52, 2: 55, 3: 43}\n",
      "----------------\n",
      "Frame:4600 Action 0 Loss: 0.00415 Reward: 0.0 Epsilon: 0.99586\n",
      "Done with episode 27 in 4653 frames\n",
      "Loss: 0.02257535420358181 Episode total reward: 0.0 Predicted Qs: 0.020654086023569107\n",
      "Actions chosen counts:  {0: 31, 1: 27, 2: 34, 3: 38}\n",
      "----------------\n",
      "Frame:4800 Action 1 Loss: 0.0009 Reward: 0.0 Epsilon: 0.99568\n",
      "Done with episode 28 in 4829 frames\n",
      "Loss: 0.010366905480623245 Episode total reward: 1.0 Predicted Qs: 0.021219495683908463\n",
      "Actions chosen counts:  {0: 41, 1: 43, 2: 48, 3: 44}\n",
      "----------------\n",
      "Frame:5000 Action 1 Loss: 0.00032 Reward: 0.0 Epsilon: 0.9954999999999999\n",
      "Done with episode 29 in 5101 frames\n",
      "Loss: 0.021609757095575333 Episode total reward: 4.0 Predicted Qs: 0.019898179918527603\n",
      "Actions chosen counts:  {0: 65, 1: 65, 2: 80, 3: 62}\n",
      "----------------\n",
      "Frame:5200 Action 3 Loss: 0.00011 Reward: 0.0 Epsilon: 0.99532\n",
      "Done with episode 30 in 5253 frames\n",
      "Loss: 0.011210438795387745 Episode total reward: 0.0 Predicted Qs: 0.01923927292227745\n",
      "Actions chosen counts:  {0: 35, 1: 34, 2: 45, 3: 38}\n",
      "----------------\n",
      "Frame:5400 Action 1 Loss: 0.00893 Reward: 0.0 Epsilon: 0.99514\n",
      "Done with episode 31 in 5432 frames\n",
      "Loss: 0.02085031569004059 Episode total reward: 1.0 Predicted Qs: 0.01905687525868416\n",
      "Actions chosen counts:  {0: 42, 1: 50, 2: 42, 3: 45}\n",
      "----------------\n",
      "Done with episode 32 in 5558 frames\n",
      "Loss: 0.019323909655213356 Episode total reward: 0.0 Predicted Qs: 0.018681153655052185\n",
      "Actions chosen counts:  {0: 37, 1: 34, 2: 27, 3: 28}\n",
      "----------------\n",
      "Frame:5600 Action 3 Loss: 0.00018 Reward: 0.0 Epsilon: 0.99496\n",
      "Done with episode 33 in 5687 frames\n",
      "Loss: 0.008359480649232864 Episode total reward: 0.0 Predicted Qs: 0.01870114728808403\n",
      "Actions chosen counts:  {0: 37, 1: 25, 2: 26, 3: 41}\n",
      "----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:5800 Action 1 Loss: 0.00056 Reward: 1.0 Epsilon: 0.99478\n",
      "Done with episode 34 in 5949 frames\n",
      "Loss: 0.021790003404021263 Episode total reward: 4.0 Predicted Qs: 0.018381809815764427\n",
      "Actions chosen counts:  {0: 72, 1: 70, 2: 51, 3: 69}\n",
      "----------------\n",
      "Frame:6000 Action 2 Loss: 0.00017 Reward: 0.0 Epsilon: 0.9946\n",
      "Done with episode 35 in 6080 frames\n",
      "Loss: 0.020063668489456177 Episode total reward: 0.0 Predicted Qs: 0.018410246819257736\n",
      "Actions chosen counts:  {0: 36, 1: 30, 2: 31, 3: 34}\n",
      "----------------\n",
      "Frame:6200 Action 0 Loss: 0.0004 Reward: 0.0 Epsilon: 0.99442\n",
      "Done with episode 36 in 6214 frames\n",
      "Loss: 0.012042298913002014 Episode total reward: 0.0 Predicted Qs: 0.018457459285855293\n",
      "Actions chosen counts:  {0: 36, 1: 36, 2: 29, 3: 33}\n",
      "----------------\n",
      "Done with episode 37 in 6356 frames\n",
      "Loss: 0.019993865862488747 Episode total reward: 0.0 Predicted Qs: 0.018466170877218246\n",
      "Actions chosen counts:  {0: 37, 1: 35, 2: 35, 3: 35}\n",
      "----------------\n",
      "Frame:6400 Action 3 Loss: 0.00038 Reward: 0.0 Epsilon: 0.99424\n",
      "Done with episode 38 in 6487 frames\n",
      "Loss: 0.01769295334815979 Episode total reward: 0.0 Predicted Qs: 0.017978481948375702\n",
      "Actions chosen counts:  {0: 31, 1: 28, 2: 30, 3: 42}\n",
      "----------------\n",
      "Frame:6600 Action 0 Loss: 0.00041 Reward: 0.0 Epsilon: 0.9940599999999999\n",
      "Done with episode 39 in 6625 frames\n",
      "Loss: 0.01586296781897545 Episode total reward: 0.0 Predicted Qs: 0.017881184816360474\n",
      "Actions chosen counts:  {0: 37, 1: 28, 2: 34, 3: 39}\n",
      "----------------\n",
      "Frame:6800 Action 0 Loss: 0.00017 Reward: 0.0 Epsilon: 0.99388\n",
      "Done with episode 40 in 6807 frames\n",
      "Loss: 0.023003458976745605 Episode total reward: 1.0 Predicted Qs: 0.017414849251508713\n",
      "Actions chosen counts:  {0: 47, 1: 51, 2: 45, 3: 39}\n",
      "----------------\n",
      "Frame:7000 Action 1 Loss: 0.00028 Reward: 0.0 Epsilon: 0.9937\n",
      "Done with episode 41 in 7085 frames\n",
      "Loss: 0.019603652879595757 Episode total reward: 4.0 Predicted Qs: 0.017957910895347595\n",
      "Actions chosen counts:  {0: 77, 1: 76, 2: 61, 3: 64}\n",
      "----------------\n",
      "Frame:7200 Action 2 Loss: 0.00079 Reward: 0.0 Epsilon: 0.99352\n",
      "Done with episode 42 in 7223 frames\n",
      "Loss: 0.021098444238305092 Episode total reward: 0.0 Predicted Qs: 0.017543647438287735\n",
      "Actions chosen counts:  {0: 43, 1: 36, 2: 34, 3: 25}\n",
      "----------------\n",
      "Done with episode 43 in 7354 frames\n",
      "Loss: 0.01608051173388958 Episode total reward: 0.0 Predicted Qs: 0.017076462507247925\n",
      "Actions chosen counts:  {0: 34, 1: 35, 2: 31, 3: 31}\n",
      "----------------\n",
      "Frame:7400 Action 0 Loss: 0.0003 Reward: 0.0 Epsilon: 0.99334\n",
      "Done with episode 44 in 7495 frames\n",
      "Loss: 0.014317663386464119 Episode total reward: 0.0 Predicted Qs: 0.016821537166833878\n",
      "Actions chosen counts:  {0: 36, 1: 32, 2: 33, 3: 40}\n",
      "----------------\n",
      "Frame:7600 Action 0 Loss: 0.00016 Reward: 0.0 Epsilon: 0.9931599999999999\n",
      "Done with episode 45 in 7630 frames\n",
      "Loss: 0.01921750046312809 Episode total reward: 0.0 Predicted Qs: 0.016764704138040543\n",
      "Actions chosen counts:  {0: 42, 1: 29, 2: 31, 3: 33}\n",
      "----------------\n",
      "Done with episode 46 in 7764 frames\n",
      "Loss: 0.016149304807186127 Episode total reward: 0.0 Predicted Qs: 0.0171552374958992\n",
      "Actions chosen counts:  {0: 42, 1: 30, 2: 33, 3: 29}\n",
      "----------------\n",
      "Frame:7800 Action 2 Loss: 0.0001 Reward: 0.0 Epsilon: 0.99298\n",
      "Done with episode 47 in 7898 frames\n",
      "Loss: 0.02959180437028408 Episode total reward: 0.0 Predicted Qs: 0.01624540612101555\n",
      "Actions chosen counts:  {0: 37, 1: 31, 2: 33, 3: 33}\n",
      "----------------\n",
      "Frame:8000 Action 3 Loss: 0.00033 Reward: 0.0 Epsilon: 0.9928\n",
      "Done with episode 48 in 8176 frames\n",
      "Loss: 0.033038124442100525 Episode total reward: 4.0 Predicted Qs: 0.016189761459827423\n",
      "Actions chosen counts:  {0: 91, 1: 63, 2: 59, 3: 65}\n",
      "----------------\n",
      "Frame:8200 Action 0 Loss: 0.00032 Reward: 0.0 Epsilon: 0.9926200000000001\n",
      "Done with episode 49 in 8393 frames\n",
      "Loss: 0.03145730867981911 Episode total reward: 2.0 Predicted Qs: 0.015672199428081512\n",
      "Actions chosen counts:  {0: 51, 1: 55, 2: 52, 3: 59}\n",
      "----------------\n",
      "Frame:8400 Action 2 Loss: 0.00022 Reward: 0.0 Epsilon: 0.99244\n",
      "Frame:8600 Action 1 Loss: 0.00267 Reward: 0.0 Epsilon: 0.9922599999999999\n",
      "Done with episode 50 in 8625 frames\n",
      "Loss: 0.02728809043765068 Episode total reward: 3.0 Predicted Qs: 0.016238180920481682\n",
      "Actions chosen counts:  {0: 60, 1: 65, 2: 53, 3: 54}\n",
      "----------------\n",
      "Done with episode 51 in 8774 frames\n",
      "Loss: 0.031733330339193344 Episode total reward: 0.0 Predicted Qs: 0.01603737287223339\n",
      "Actions chosen counts:  {0: 39, 1: 31, 2: 42, 3: 37}\n",
      "----------------\n",
      "Frame:8800 Action 0 Loss: 0.00034 Reward: 0.0 Epsilon: 0.99208\n",
      "Done with episode 52 in 8950 frames\n",
      "Loss: 0.026493825018405914 Episode total reward: 1.0 Predicted Qs: 0.015573331154882908\n",
      "Actions chosen counts:  {0: 43, 1: 37, 2: 47, 3: 49}\n",
      "----------------\n",
      "Frame:9000 Action 2 Loss: 0.00019 Reward: 0.0 Epsilon: 0.9919\n",
      "Frame:9200 Action 2 Loss: 0.00021 Reward: 0.0 Epsilon: 0.99172\n",
      "Done with episode 53 in 9254 frames\n",
      "Loss: 0.01932993158698082 Episode total reward: 4.0 Predicted Qs: 0.015326465480029583\n",
      "Actions chosen counts:  {0: 74, 1: 72, 2: 70, 3: 88}\n",
      "----------------\n",
      "Frame:9400 Action 0 Loss: 0.00072 Reward: 0.0 Epsilon: 0.99154\n",
      "Done with episode 54 in 9439 frames\n",
      "Loss: 0.02046111784875393 Episode total reward: 1.0 Predicted Qs: 0.014788070693612099\n",
      "Actions chosen counts:  {0: 49, 1: 45, 2: 45, 3: 46}\n",
      "----------------\n",
      "Frame:9600 Action 0 Loss: 0.00024 Reward: 0.0 Epsilon: 0.9913599999999999\n",
      "Done with episode 55 in 9605 frames\n",
      "Loss: 0.029452377930283546 Episode total reward: 1.0 Predicted Qs: 0.014957088977098465\n",
      "Actions chosen counts:  {0: 41, 1: 37, 2: 40, 3: 48}\n",
      "----------------\n",
      "Done with episode 56 in 9739 frames\n",
      "Loss: 0.022662576287984848 Episode total reward: 0.0 Predicted Qs: 0.014460643753409386\n",
      "Actions chosen counts:  {0: 31, 1: 35, 2: 34, 3: 34}\n",
      "----------------\n",
      "Frame:9800 Action 0 Loss: 0.02297 Reward: 0.0 Epsilon: 0.99118\n",
      "Done with episode 57 in 9898 frames\n",
      "Loss: 0.025541558861732483 Episode total reward: 1.0 Predicted Qs: 0.01441141590476036\n",
      "Actions chosen counts:  {0: 37, 1: 37, 2: 38, 3: 47}\n",
      "----------------\n",
      "Frame:10000 Action 3 Loss: 0.00019 Reward: 0.0 Epsilon: 0.991\n",
      "Done with episode 58 in 10079 frames\n",
      "Loss: 0.024398820474743843 Episode total reward: 1.0 Predicted Qs: 0.014636222273111343\n",
      "Actions chosen counts:  {0: 51, 1: 27, 2: 53, 3: 50}\n",
      "----------------\n",
      "Frame:10200 Action 3 Loss: 0.00026 Reward: 0.0 Epsilon: 0.99082\n",
      "Done with episode 59 in 10274 frames\n",
      "Loss: 0.018079709261655807 Episode total reward: 2.0 Predicted Qs: 0.01399858109652996\n",
      "Actions chosen counts:  {0: 64, 1: 36, 2: 42, 3: 53}\n",
      "----------------\n",
      "Frame:10400 Action 3 Loss: 0.00145 Reward: 0.0 Epsilon: 0.9906400000000001\n",
      "Done with episode 60 in 10450 frames\n",
      "Loss: 0.014646971598267555 Episode total reward: 1.0 Predicted Qs: 0.01361487340182066\n",
      "Actions chosen counts:  {0: 38, 1: 45, 2: 48, 3: 45}\n",
      "----------------\n",
      "Done with episode 61 in 10583 frames\n",
      "Loss: 0.02208678051829338 Episode total reward: 0.0 Predicted Qs: 0.013635638169944286\n",
      "Actions chosen counts:  {0: 33, 1: 35, 2: 36, 3: 29}\n",
      "----------------\n",
      "Frame:10600 Action 3 Loss: 0.00011 Reward: 0.0 Epsilon: 0.9904599999999999\n",
      "Frame:10800 Action 2 Loss: 0.00197 Reward: 0.0 Epsilon: 0.9902799999999999\n",
      "Done with episode 62 in 10803 frames\n",
      "Loss: 0.04105500131845474 Episode total reward: 2.0 Predicted Qs: 0.013537421822547913\n",
      "Actions chosen counts:  {0: 47, 1: 60, 2: 61, 3: 52}\n",
      "----------------\n",
      "Frame:11000 Action 1 Loss: 0.00033 Reward: 0.0 Epsilon: 0.9901\n",
      "Done with episode 63 in 11030 frames\n",
      "Loss: 0.02296418882906437 Episode total reward: 2.0 Predicted Qs: 0.014111271128058434\n",
      "Actions chosen counts:  {0: 59, 1: 53, 2: 58, 3: 57}\n",
      "----------------\n",
      "Frame:11200 Action 0 Loss: 4e-05 Reward: 0.0 Epsilon: 0.98992\n",
      "Done with episode 64 in 11259 frames\n",
      "Loss: 0.03646816685795784 Episode total reward: 2.0 Predicted Qs: 0.013541832566261292\n",
      "Actions chosen counts:  {0: 65, 1: 49, 2: 64, 3: 51}\n",
      "----------------\n",
      "Done with episode 65 in 11385 frames\n",
      "Loss: 0.03517882153391838 Episode total reward: 0.0 Predicted Qs: 0.01320415735244751\n",
      "Actions chosen counts:  {0: 35, 1: 29, 2: 32, 3: 30}\n",
      "----------------\n",
      "Frame:11400 Action 0 Loss: 0.00082 Reward: 0.0 Epsilon: 0.9897400000000001\n",
      "Done with episode 66 in 11541 frames\n",
      "Loss: 0.03062438778579235 Episode total reward: 1.0 Predicted Qs: 0.013320514000952244\n",
      "Actions chosen counts:  {0: 40, 1: 47, 2: 31, 3: 38}\n",
      "----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:11600 Action 1 Loss: 0.00114 Reward: 0.0 Epsilon: 0.98956\n",
      "Done with episode 67 in 11676 frames\n",
      "Loss: 0.021863127127289772 Episode total reward: 0.0 Predicted Qs: 0.01307135634124279\n",
      "Actions chosen counts:  {0: 44, 1: 26, 2: 32, 3: 33}\n",
      "----------------\n",
      "Frame:11800 Action 2 Loss: 0.0001 Reward: 0.0 Epsilon: 0.9893799999999999\n",
      "Done with episode 68 in 11895 frames\n",
      "Loss: 0.03534753620624542 Episode total reward: 2.0 Predicted Qs: 0.012772543355822563\n",
      "Actions chosen counts:  {0: 62, 1: 38, 2: 65, 3: 54}\n",
      "----------------\n",
      "Frame:12000 Action 3 Loss: 0.00134 Reward: 0.0 Epsilon: 0.9892\n",
      "Done with episode 69 in 12097 frames\n",
      "Loss: 0.030545473098754883 Episode total reward: 1.0 Predicted Qs: 0.013208867982029915\n",
      "Actions chosen counts:  {0: 39, 1: 46, 2: 59, 3: 58}\n",
      "----------------\n",
      "Frame:12200 Action 2 Loss: 0.00016 Reward: 0.0 Epsilon: 0.98902\n",
      "Done with episode 70 in 12281 frames\n",
      "Loss: 0.02657843753695488 Episode total reward: 1.0 Predicted Qs: 0.01274874433875084\n",
      "Actions chosen counts:  {0: 46, 1: 35, 2: 48, 3: 55}\n",
      "----------------\n",
      "Frame:12400 Action 3 Loss: 0.00016 Reward: 0.0 Epsilon: 0.98884\n",
      "Done with episode 71 in 12441 frames\n",
      "Loss: 0.020012106746435165 Episode total reward: 0.0 Predicted Qs: 0.01233216468244791\n",
      "Actions chosen counts:  {0: 46, 1: 33, 2: 42, 3: 39}\n",
      "----------------\n",
      "Frame:12600 Action 0 Loss: 0.00013 Reward: 0.0 Epsilon: 0.9886600000000001\n",
      "Done with episode 72 in 12618 frames\n",
      "Loss: 0.017783718183636665 Episode total reward: 1.0 Predicted Qs: 0.012484685517847538\n",
      "Actions chosen counts:  {0: 56, 1: 39, 2: 40, 3: 42}\n",
      "----------------\n",
      "Frame:12800 Action 2 Loss: 0.00014 Reward: 0.0 Epsilon: 0.9884799999999999\n",
      "Done with episode 73 in 12817 frames\n",
      "Loss: 0.01690666191279888 Episode total reward: 2.0 Predicted Qs: 0.012406646274030209\n",
      "Actions chosen counts:  {0: 50, 1: 62, 2: 42, 3: 45}\n",
      "----------------\n",
      "Frame:13000 Action 1 Loss: 0.00013 Reward: 0.0 Epsilon: 0.9883\n",
      "Done with episode 74 in 13026 frames\n",
      "Loss: 0.025650544092059135 Episode total reward: 2.0 Predicted Qs: 0.012041879817843437\n",
      "Actions chosen counts:  {0: 55, 1: 59, 2: 54, 3: 41}\n",
      "----------------\n",
      "Done with episode 75 in 13180 frames\n",
      "Loss: 0.013466070406138897 Episode total reward: 0.0 Predicted Qs: 0.011849921196699142\n",
      "Actions chosen counts:  {0: 41, 1: 27, 2: 44, 3: 42}\n",
      "----------------\n",
      "Frame:13200 Action 3 Loss: 6e-05 Reward: 0.0 Epsilon: 0.98812\n",
      "Done with episode 76 in 13370 frames\n",
      "Loss: 0.024130558595061302 Episode total reward: 2.0 Predicted Qs: 0.011803151108324528\n",
      "Actions chosen counts:  {0: 41, 1: 58, 2: 45, 3: 46}\n",
      "----------------\n",
      "Frame:13400 Action 1 Loss: 0.00017 Reward: 0.0 Epsilon: 0.98794\n",
      "Frame:13600 Action 1 Loss: 0.00014 Reward: 0.0 Epsilon: 0.9877600000000001\n",
      "Done with episode 77 in 13606 frames\n",
      "Loss: 0.03152875229716301 Episode total reward: 3.0 Predicted Qs: 0.011602936312556267\n",
      "Actions chosen counts:  {0: 57, 1: 66, 2: 51, 3: 62}\n",
      "----------------\n",
      "Done with episode 78 in 13760 frames\n",
      "Loss: 0.02131311222910881 Episode total reward: 1.0 Predicted Qs: 0.012039357796311378\n",
      "Actions chosen counts:  {0: 31, 1: 35, 2: 39, 3: 49}\n",
      "----------------\n",
      "Frame:13800 Action 3 Loss: 0.00038 Reward: 0.0 Epsilon: 0.98758\n",
      "Done with episode 79 in 13950 frames\n",
      "Loss: 0.013042044825851917 Episode total reward: 1.0 Predicted Qs: 0.011693368665874004\n",
      "Actions chosen counts:  {0: 40, 1: 35, 2: 63, 3: 52}\n",
      "----------------\n",
      "Frame:14000 Action 2 Loss: 7e-05 Reward: 0.0 Epsilon: 0.9873999999999999\n",
      "Done with episode 80 in 14167 frames\n",
      "Loss: 0.03297955542802811 Episode total reward: 2.0 Predicted Qs: 0.01133260689675808\n",
      "Actions chosen counts:  {0: 59, 1: 62, 2: 50, 3: 46}\n",
      "----------------\n",
      "Frame:14200 Action 0 Loss: 0.00052 Reward: 0.0 Epsilon: 0.98722\n",
      "Done with episode 81 in 14312 frames\n",
      "Loss: 0.019957013428211212 Episode total reward: 0.0 Predicted Qs: 0.011093804612755775\n",
      "Actions chosen counts:  {0: 51, 1: 30, 2: 31, 3: 33}\n",
      "----------------\n",
      "Frame:14400 Action 3 Loss: 3e-05 Reward: 0.0 Epsilon: 0.98704\n",
      "Done with episode 82 in 14513 frames\n",
      "Loss: 0.02951427362859249 Episode total reward: 2.0 Predicted Qs: 0.01109230425208807\n",
      "Actions chosen counts:  {0: 51, 1: 41, 2: 56, 3: 53}\n",
      "----------------\n",
      "Frame:14600 Action 1 Loss: 0.0003 Reward: 0.0 Epsilon: 0.9868600000000001\n",
      "Done with episode 83 in 14792 frames\n",
      "Loss: 0.02944665029644966 Episode total reward: 4.0 Predicted Qs: 0.010995423421263695\n",
      "Actions chosen counts:  {0: 75, 1: 76, 2: 62, 3: 66}\n",
      "----------------\n",
      "Frame:14800 Action 2 Loss: 0.00931 Reward: 0.0 Epsilon: 0.98668\n",
      "Done with episode 84 in 14984 frames\n",
      "Loss: 0.009309090673923492 Episode total reward: 2.0 Predicted Qs: 0.010502012446522713\n",
      "Actions chosen counts:  {0: 47, 1: 44, 2: 43, 3: 58}\n",
      "----------------\n",
      "Frame:15000 Action 0 Loss: 0.00013 Reward: 0.0 Epsilon: 0.9864999999999999\n",
      "Done with episode 85 in 15179 frames\n",
      "Loss: 0.012542922981083393 Episode total reward: 2.0 Predicted Qs: 0.01073561143130064\n",
      "Actions chosen counts:  {0: 54, 1: 62, 2: 40, 3: 39}\n",
      "----------------\n",
      "Frame:15200 Action 0 Loss: 0.00016 Reward: 0.0 Epsilon: 0.98632\n",
      "Done with episode 86 in 15307 frames\n",
      "Loss: 0.02897661365568638 Episode total reward: 0.0 Predicted Qs: 0.01032971404492855\n",
      "Actions chosen counts:  {0: 43, 1: 36, 2: 26, 3: 23}\n",
      "----------------\n",
      "Frame:15400 Action 1 Loss: 0.00027 Reward: 0.0 Epsilon: 0.98614\n",
      "Done with episode 87 in 15469 frames\n",
      "Loss: 0.02713250182569027 Episode total reward: 1.0 Predicted Qs: 0.010511623695492744\n",
      "Actions chosen counts:  {0: 43, 1: 46, 2: 36, 3: 37}\n",
      "----------------\n",
      "Frame:15600 Action 3 Loss: 9e-05 Reward: 0.0 Epsilon: 0.9859600000000001\n",
      "Done with episode 88 in 15628 frames\n",
      "Loss: 0.025905830785632133 Episode total reward: 1.0 Predicted Qs: 0.01027345284819603\n",
      "Actions chosen counts:  {0: 46, 1: 43, 2: 31, 3: 39}\n",
      "----------------\n",
      "Done with episode 89 in 15792 frames\n",
      "Loss: 0.02418588474392891 Episode total reward: 1.0 Predicted Qs: 0.010176647454500198\n",
      "Actions chosen counts:  {0: 43, 1: 52, 2: 34, 3: 35}\n",
      "----------------\n",
      "Frame:15800 Action 0 Loss: 0.00099 Reward: 0.0 Epsilon: 0.98578\n",
      "Done with episode 90 in 15984 frames\n",
      "Loss: 0.017815416678786278 Episode total reward: 1.0 Predicted Qs: 0.010275034233927727\n",
      "Actions chosen counts:  {0: 50, 1: 52, 2: 45, 3: 45}\n",
      "----------------\n",
      "Frame:16000 Action 1 Loss: 0.00773 Reward: 0.0 Epsilon: 0.9856\n",
      "Done with episode 91 in 16148 frames\n",
      "Loss: 0.025275545194745064 Episode total reward: 1.0 Predicted Qs: 0.009717038832604885\n",
      "Actions chosen counts:  {0: 36, 1: 37, 2: 46, 3: 45}\n",
      "----------------\n",
      "Frame:16200 Action 2 Loss: 0.00014 Reward: 0.0 Epsilon: 0.98542\n",
      "Done with episode 92 in 16358 frames\n",
      "Loss: 0.016936903819441795 Episode total reward: 2.0 Predicted Qs: 0.009380636736750603\n",
      "Actions chosen counts:  {0: 50, 1: 56, 2: 55, 3: 49}\n",
      "----------------\n",
      "Frame:16400 Action 3 Loss: 0.00045 Reward: 0.0 Epsilon: 0.98524\n",
      "Frame:16600 Action 2 Loss: 0.00019 Reward: 0.0 Epsilon: 0.98506\n",
      "Done with episode 93 in 16690 frames\n",
      "Loss: 0.013160161674022675 Episode total reward: 5.0 Predicted Qs: 0.009236283600330353\n",
      "Actions chosen counts:  {0: 88, 1: 79, 2: 84, 3: 81}\n",
      "----------------\n",
      "Frame:16800 Action 2 Loss: 0.00014 Reward: 0.0 Epsilon: 0.98488\n",
      "Done with episode 94 in 16846 frames\n",
      "Loss: 0.0062193600460886955 Episode total reward: 0.0 Predicted Qs: 0.00855507142841816\n",
      "Actions chosen counts:  {0: 51, 1: 32, 2: 40, 3: 33}\n",
      "----------------\n",
      "Frame:17000 Action 0 Loss: 4e-05 Reward: 0.0 Epsilon: 0.9847\n",
      "Done with episode 95 in 17101 frames\n",
      "Loss: 0.029066044837236404 Episode total reward: 3.0 Predicted Qs: 0.008600333705544472\n",
      "Actions chosen counts:  {0: 65, 1: 58, 2: 79, 3: 53}\n",
      "----------------\n",
      "Frame:17200 Action 1 Loss: 6e-05 Reward: 0.0 Epsilon: 0.98452\n",
      "Done with episode 96 in 17331 frames\n",
      "Loss: 0.011135553941130638 Episode total reward: 3.0 Predicted Qs: 0.008280780166387558\n",
      "Actions chosen counts:  {0: 63, 1: 56, 2: 64, 3: 47}\n",
      "----------------\n",
      "Frame:17400 Action 1 Loss: 0.00114 Reward: 0.0 Epsilon: 0.98434\n",
      "Done with episode 97 in 17478 frames\n",
      "Loss: 0.02258423902094364 Episode total reward: 0.0 Predicted Qs: 0.008427418768405914\n",
      "Actions chosen counts:  {0: 37, 1: 40, 2: 31, 3: 39}\n",
      "----------------\n",
      "Frame:17600 Action 1 Loss: 0.00576 Reward: 0.0 Epsilon: 0.98416\n",
      "Done with episode 98 in 17708 frames\n",
      "Loss: 0.026862673461437225 Episode total reward: 2.0 Predicted Qs: 0.00833211001008749\n",
      "Actions chosen counts:  {0: 59, 1: 52, 2: 69, 3: 50}\n",
      "----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:17800 Action 2 Loss: 0.00184 Reward: 0.0 Epsilon: 0.98398\n",
      "Done with episode 99 in 17837 frames\n",
      "Loss: 0.020704828202724457 Episode total reward: 0.0 Predicted Qs: 0.008204471319913864\n",
      "Actions chosen counts:  {0: 30, 1: 30, 2: 37, 3: 32}\n",
      "----------------\n",
      "Frame:18000 Action 2 Loss: 0.00111 Reward: 0.0 Epsilon: 0.9838\n",
      "Done with episode 100 in 18144 frames\n",
      "Loss: 0.032932523638010025 Episode total reward: 4.0 Predicted Qs: 0.008393961936235428\n",
      "Actions chosen counts:  {0: 87, 1: 78, 2: 76, 3: 66}\n",
      "----------------\n",
      "Frame:18200 Action 1 Loss: 0.0002 Reward: 0.0 Epsilon: 0.98362\n",
      "Done with episode 101 in 18300 frames\n",
      "Loss: 0.006968914531171322 Episode total reward: 0.0 Predicted Qs: 0.007875854149460793\n",
      "Actions chosen counts:  {0: 49, 1: 32, 2: 38, 3: 37}\n",
      "----------------\n",
      "Frame:18400 Action 2 Loss: 0.00046 Reward: 0.0 Epsilon: 0.98344\n",
      "Done with episode 102 in 18429 frames\n",
      "Loss: 0.00715221930295229 Episode total reward: 0.0 Predicted Qs: 0.007449140772223473\n",
      "Actions chosen counts:  {0: 32, 1: 30, 2: 38, 3: 29}\n",
      "----------------\n",
      "Frame:18600 Action 1 Loss: 0.00197 Reward: 0.0 Epsilon: 0.98326\n",
      "Done with episode 103 in 18708 frames\n",
      "Loss: 0.03760884329676628 Episode total reward: 3.0 Predicted Qs: 0.007695449516177177\n",
      "Actions chosen counts:  {0: 63, 1: 92, 2: 66, 3: 58}\n",
      "----------------\n",
      "Frame:18800 Action 1 Loss: 0.00046 Reward: 0.0 Epsilon: 0.98308\n",
      "Done with episode 104 in 18838 frames\n",
      "Loss: 0.01775117963552475 Episode total reward: 0.0 Predicted Qs: 0.007216272875666618\n",
      "Actions chosen counts:  {0: 52, 1: 29, 2: 20, 3: 29}\n",
      "----------------\n",
      "Done with episode 105 in 18972 frames\n",
      "Loss: 0.006437471602112055 Episode total reward: 0.0 Predicted Qs: 0.006963422521948814\n",
      "Actions chosen counts:  {0: 36, 1: 34, 2: 31, 3: 33}\n",
      "----------------\n",
      "Frame:19000 Action 3 Loss: 0.00102 Reward: 0.0 Epsilon: 0.9829\n",
      "Done with episode 106 in 19118 frames\n",
      "Loss: 0.012118259444832802 Episode total reward: 0.0 Predicted Qs: 0.006933758035302162\n",
      "Actions chosen counts:  {0: 44, 1: 32, 2: 32, 3: 38}\n",
      "----------------\n",
      "Frame:19200 Action 0 Loss: 0.00178 Reward: 0.0 Epsilon: 0.98272\n",
      "Done with episode 107 in 19291 frames\n",
      "Loss: 0.021267615258693695 Episode total reward: 1.0 Predicted Qs: 0.007096814922988415\n",
      "Actions chosen counts:  {0: 54, 1: 39, 2: 37, 3: 43}\n",
      "----------------\n",
      "Frame:19400 Action 0 Loss: 0.00054 Reward: 0.0 Epsilon: 0.98254\n",
      "Done with episode 108 in 19472 frames\n",
      "Loss: 0.029380686581134796 Episode total reward: 1.0 Predicted Qs: 0.006852693855762482\n",
      "Actions chosen counts:  {0: 52, 1: 39, 2: 45, 3: 45}\n",
      "----------------\n",
      "Frame:19600 Action 0 Loss: 0.0004 Reward: 0.0 Epsilon: 0.98236\n",
      "Done with episode 109 in 19687 frames\n",
      "Loss: 0.017247887328267097 Episode total reward: 2.0 Predicted Qs: 0.006657802499830723\n",
      "Actions chosen counts:  {0: 62, 1: 58, 2: 57, 3: 38}\n",
      "----------------\n",
      "Frame:19800 Action 0 Loss: 0.00044 Reward: 0.0 Epsilon: 0.9821799999999999\n",
      "Done with episode 110 in 19898 frames\n",
      "Loss: 0.020415063947439194 Episode total reward: 2.0 Predicted Qs: 0.006562904920428991\n",
      "Actions chosen counts:  {0: 58, 1: 60, 2: 53, 3: 40}\n",
      "----------------\n",
      "Frame:20000 Action 3 Loss: 0.00019 Reward: 0.0 Epsilon: 0.982\n",
      "Done with episode 111 in 20035 frames\n",
      "Loss: 0.027174463495612144 Episode total reward: 0.0 Predicted Qs: 0.006821217015385628\n",
      "Actions chosen counts:  {0: 41, 1: 38, 2: 32, 3: 26}\n",
      "----------------\n",
      "Done with episode 112 in 20171 frames\n",
      "Loss: 0.00985248014330864 Episode total reward: 0.0 Predicted Qs: 0.006296729668974876\n",
      "Actions chosen counts:  {0: 32, 1: 34, 2: 35, 3: 35}\n",
      "----------------\n",
      "Frame:20200 Action 2 Loss: 5e-05 Reward: 0.0 Epsilon: 0.98182\n",
      "Done with episode 113 in 20386 frames\n",
      "Loss: 0.021692056208848953 Episode total reward: 2.0 Predicted Qs: 0.00602637929841876\n",
      "Actions chosen counts:  {0: 53, 1: 50, 2: 50, 3: 62}\n",
      "----------------\n",
      "Frame:20400 Action 3 Loss: 0.00061 Reward: 0.0 Epsilon: 0.9816400000000001\n",
      "Done with episode 114 in 20522 frames\n",
      "Loss: 0.01210350263863802 Episode total reward: 0.0 Predicted Qs: 0.00614783214405179\n",
      "Actions chosen counts:  {0: 38, 1: 36, 2: 32, 3: 30}\n",
      "----------------\n",
      "Frame:20600 Action 1 Loss: 6e-05 Reward: 0.0 Epsilon: 0.98146\n",
      "Frame:20800 Action 2 Loss: 0.0003 Reward: 0.0 Epsilon: 0.9812799999999999\n",
      "Done with episode 115 in 20877 frames\n",
      "Loss: 0.026853984221816063 Episode total reward: 5.0 Predicted Qs: 0.006174504291266203\n",
      "Actions chosen counts:  {0: 104, 1: 80, 2: 89, 3: 82}\n",
      "----------------\n",
      "Frame:21000 Action 2 Loss: 0.00039 Reward: 0.0 Epsilon: 0.9811\n",
      "Done with episode 116 in 21082 frames\n",
      "Loss: 0.019094105809926987 Episode total reward: 2.0 Predicted Qs: 0.005832452327013016\n",
      "Actions chosen counts:  {0: 61, 1: 55, 2: 44, 3: 45}\n",
      "----------------\n",
      "Frame:21200 Action 1 Loss: 7e-05 Reward: 0.0 Epsilon: 0.98092\n",
      "Done with episode 117 in 21252 frames\n",
      "Loss: 0.01629035733640194 Episode total reward: 0.0 Predicted Qs: 0.005833751987665892\n",
      "Actions chosen counts:  {0: 51, 1: 31, 2: 52, 3: 36}\n",
      "----------------\n",
      "Frame:21400 Action 0 Loss: 0.00015 Reward: 0.0 Epsilon: 0.9807400000000001\n",
      "Done with episode 118 in 21462 frames\n",
      "Loss: 0.010602666065096855 Episode total reward: 2.0 Predicted Qs: 0.005585500039160252\n",
      "Actions chosen counts:  {0: 58, 1: 53, 2: 42, 3: 57}\n",
      "----------------\n",
      "Frame:21600 Action 1 Loss: 0.00045 Reward: 0.0 Epsilon: 0.98056\n",
      "Done with episode 119 in 21607 frames\n",
      "Loss: 0.014071211218833923 Episode total reward: 0.0 Predicted Qs: 0.005374391097575426\n",
      "Actions chosen counts:  {0: 37, 1: 30, 2: 42, 3: 36}\n",
      "----------------\n",
      "Frame:21800 Action 2 Loss: 0.00029 Reward: 0.0 Epsilon: 0.9803799999999999\n",
      "Done with episode 120 in 21813 frames\n",
      "Loss: 0.03473799675703049 Episode total reward: 2.0 Predicted Qs: 0.0060417503118515015\n",
      "Actions chosen counts:  {0: 52, 1: 63, 2: 59, 3: 32}\n",
      "----------------\n",
      "Done with episode 121 in 21964 frames\n",
      "Loss: 0.012088491581380367 Episode total reward: 0.0 Predicted Qs: 0.0057037691585719585\n",
      "Actions chosen counts:  {0: 46, 1: 26, 2: 43, 3: 36}\n",
      "----------------\n",
      "Frame:22000 Action 0 Loss: 0.00131 Reward: 0.0 Epsilon: 0.9802\n",
      "Done with episode 122 in 22182 frames\n",
      "Loss: 0.017917964607477188 Episode total reward: 2.0 Predicted Qs: 0.005009517073631287\n",
      "Actions chosen counts:  {0: 56, 1: 51, 2: 48, 3: 63}\n",
      "----------------\n",
      "Frame:22200 Action 3 Loss: 9e-05 Reward: 0.0 Epsilon: 0.98002\n",
      "Done with episode 123 in 22319 frames\n",
      "Loss: 0.01649978570640087 Episode total reward: 0.0 Predicted Qs: 0.0048131211660802364\n",
      "Actions chosen counts:  {0: 35, 1: 34, 2: 31, 3: 37}\n",
      "----------------\n",
      "Frame:22400 Action 3 Loss: 0.00078 Reward: 0.0 Epsilon: 0.97984\n",
      "Done with episode 124 in 22450 frames\n",
      "Loss: 0.01320625375956297 Episode total reward: 0.0 Predicted Qs: 0.004861006513237953\n",
      "Actions chosen counts:  {0: 32, 1: 29, 2: 41, 3: 29}\n",
      "----------------\n",
      "Frame:22600 Action 0 Loss: 0.00042 Reward: 0.0 Epsilon: 0.9796600000000001\n",
      "Done with episode 125 in 22685 frames\n",
      "Loss: 0.029715271666646004 Episode total reward: 3.0 Predicted Qs: 0.004641737323254347\n",
      "Actions chosen counts:  {0: 58, 1: 52, 2: 60, 3: 65}\n",
      "----------------\n",
      "Frame:22800 Action 1 Loss: 8e-05 Reward: 0.0 Epsilon: 0.9794799999999999\n",
      "Done with episode 126 in 22879 frames\n",
      "Loss: 0.007107792422175407 Episode total reward: 1.0 Predicted Qs: 0.004755605477839708\n",
      "Actions chosen counts:  {0: 65, 1: 40, 2: 38, 3: 51}\n",
      "----------------\n",
      "Frame:23000 Action 2 Loss: 0.00021 Reward: 0.0 Epsilon: 0.9793\n",
      "Done with episode 127 in 23010 frames\n",
      "Loss: 0.024915283545851707 Episode total reward: 0.0 Predicted Qs: 0.0044325971975922585\n",
      "Actions chosen counts:  {0: 31, 1: 36, 2: 29, 3: 35}\n",
      "----------------\n",
      "Done with episode 128 in 23166 frames\n",
      "Loss: 0.007174961268901825 Episode total reward: 1.0 Predicted Qs: 0.0047401427291333675\n",
      "Actions chosen counts:  {0: 37, 1: 45, 2: 34, 3: 40}\n",
      "----------------\n",
      "Frame:23200 Action 0 Loss: 0.0006 Reward: 0.0 Epsilon: 0.97912\n",
      "Done with episode 129 in 23321 frames\n",
      "Loss: 0.011564158834517002 Episode total reward: 1.0 Predicted Qs: 0.004309798590838909\n",
      "Actions chosen counts:  {0: 46, 1: 39, 2: 33, 3: 37}\n",
      "----------------\n",
      "Frame:23400 Action 3 Loss: 9e-05 Reward: 0.0 Epsilon: 0.97894\n",
      "Done with episode 130 in 23485 frames\n",
      "Loss: 0.023961903527379036 Episode total reward: 1.0 Predicted Qs: 0.004575580358505249\n",
      "Actions chosen counts:  {0: 45, 1: 36, 2: 38, 3: 45}\n",
      "----------------\n",
      "Frame:23600 Action 3 Loss: 0.00014 Reward: 0.0 Epsilon: 0.9787600000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with episode 131 in 23624 frames\n",
      "Loss: 0.018223395571112633 Episode total reward: 0.0 Predicted Qs: 0.0039716484025120735\n",
      "Actions chosen counts:  {0: 35, 1: 28, 2: 32, 3: 44}\n",
      "----------------\n",
      "Done with episode 132 in 23759 frames\n",
      "Loss: 0.012158410623669624 Episode total reward: 0.0 Predicted Qs: 0.004204141441732645\n",
      "Actions chosen counts:  {0: 33, 1: 31, 2: 34, 3: 37}\n",
      "----------------\n",
      "Frame:23800 Action 0 Loss: 0.00025 Reward: 0.0 Epsilon: 0.97858\n",
      "Done with episode 133 in 23965 frames\n",
      "Loss: 0.010285437107086182 Episode total reward: 2.0 Predicted Qs: 0.003978032618761063\n",
      "Actions chosen counts:  {0: 54, 1: 52, 2: 41, 3: 59}\n",
      "----------------\n",
      "Frame:24000 Action 2 Loss: 0.00023 Reward: 0.0 Epsilon: 0.9783999999999999\n",
      "Done with episode 134 in 24104 frames\n",
      "Loss: 0.01415637880563736 Episode total reward: 0.0 Predicted Qs: 0.004191703163087368\n",
      "Actions chosen counts:  {0: 37, 1: 40, 2: 28, 3: 34}\n",
      "----------------\n",
      "Frame:24200 Action 2 Loss: 0.00028 Reward: 0.0 Epsilon: 0.97822\n",
      "Done with episode 135 in 24266 frames\n",
      "Loss: 0.025726119056344032 Episode total reward: 1.0 Predicted Qs: 0.003764956956729293\n",
      "Actions chosen counts:  {0: 39, 1: 51, 2: 43, 3: 29}\n",
      "----------------\n",
      "Frame:24400 Action 3 Loss: 0.00011 Reward: 0.0 Epsilon: 0.97804\n",
      "Done with episode 136 in 24446 frames\n",
      "Loss: 0.02070816420018673 Episode total reward: 1.0 Predicted Qs: 0.003753605065867305\n",
      "Actions chosen counts:  {0: 45, 1: 49, 2: 38, 3: 48}\n",
      "----------------\n",
      "Done with episode 137 in 24576 frames\n",
      "Loss: 0.01762956753373146 Episode total reward: 0.0 Predicted Qs: 0.003962386399507523\n",
      "Actions chosen counts:  {0: 31, 1: 32, 2: 32, 3: 35}\n",
      "----------------\n",
      "Frame:24600 Action 0 Loss: 8e-05 Reward: 0.0 Epsilon: 0.9778600000000001\n",
      "Done with episode 138 in 24724 frames\n",
      "Loss: 0.021492155268788338 Episode total reward: 0.0 Predicted Qs: 0.004203750751912594\n",
      "Actions chosen counts:  {0: 50, 1: 35, 2: 35, 3: 28}\n",
      "----------------\n",
      "Frame:24800 Action 0 Loss: 0.00033 Reward: 0.0 Epsilon: 0.97768\n",
      "Done with episode 139 in 24927 frames\n",
      "Loss: 0.011118737049400806 Episode total reward: 2.0 Predicted Qs: 0.004309257958084345\n",
      "Actions chosen counts:  {0: 60, 1: 30, 2: 40, 3: 73}\n",
      "----------------\n",
      "Frame:25000 Action 2 Loss: 8e-05 Reward: 0.0 Epsilon: 0.9774999999999999\n",
      "Done with episode 140 in 25115 frames\n",
      "Loss: 0.015668852254748344 Episode total reward: 1.0 Predicted Qs: 0.0037319434341043234\n",
      "Actions chosen counts:  {0: 56, 1: 40, 2: 46, 3: 46}\n",
      "----------------\n",
      "Frame:25200 Action 0 Loss: 0.00011 Reward: 0.0 Epsilon: 0.97732\n",
      "Done with episode 141 in 25285 frames\n",
      "Loss: 0.014562603086233139 Episode total reward: 1.0 Predicted Qs: 0.003764287568628788\n",
      "Actions chosen counts:  {0: 52, 1: 40, 2: 39, 3: 39}\n",
      "----------------\n",
      "Frame:25400 Action 3 Loss: 0.00076 Reward: 0.0 Epsilon: 0.97714\n",
      "Done with episode 142 in 25450 frames\n",
      "Loss: 0.010758090764284134 Episode total reward: 1.0 Predicted Qs: 0.004051016177982092\n",
      "Actions chosen counts:  {0: 51, 1: 29, 2: 36, 3: 49}\n",
      "----------------\n",
      "Done with episode 143 in 25598 frames\n",
      "Loss: 0.008425937034189701 Episode total reward: 0.0 Predicted Qs: 0.004038380458950996\n",
      "Actions chosen counts:  {0: 43, 1: 24, 2: 39, 3: 42}\n",
      "----------------\n",
      "Frame:25600 Action 1 Loss: 0.00013 Reward: 0.0 Epsilon: 0.97696\n",
      "Frame:25800 Action 2 Loss: 0.00018 Reward: 0.0 Epsilon: 0.97678\n",
      "Done with episode 144 in 25868 frames\n",
      "Loss: 0.02068312279880047 Episode total reward: 3.0 Predicted Qs: 0.0036313352175056934\n",
      "Actions chosen counts:  {0: 69, 1: 60, 2: 68, 3: 73}\n",
      "----------------\n",
      "Frame:26000 Action 0 Loss: 6e-05 Reward: 0.0 Epsilon: 0.9766\n",
      "Done with episode 145 in 26090 frames\n",
      "Loss: 0.010975856333971024 Episode total reward: 2.0 Predicted Qs: 0.003494052216410637\n",
      "Actions chosen counts:  {0: 61, 1: 53, 2: 59, 3: 49}\n",
      "----------------\n",
      "Frame:26200 Action 1 Loss: 0.00095 Reward: 0.0 Epsilon: 0.97642\n",
      "Done with episode 146 in 26244 frames\n",
      "Loss: 0.00955305714160204 Episode total reward: 0.0 Predicted Qs: 0.0033739313948899508\n",
      "Actions chosen counts:  {0: 37, 1: 34, 2: 50, 3: 33}\n",
      "----------------\n",
      "Frame:26400 Action 2 Loss: 6e-05 Reward: 0.0 Epsilon: 0.97624\n",
      "Done with episode 147 in 26443 frames\n",
      "Loss: 0.010145561769604683 Episode total reward: 2.0 Predicted Qs: 0.003369181649759412\n",
      "Actions chosen counts:  {0: 45, 1: 57, 2: 47, 3: 50}\n",
      "----------------\n",
      "Done with episode 148 in 26578 frames\n",
      "Loss: 0.0071088699623942375 Episode total reward: 0.0 Predicted Qs: 0.003030709456652403\n",
      "Actions chosen counts:  {0: 38, 1: 31, 2: 32, 3: 34}\n",
      "----------------\n",
      "Frame:26600 Action 1 Loss: 3e-05 Reward: 0.0 Epsilon: 0.97606\n",
      "Done with episode 149 in 26727 frames\n",
      "Loss: 0.0056875478476285934 Episode total reward: 0.0 Predicted Qs: 0.002970002591609955\n",
      "Actions chosen counts:  {0: 42, 1: 34, 2: 41, 3: 32}\n",
      "----------------\n",
      "Frame:26800 Action 2 Loss: 0.0001 Reward: 1.0 Epsilon: 0.97588\n",
      "Done with episode 150 in 26950 frames\n",
      "Loss: 0.017723077908158302 Episode total reward: 2.0 Predicted Qs: 0.003307315753772855\n",
      "Actions chosen counts:  {0: 67, 1: 56, 2: 53, 3: 47}\n",
      "----------------\n",
      "Frame:27000 Action 3 Loss: 0.00027 Reward: 0.0 Epsilon: 0.9757\n",
      "Done with episode 151 in 27111 frames\n",
      "Loss: 0.019246095791459084 Episode total reward: 1.0 Predicted Qs: 0.00313514843583107\n",
      "Actions chosen counts:  {0: 43, 1: 47, 2: 35, 3: 36}\n",
      "----------------\n",
      "Frame:27200 Action 3 Loss: 0.00032 Reward: 0.0 Epsilon: 0.9755199999999999\n",
      "Done with episode 152 in 27296 frames\n",
      "Loss: 0.016483401879668236 Episode total reward: 1.0 Predicted Qs: 0.0028977044858038425\n",
      "Actions chosen counts:  {0: 56, 1: 46, 2: 39, 3: 44}\n",
      "----------------\n",
      "Frame:27400 Action 2 Loss: 0.00013 Reward: 0.0 Epsilon: 0.97534\n",
      "Done with episode 153 in 27441 frames\n",
      "Loss: 0.015678737312555313 Episode total reward: 0.0 Predicted Qs: 0.002588519360870123\n",
      "Actions chosen counts:  {0: 32, 1: 35, 2: 42, 3: 36}\n",
      "----------------\n",
      "Frame:27600 Action 3 Loss: 0.00017 Reward: 0.0 Epsilon: 0.97516\n",
      "Done with episode 154 in 27640 frames\n",
      "Loss: 0.01158395316451788 Episode total reward: 2.0 Predicted Qs: 0.0027982036117464304\n",
      "Actions chosen counts:  {0: 53, 1: 50, 2: 47, 3: 49}\n",
      "----------------\n",
      "Frame:27800 Action 0 Loss: 8e-05 Reward: 0.0 Epsilon: 0.97498\n",
      "Done with episode 155 in 27819 frames\n",
      "Loss: 0.011086725629866123 Episode total reward: 1.0 Predicted Qs: 0.0028186687268316746\n",
      "Actions chosen counts:  {0: 47, 1: 48, 2: 43, 3: 41}\n",
      "----------------\n",
      "Done with episode 156 in 27983 frames\n",
      "Loss: 0.0087295426055789 Episode total reward: 1.0 Predicted Qs: 0.002996082417666912\n",
      "Actions chosen counts:  {0: 43, 1: 50, 2: 36, 3: 35}\n",
      "----------------\n",
      "Frame:28000 Action 2 Loss: 8e-05 Reward: 0.0 Epsilon: 0.9748\n",
      "Frame:28200 Action 1 Loss: 0.00012 Reward: 0.0 Epsilon: 0.97462\n",
      "Done with episode 157 in 28239 frames\n",
      "Loss: 0.007814764976501465 Episode total reward: 3.0 Predicted Qs: 0.00303694442845881\n",
      "Actions chosen counts:  {0: 76, 1: 55, 2: 62, 3: 63}\n",
      "----------------\n",
      "Frame:28400 Action 0 Loss: 0.00084 Reward: 0.0 Epsilon: 0.97444\n",
      "Done with episode 158 in 28517 frames\n",
      "Loss: 0.017965395003557205 Episode total reward: 3.0 Predicted Qs: 0.002806154079735279\n",
      "Actions chosen counts:  {0: 68, 1: 64, 2: 76, 3: 70}\n",
      "----------------\n",
      "Frame:28600 Action 1 Loss: 0.00023 Reward: 0.0 Epsilon: 0.97426\n",
      "Done with episode 159 in 28698 frames\n",
      "Loss: 0.015296979807317257 Episode total reward: 1.0 Predicted Qs: 0.003116604406386614\n",
      "Actions chosen counts:  {0: 49, 1: 47, 2: 39, 3: 46}\n",
      "----------------\n",
      "Frame:28800 Action 3 Loss: 0.00014 Reward: 0.0 Epsilon: 0.97408\n",
      "Done with episode 160 in 28872 frames\n",
      "Loss: 0.0028781313449144363 Episode total reward: 1.0 Predicted Qs: 0.002921765437349677\n",
      "Actions chosen counts:  {0: 42, 1: 40, 2: 41, 3: 51}\n",
      "----------------\n",
      "Frame:29000 Action 0 Loss: 0.00027 Reward: 0.0 Epsilon: 0.9739\n",
      "Done with episode 161 in 29075 frames\n",
      "Loss: 0.0072415717877447605 Episode total reward: 2.0 Predicted Qs: 0.0024699950590729713\n",
      "Actions chosen counts:  {0: 60, 1: 53, 2: 50, 3: 40}\n",
      "----------------\n",
      "Frame:29200 Action 0 Loss: 0.00023 Reward: 0.0 Epsilon: 0.97372\n",
      "Done with episode 162 in 29216 frames\n",
      "Loss: 0.025792676955461502 Episode total reward: 0.0 Predicted Qs: 0.0026536048389971256\n",
      "Actions chosen counts:  {0: 37, 1: 32, 2: 39, 3: 33}\n",
      "----------------\n",
      "Done with episode 163 in 29378 frames\n",
      "Loss: 0.017399711534380913 Episode total reward: 1.0 Predicted Qs: 0.002447684993967414\n",
      "Actions chosen counts:  {0: 56, 1: 40, 2: 34, 3: 32}\n",
      "----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:29400 Action 3 Loss: 0.00036 Reward: 0.0 Epsilon: 0.97354\n",
      "Done with episode 164 in 29584 frames\n",
      "Loss: 0.015151998959481716 Episode total reward: 2.0 Predicted Qs: 0.0022966181859374046\n",
      "Actions chosen counts:  {0: 52, 1: 48, 2: 59, 3: 47}\n",
      "----------------\n",
      "Frame:29600 Action 0 Loss: 0.00027 Reward: 0.0 Epsilon: 0.97336\n",
      "Done with episode 165 in 29719 frames\n",
      "Loss: 0.008742879144847393 Episode total reward: 0.0 Predicted Qs: 0.0024407291784882545\n",
      "Actions chosen counts:  {0: 32, 1: 31, 2: 40, 3: 32}\n",
      "----------------\n",
      "Frame:29800 Action 1 Loss: 0.00027 Reward: 0.0 Epsilon: 0.9731799999999999\n",
      "Done with episode 166 in 29854 frames\n",
      "Loss: 0.010095088742673397 Episode total reward: 0.0 Predicted Qs: 0.002549901604652405\n",
      "Actions chosen counts:  {0: 30, 1: 28, 2: 44, 3: 33}\n",
      "----------------\n",
      "Frame:30000 Action 3 Loss: 0.00068 Reward: 0.0 Epsilon: 0.973\n",
      "Done with episode 167 in 30081 frames\n",
      "Loss: 0.012768037617206573 Episode total reward: 2.0 Predicted Qs: 0.0021352290641516447\n",
      "Actions chosen counts:  {0: 56, 1: 52, 2: 46, 3: 73}\n",
      "----------------\n",
      "Frame:30200 Action 0 Loss: 0.00125 Reward: 0.0 Epsilon: 0.97282\n",
      "Done with episode 168 in 30243 frames\n",
      "Loss: 0.007713504135608673 Episode total reward: 1.0 Predicted Qs: 0.0020562992431223392\n",
      "Actions chosen counts:  {0: 49, 1: 33, 2: 48, 3: 32}\n",
      "----------------\n",
      "Done with episode 169 in 30376 frames\n",
      "Loss: 0.001958654960617423 Episode total reward: 0.0 Predicted Qs: 0.0019015066791325808\n",
      "Actions chosen counts:  {0: 37, 1: 29, 2: 30, 3: 37}\n",
      "----------------\n",
      "Frame:30400 Action 1 Loss: 8e-05 Reward: 0.0 Epsilon: 0.9726400000000001\n",
      "Done with episode 170 in 30586 frames\n",
      "Loss: 0.008825324475765228 Episode total reward: 2.0 Predicted Qs: 0.0021808717865496874\n",
      "Actions chosen counts:  {0: 66, 1: 44, 2: 53, 3: 47}\n",
      "----------------\n",
      "Frame:30600 Action 1 Loss: 0.00023 Reward: 0.0 Epsilon: 0.97246\n",
      "Done with episode 171 in 30720 frames\n",
      "Loss: 0.004188524559140205 Episode total reward: 0.0 Predicted Qs: 0.0016615316271781921\n",
      "Actions chosen counts:  {0: 36, 1: 39, 2: 30, 3: 29}\n",
      "----------------\n",
      "Frame:30800 Action 1 Loss: 0.0001 Reward: 0.0 Epsilon: 0.9722799999999999\n",
      "Done with episode 172 in 30904 frames\n",
      "Loss: 0.0026229454670101404 Episode total reward: 2.0 Predicted Qs: 0.001996847102418542\n",
      "Actions chosen counts:  {0: 49, 1: 50, 2: 33, 3: 52}\n",
      "----------------\n",
      "Frame:31000 Action 3 Loss: 0.0004 Reward: 0.0 Epsilon: 0.9721\n",
      "Done with episode 173 in 31051 frames\n",
      "Loss: 0.015232669189572334 Episode total reward: 0.0 Predicted Qs: 0.001912881387397647\n",
      "Actions chosen counts:  {0: 38, 1: 36, 2: 37, 3: 36}\n",
      "----------------\n",
      "Frame:31200 Action 0 Loss: 4e-05 Reward: 0.0 Epsilon: 0.97192\n",
      "Done with episode 174 in 31219 frames\n",
      "Loss: 0.005589437671005726 Episode total reward: 1.0 Predicted Qs: 0.0015930045628920197\n",
      "Actions chosen counts:  {0: 51, 1: 41, 2: 38, 3: 38}\n",
      "----------------\n",
      "Done with episode 175 in 31351 frames\n",
      "Loss: 0.0013346885098144412 Episode total reward: 0.0 Predicted Qs: 0.0019086537649855018\n",
      "Actions chosen counts:  {0: 35, 1: 35, 2: 35, 3: 27}\n",
      "----------------\n",
      "Frame:31400 Action 1 Loss: 0.00013 Reward: 0.0 Epsilon: 0.97174\n",
      "Done with episode 176 in 31522 frames\n",
      "Loss: 0.003365587443113327 Episode total reward: 1.0 Predicted Qs: 0.0017661923775449395\n",
      "Actions chosen counts:  {0: 46, 1: 40, 2: 43, 3: 42}\n",
      "----------------\n",
      "Frame:31600 Action 0 Loss: 0.00029 Reward: 0.0 Epsilon: 0.97156\n",
      "Done with episode 177 in 31786 frames\n",
      "Loss: 0.007842173799872398 Episode total reward: 3.0 Predicted Qs: 0.0019067060202360153\n",
      "Actions chosen counts:  {0: 74, 1: 58, 2: 76, 3: 56}\n",
      "----------------\n",
      "Frame:31800 Action 2 Loss: 0.00011 Reward: 0.0 Epsilon: 0.9713799999999999\n",
      "Done with episode 178 in 31945 frames\n",
      "Loss: 0.01312257256358862 Episode total reward: 1.0 Predicted Qs: 0.001722373766824603\n",
      "Actions chosen counts:  {0: 36, 1: 34, 2: 43, 3: 46}\n",
      "----------------\n",
      "Frame:32000 Action 2 Loss: 8e-05 Reward: 0.0 Epsilon: 0.9712\n",
      "Done with episode 179 in 32149 frames\n",
      "Loss: 0.012087693437933922 Episode total reward: 1.0 Predicted Qs: 0.0016566480044275522\n",
      "Actions chosen counts:  {0: 55, 1: 41, 2: 55, 3: 53}\n",
      "----------------\n",
      "Frame:32200 Action 1 Loss: 0.00022 Reward: 0.0 Epsilon: 0.97102\n",
      "Done with episode 180 in 32275 frames\n",
      "Loss: 0.002793822204694152 Episode total reward: 0.0 Predicted Qs: 0.001498707802966237\n",
      "Actions chosen counts:  {0: 35, 1: 35, 2: 31, 3: 25}\n",
      "----------------\n",
      "Frame:32400 Action 2 Loss: 0.00039 Reward: 0.0 Epsilon: 0.97084\n",
      "Done with episode 181 in 32458 frames\n",
      "Loss: 0.01345842145383358 Episode total reward: 1.0 Predicted Qs: 0.001969475531950593\n",
      "Actions chosen counts:  {0: 48, 1: 47, 2: 46, 3: 42}\n",
      "----------------\n",
      "Done with episode 182 in 32599 frames\n",
      "Loss: 0.011778334155678749 Episode total reward: 0.0 Predicted Qs: 0.001807693624868989\n",
      "Actions chosen counts:  {0: 34, 1: 30, 2: 45, 3: 32}\n",
      "----------------\n",
      "Frame:32600 Action 1 Loss: 0.00028 Reward: 0.0 Epsilon: 0.9706600000000001\n",
      "Done with episode 183 in 32786 frames\n",
      "Loss: 0.006781767588108778 Episode total reward: 2.0 Predicted Qs: 0.0017032958567142487\n",
      "Actions chosen counts:  {0: 55, 1: 51, 2: 36, 3: 45}\n",
      "----------------\n",
      "Frame:32800 Action 2 Loss: 8e-05 Reward: 0.0 Epsilon: 0.9704799999999999\n",
      "Frame:33000 Action 2 Loss: 0.00045 Reward: 0.0 Epsilon: 0.9702999999999999\n",
      "Done with episode 184 in 33022 frames\n",
      "Loss: 0.00492488918825984 Episode total reward: 3.0 Predicted Qs: 0.0014703047927469015\n",
      "Actions chosen counts:  {0: 52, 1: 59, 2: 69, 3: 56}\n",
      "----------------\n",
      "Done with episode 185 in 33168 frames\n",
      "Loss: 0.012291728518903255 Episode total reward: 0.0 Predicted Qs: 0.0015900044236332178\n",
      "Actions chosen counts:  {0: 38, 1: 36, 2: 42, 3: 30}\n",
      "----------------\n",
      "Frame:33200 Action 2 Loss: 8e-05 Reward: 0.0 Epsilon: 0.97012\n",
      "Frame:33400 Action 3 Loss: 0.00011 Reward: 0.0 Epsilon: 0.96994\n",
      "Done with episode 186 in 33478 frames\n",
      "Loss: 0.03247883915901184 Episode total reward: 4.0 Predicted Qs: 0.0018555624410510063\n",
      "Actions chosen counts:  {0: 74, 1: 76, 2: 88, 3: 72}\n",
      "----------------\n",
      "Frame:33600 Action 0 Loss: 0.0001 Reward: 0.0 Epsilon: 0.9697600000000001\n",
      "Done with episode 187 in 33660 frames\n",
      "Loss: 0.004743096884340048 Episode total reward: 1.0 Predicted Qs: 0.00155341112986207\n",
      "Actions chosen counts:  {0: 53, 1: 47, 2: 41, 3: 41}\n",
      "----------------\n",
      "Frame:33800 Action 0 Loss: 8e-05 Reward: 0.0 Epsilon: 0.96958\n",
      "Done with episode 188 in 33847 frames\n",
      "Loss: 0.003654833184555173 Episode total reward: 1.0 Predicted Qs: 0.0018267534906044602\n",
      "Actions chosen counts:  {0: 53, 1: 43, 2: 48, 3: 43}\n",
      "----------------\n",
      "Frame:34000 Action 0 Loss: 0.00114 Reward: 0.0 Epsilon: 0.9693999999999999\n",
      "Done with episode 189 in 34078 frames\n",
      "Loss: 0.011358133517205715 Episode total reward: 2.0 Predicted Qs: 0.0017246806528419256\n",
      "Actions chosen counts:  {0: 59, 1: 60, 2: 57, 3: 55}\n",
      "----------------\n",
      "Frame:34200 Action 1 Loss: 5e-05 Reward: 0.0 Epsilon: 0.96922\n",
      "Done with episode 190 in 34210 frames\n",
      "Loss: 0.02235238067805767 Episode total reward: 0.0 Predicted Qs: 0.0018503309693187475\n",
      "Actions chosen counts:  {0: 37, 1: 37, 2: 26, 3: 32}\n",
      "----------------\n",
      "Done with episode 191 in 34380 frames\n",
      "Loss: 0.027079394087195396 Episode total reward: 1.0 Predicted Qs: 0.0014325028751045465\n",
      "Actions chosen counts:  {0: 45, 1: 49, 2: 37, 3: 39}\n",
      "----------------\n",
      "Frame:34400 Action 2 Loss: 0.00016 Reward: 0.0 Epsilon: 0.96904\n",
      "Done with episode 192 in 34540 frames\n",
      "Loss: 0.01848810352385044 Episode total reward: 1.0 Predicted Qs: 0.001149827498011291\n",
      "Actions chosen counts:  {0: 43, 1: 44, 2: 33, 3: 40}\n",
      "----------------\n",
      "Frame:34600 Action 2 Loss: 9e-05 Reward: 0.0 Epsilon: 0.96886\n",
      "Frame:34800 Action 2 Loss: 3e-05 Reward: 0.0 Epsilon: 0.96868\n",
      "Done with episode 193 in 34843 frames\n",
      "Loss: 0.008327469229698181 Episode total reward: 4.0 Predicted Qs: 0.0015143502969294786\n",
      "Actions chosen counts:  {0: 78, 1: 83, 2: 64, 3: 78}\n",
      "----------------\n",
      "Done with episode 194 in 34991 frames\n",
      "Loss: 0.039349984377622604 Episode total reward: 0.0 Predicted Qs: 0.0015761503018438816\n",
      "Actions chosen counts:  {0: 55, 1: 33, 2: 32, 3: 28}\n",
      "----------------\n",
      "Frame:35000 Action 1 Loss: 3e-05 Reward: 0.0 Epsilon: 0.9684999999999999\n",
      "Done with episode 195 in 35182 frames\n",
      "Loss: 0.016591718420386314 Episode total reward: 1.0 Predicted Qs: 0.002019236097112298\n",
      "Actions chosen counts:  {0: 51, 1: 52, 2: 44, 3: 44}\n",
      "----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:35200 Action 0 Loss: 0.00043 Reward: 0.0 Epsilon: 0.96832\n",
      "Done with episode 196 in 35365 frames\n",
      "Loss: 0.029782384634017944 Episode total reward: 1.0 Predicted Qs: 0.002208733931183815\n",
      "Actions chosen counts:  {0: 55, 1: 36, 2: 54, 3: 38}\n",
      "----------------\n",
      "Frame:35400 Action 0 Loss: 0.00024 Reward: 0.0 Epsilon: 0.96814\n",
      "Done with episode 197 in 35546 frames\n",
      "Loss: 0.002993213478475809 Episode total reward: 1.0 Predicted Qs: 0.001902167685329914\n",
      "Actions chosen counts:  {0: 54, 1: 42, 2: 42, 3: 43}\n",
      "----------------\n",
      "Frame:35600 Action 0 Loss: 5e-05 Reward: 0.0 Epsilon: 0.96796\n",
      "Done with episode 198 in 35681 frames\n",
      "Loss: 0.006619635503739119 Episode total reward: 0.0 Predicted Qs: 0.0019485553493723273\n",
      "Actions chosen counts:  {0: 32, 1: 35, 2: 34, 3: 34}\n",
      "----------------\n",
      "Frame:35800 Action 3 Loss: 7e-05 Reward: 0.0 Epsilon: 0.96778\n",
      "Done with episode 199 in 35896 frames\n",
      "Loss: 0.01417235191911459 Episode total reward: 2.0 Predicted Qs: 0.0022306067403405905\n",
      "Actions chosen counts:  {0: 58, 1: 51, 2: 45, 3: 61}\n",
      "----------------\n",
      "Frame:36000 Action 2 Loss: 0.00012 Reward: 0.0 Epsilon: 0.9676\n",
      "Done with episode 200 in 36098 frames\n",
      "Loss: 0.01847708225250244 Episode total reward: 2.0 Predicted Qs: 0.001970121171325445\n",
      "Actions chosen counts:  {0: 57, 1: 57, 2: 47, 3: 41}\n",
      "----------------\n",
      "Frame:36200 Action 0 Loss: 0.00016 Reward: 0.0 Epsilon: 0.96742\n",
      "Done with episode 201 in 36239 frames\n",
      "Loss: 0.013760397210717201 Episode total reward: 0.0 Predicted Qs: 0.002040745224803686\n",
      "Actions chosen counts:  {0: 36, 1: 35, 2: 36, 3: 34}\n",
      "----------------\n",
      "Frame:36400 Action 2 Loss: 0.00101 Reward: 0.0 Epsilon: 0.96724\n",
      "Done with episode 202 in 36422 frames\n",
      "Loss: 0.009428673423826694 Episode total reward: 1.0 Predicted Qs: 0.002028214745223522\n",
      "Actions chosen counts:  {0: 56, 1: 39, 2: 48, 3: 40}\n",
      "----------------\n",
      "Done with episode 203 in 36577 frames\n",
      "Loss: 0.005430177319794893 Episode total reward: 1.0 Predicted Qs: 0.0018224073573946953\n",
      "Actions chosen counts:  {0: 43, 1: 36, 2: 39, 3: 37}\n",
      "----------------\n",
      "Frame:36600 Action 1 Loss: 0.00031 Reward: 0.0 Epsilon: 0.96706\n",
      "Done with episode 204 in 36709 frames\n",
      "Loss: 0.01627584919333458 Episode total reward: 0.0 Predicted Qs: 0.001873545115813613\n",
      "Actions chosen counts:  {0: 40, 1: 30, 2: 31, 3: 31}\n",
      "----------------\n",
      "Frame:36800 Action 0 Loss: 9e-05 Reward: 0.0 Epsilon: 0.96688\n",
      "Done with episode 205 in 36916 frames\n",
      "Loss: 0.029775675386190414 Episode total reward: 2.0 Predicted Qs: 0.0016465260414406657\n",
      "Actions chosen counts:  {0: 59, 1: 51, 2: 51, 3: 46}\n",
      "----------------\n",
      "Frame:37000 Action 1 Loss: 0.0001 Reward: 0.0 Epsilon: 0.9667\n",
      "Done with episode 206 in 37060 frames\n",
      "Loss: 0.013073071837425232 Episode total reward: 0.0 Predicted Qs: 0.0018190649570897222\n",
      "Actions chosen counts:  {0: 32, 1: 26, 2: 46, 3: 40}\n",
      "----------------\n",
      "Frame:37200 Action 3 Loss: 9e-05 Reward: 0.0 Epsilon: 0.9665199999999999\n",
      "Done with episode 207 in 37262 frames\n",
      "Loss: 0.02390608936548233 Episode total reward: 2.0 Predicted Qs: 0.0016605313867330551\n",
      "Actions chosen counts:  {0: 62, 1: 47, 2: 48, 3: 45}\n",
      "----------------\n",
      "Frame:37400 Action 2 Loss: 0.0001 Reward: 0.0 Epsilon: 0.96634\n",
      "Done with episode 208 in 37416 frames\n",
      "Loss: 0.020482772961258888 Episode total reward: 1.0 Predicted Qs: 0.0019082592334598303\n",
      "Actions chosen counts:  {0: 36, 1: 36, 2: 37, 3: 45}\n",
      "----------------\n",
      "Frame:37600 Action 1 Loss: 0.0001 Reward: 0.0 Epsilon: 0.96616\n",
      "Done with episode 209 in 37617 frames\n",
      "Loss: 0.017836010083556175 Episode total reward: 2.0 Predicted Qs: 0.0018721753731369972\n",
      "Actions chosen counts:  {0: 54, 1: 56, 2: 52, 3: 39}\n",
      "----------------\n",
      "Frame:37800 Action 0 Loss: 3e-05 Reward: 0.0 Epsilon: 0.9659800000000001\n",
      "Done with episode 210 in 37810 frames\n",
      "Loss: 0.008867154829204082 Episode total reward: 1.0 Predicted Qs: 0.0018497516866773367\n",
      "Actions chosen counts:  {0: 59, 1: 45, 2: 41, 3: 48}\n",
      "----------------\n",
      "Frame:38000 Action 3 Loss: 0.0001 Reward: 0.0 Epsilon: 0.9658\n",
      "Done with episode 211 in 38024 frames\n",
      "Loss: 0.015061983838677406 Episode total reward: 2.0 Predicted Qs: 0.0019067497923970222\n",
      "Actions chosen counts:  {0: 64, 1: 54, 2: 51, 3: 45}\n",
      "----------------\n",
      "Frame:38200 Action 2 Loss: 5e-05 Reward: 0.0 Epsilon: 0.96562\n",
      "Done with episode 212 in 38246 frames\n",
      "Loss: 0.008841309696435928 Episode total reward: 2.0 Predicted Qs: 0.001775852171704173\n",
      "Actions chosen counts:  {0: 65, 1: 50, 2: 54, 3: 53}\n",
      "----------------\n",
      "Frame:38400 Action 1 Loss: 0.00014 Reward: 0.0 Epsilon: 0.96544\n",
      "Done with episode 213 in 38415 frames\n",
      "Loss: 0.007983263581991196 Episode total reward: 1.0 Predicted Qs: 0.0015251976437866688\n",
      "Actions chosen counts:  {0: 48, 1: 41, 2: 38, 3: 42}\n",
      "----------------\n",
      "Done with episode 214 in 38548 frames\n",
      "Loss: 0.006988075561821461 Episode total reward: 0.0 Predicted Qs: 0.001511021051555872\n",
      "Actions chosen counts:  {0: 47, 1: 30, 2: 31, 3: 25}\n",
      "----------------\n",
      "Frame:38600 Action 2 Loss: 0.00011 Reward: 0.0 Epsilon: 0.96526\n",
      "Done with episode 215 in 38722 frames\n",
      "Loss: 0.009506233036518097 Episode total reward: 1.0 Predicted Qs: 0.0015155896544456482\n",
      "Actions chosen counts:  {0: 56, 1: 34, 2: 37, 3: 47}\n",
      "----------------\n",
      "Frame:38800 Action 1 Loss: 0.00142 Reward: 0.0 Epsilon: 0.96508\n",
      "Done with episode 216 in 38856 frames\n",
      "Loss: 0.007837275974452496 Episode total reward: 0.0 Predicted Qs: 0.0020804880186915398\n",
      "Actions chosen counts:  {0: 36, 1: 35, 2: 30, 3: 33}\n",
      "----------------\n",
      "Frame:39000 Action 1 Loss: 7e-05 Reward: 0.0 Epsilon: 0.9649\n",
      "Done with episode 217 in 39071 frames\n",
      "Loss: 0.016302045434713364 Episode total reward: 2.0 Predicted Qs: 0.0017379641067236662\n",
      "Actions chosen counts:  {0: 56, 1: 51, 2: 61, 3: 47}\n",
      "----------------\n",
      "Frame:39200 Action 0 Loss: 5e-05 Reward: 0.0 Epsilon: 0.96472\n",
      "Done with episode 218 in 39212 frames\n",
      "Loss: 0.001667188131250441 Episode total reward: 0.0 Predicted Qs: 0.0015738767106086016\n",
      "Actions chosen counts:  {0: 35, 1: 31, 2: 39, 3: 36}\n",
      "----------------\n",
      "Done with episode 219 in 39348 frames\n",
      "Loss: 0.002662201412022114 Episode total reward: 0.0 Predicted Qs: 0.0014824983663856983\n",
      "Actions chosen counts:  {0: 45, 1: 42, 2: 28, 3: 21}\n",
      "----------------\n",
      "Frame:39400 Action 2 Loss: 0.00014 Reward: 0.0 Epsilon: 0.96454\n",
      "Frame:39600 Action 0 Loss: 5e-05 Reward: 0.0 Epsilon: 0.96436\n",
      "Done with episode 220 in 39613 frames\n",
      "Loss: 0.010838260874152184 Episode total reward: 3.0 Predicted Qs: 0.001714867539703846\n",
      "Actions chosen counts:  {0: 70, 1: 58, 2: 60, 3: 77}\n",
      "----------------\n",
      "Done with episode 221 in 39747 frames\n",
      "Loss: 0.00807929877191782 Episode total reward: 0.0 Predicted Qs: 0.0013664714060723782\n",
      "Actions chosen counts:  {0: 46, 1: 32, 2: 28, 3: 28}\n",
      "----------------\n",
      "Frame:39800 Action 0 Loss: 0.00025 Reward: 0.0 Epsilon: 0.96418\n",
      "Done with episode 222 in 39949 frames\n",
      "Loss: 0.009196690283715725 Episode total reward: 2.0 Predicted Qs: 0.0014280619798228145\n",
      "Actions chosen counts:  {0: 67, 1: 49, 2: 39, 3: 47}\n",
      "----------------\n",
      "Frame:40000 Action 2 Loss: 2e-05 Reward: 0.0 Epsilon: 0.964\n",
      "Done with episode 223 in 40113 frames\n",
      "Loss: 0.008471284061670303 Episode total reward: 1.0 Predicted Qs: 0.0014671313110738993\n",
      "Actions chosen counts:  {0: 52, 1: 29, 2: 39, 3: 44}\n",
      "----------------\n",
      "Frame:40200 Action 0 Loss: 6e-05 Reward: 0.0 Epsilon: 0.96382\n",
      "Done with episode 224 in 40251 frames\n",
      "Loss: 0.01715647242963314 Episode total reward: 0.0 Predicted Qs: 0.001574801281094551\n",
      "Actions chosen counts:  {0: 39, 1: 37, 2: 30, 3: 32}\n",
      "----------------\n",
      "Frame:40400 Action 3 Loss: 0.00019 Reward: 0.0 Epsilon: 0.96364\n",
      "Done with episode 225 in 40461 frames\n",
      "Loss: 0.006983975414186716 Episode total reward: 2.0 Predicted Qs: 0.001824862090870738\n",
      "Actions chosen counts:  {0: 62, 1: 50, 2: 39, 3: 59}\n",
      "----------------\n",
      "Frame:40600 Action 1 Loss: 4e-05 Reward: 0.0 Epsilon: 0.96346\n",
      "Done with episode 226 in 40619 frames\n",
      "Loss: 0.0045044319704174995 Episode total reward: 1.0 Predicted Qs: 0.0011940626427531242\n",
      "Actions chosen counts:  {0: 44, 1: 36, 2: 38, 3: 40}\n",
      "----------------\n",
      "Frame:40800 Action 1 Loss: 0.00014 Reward: 0.0 Epsilon: 0.96328\n",
      "Done with episode 227 in 40848 frames\n",
      "Loss: 0.003187979571521282 Episode total reward: 3.0 Predicted Qs: 0.0013992248568683863\n",
      "Actions chosen counts:  {0: 46, 1: 71, 2: 57, 3: 55}\n",
      "----------------\n",
      "Done with episode 228 in 40983 frames\n",
      "Loss: 0.008190212771296501 Episode total reward: 0.0 Predicted Qs: 0.0012676530750468373\n",
      "Actions chosen counts:  {0: 45, 1: 26, 2: 33, 3: 31}\n",
      "----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:41000 Action 1 Loss: 0.00018 Reward: 0.0 Epsilon: 0.9631\n",
      "Done with episode 229 in 41121 frames\n",
      "Loss: 0.0015095917042344809 Episode total reward: 0.0 Predicted Qs: 0.0012759410310536623\n",
      "Actions chosen counts:  {0: 42, 1: 28, 2: 34, 3: 34}\n",
      "----------------\n",
      "Frame:41200 Action 1 Loss: 0.00031 Reward: 0.0 Epsilon: 0.96292\n",
      "Done with episode 230 in 41253 frames\n",
      "Loss: 0.01254010759294033 Episode total reward: 0.0 Predicted Qs: 0.0009926460916176438\n",
      "Actions chosen counts:  {0: 43, 1: 31, 2: 31, 3: 27}\n",
      "----------------\n",
      "Frame:41400 Action 2 Loss: 0.00103 Reward: 0.0 Epsilon: 0.96274\n",
      "Done with episode 231 in 41549 frames\n",
      "Loss: 0.011318364180624485 Episode total reward: 4.0 Predicted Qs: 0.0013479525223374367\n",
      "Actions chosen counts:  {0: 73, 1: 70, 2: 71, 3: 82}\n",
      "----------------\n",
      "Frame:41600 Action 3 Loss: 0.00019 Reward: 0.0 Epsilon: 0.96256\n",
      "Done with episode 232 in 41733 frames\n",
      "Loss: 0.0024012180510908365 Episode total reward: 1.0 Predicted Qs: 0.0008783664088696241\n",
      "Actions chosen counts:  {0: 54, 1: 42, 2: 46, 3: 42}\n",
      "----------------\n",
      "Frame:41800 Action 3 Loss: 8e-05 Reward: 0.0 Epsilon: 0.96238\n",
      "Done with episode 233 in 41870 frames\n",
      "Loss: 0.0064115459099411964 Episode total reward: 0.0 Predicted Qs: 0.0012766511645168066\n",
      "Actions chosen counts:  {0: 33, 1: 34, 2: 35, 3: 35}\n",
      "----------------\n",
      "Frame:42000 Action 1 Loss: 6e-05 Reward: 0.0 Epsilon: 0.9621999999999999\n",
      "Done with episode 234 in 42003 frames\n",
      "Loss: 0.004634547512978315 Episode total reward: 0.0 Predicted Qs: 0.0013191166799515486\n",
      "Actions chosen counts:  {0: 44, 1: 31, 2: 29, 3: 29}\n",
      "----------------\n",
      "Done with episode 235 in 42180 frames\n",
      "Loss: 0.011143882758915424 Episode total reward: 1.0 Predicted Qs: 0.0014947055606171489\n",
      "Actions chosen counts:  {0: 35, 1: 50, 2: 52, 3: 40}\n",
      "----------------\n",
      "Frame:42200 Action 1 Loss: 4e-05 Reward: 0.0 Epsilon: 0.96202\n",
      "Done with episode 236 in 42317 frames\n",
      "Loss: 0.013976792804896832 Episode total reward: 0.0 Predicted Qs: 0.0014672190882265568\n",
      "Actions chosen counts:  {0: 37, 1: 32, 2: 32, 3: 36}\n",
      "----------------\n",
      "Frame:42400 Action 0 Loss: 6e-05 Reward: 0.0 Epsilon: 0.96184\n",
      "Done with episode 237 in 42453 frames\n",
      "Loss: 0.013274777680635452 Episode total reward: 0.0 Predicted Qs: 0.0012019439600408077\n",
      "Actions chosen counts:  {0: 33, 1: 41, 2: 33, 3: 29}\n",
      "----------------\n",
      "Done with episode 238 in 42598 frames\n",
      "Loss: 0.004669716581702232 Episode total reward: 0.0 Predicted Qs: 0.0012079074513167143\n",
      "Actions chosen counts:  {0: 45, 1: 36, 2: 28, 3: 36}\n",
      "----------------\n",
      "Frame:42600 Action 2 Loss: 7e-05 Reward: 0.0 Epsilon: 0.9616600000000001\n",
      "Done with episode 239 in 42728 frames\n",
      "Loss: 0.0027573113329708576 Episode total reward: 0.0 Predicted Qs: 0.0014481254620477557\n",
      "Actions chosen counts:  {0: 40, 1: 27, 2: 29, 3: 34}\n",
      "----------------\n",
      "Frame:42800 Action 2 Loss: 0.00038 Reward: 0.0 Epsilon: 0.96148\n",
      "Done with episode 240 in 42892 frames\n",
      "Loss: 0.009833775460720062 Episode total reward: 0.0 Predicted Qs: 0.0014118854887783527\n",
      "Actions chosen counts:  {0: 48, 1: 33, 2: 41, 3: 42}\n",
      "----------------\n",
      "Frame:43000 Action 0 Loss: 0.00056 Reward: 0.0 Epsilon: 0.9612999999999999\n",
      "Done with episode 241 in 43076 frames\n",
      "Loss: 0.004622429143637419 Episode total reward: 1.0 Predicted Qs: 0.0012977018486708403\n",
      "Actions chosen counts:  {0: 47, 1: 40, 2: 46, 3: 51}\n",
      "----------------\n",
      "Frame:43200 Action 3 Loss: 3e-05 Reward: 0.0 Epsilon: 0.96112\n",
      "Done with episode 242 in 43240 frames\n",
      "Loss: 0.011336203664541245 Episode total reward: 1.0 Predicted Qs: 0.0013983824755996466\n",
      "Actions chosen counts:  {0: 47, 1: 37, 2: 38, 3: 42}\n",
      "----------------\n",
      "Frame:43400 Action 1 Loss: 6e-05 Reward: 0.0 Epsilon: 0.96094\n",
      "Done with episode 243 in 43513 frames\n",
      "Loss: 0.003120258217677474 Episode total reward: 3.0 Predicted Qs: 0.0010644217254593968\n",
      "Actions chosen counts:  {0: 80, 1: 63, 2: 67, 3: 63}\n",
      "----------------\n",
      "Frame:43600 Action 3 Loss: 5e-05 Reward: 0.0 Epsilon: 0.9607600000000001\n",
      "Done with episode 244 in 43713 frames\n",
      "Loss: 0.0015895923133939505 Episode total reward: 2.0 Predicted Qs: 0.000897905440069735\n",
      "Actions chosen counts:  {0: 53, 1: 47, 2: 47, 3: 53}\n",
      "----------------\n",
      "Frame:43800 Action 1 Loss: 8e-05 Reward: 0.0 Epsilon: 0.96058\n",
      "Done with episode 245 in 43940 frames\n",
      "Loss: 0.010248670354485512 Episode total reward: 2.0 Predicted Qs: 0.0008794228197075427\n",
      "Actions chosen counts:  {0: 69, 1: 59, 2: 48, 3: 51}\n",
      "----------------\n",
      "Frame:44000 Action 0 Loss: 0.00017 Reward: 0.0 Epsilon: 0.9603999999999999\n",
      "Done with episode 246 in 44075 frames\n",
      "Loss: 0.014873725362122059 Episode total reward: 0.0 Predicted Qs: 0.001298203133046627\n",
      "Actions chosen counts:  {0: 37, 1: 39, 2: 29, 3: 30}\n",
      "----------------\n",
      "Frame:44200 Action 1 Loss: 2e-05 Reward: 0.0 Epsilon: 0.96022\n",
      "Done with episode 247 in 44209 frames\n",
      "Loss: 0.005037589929997921 Episode total reward: 0.0 Predicted Qs: 0.001312341308221221\n",
      "Actions chosen counts:  {0: 27, 1: 35, 2: 43, 3: 29}\n",
      "----------------\n",
      "Done with episode 248 in 44346 frames\n",
      "Loss: 0.007641981355845928 Episode total reward: 0.0 Predicted Qs: 0.0017223013564944267\n",
      "Actions chosen counts:  {0: 41, 1: 27, 2: 37, 3: 32}\n",
      "----------------\n",
      "Frame:44400 Action 0 Loss: 0.00012 Reward: 0.0 Epsilon: 0.96004\n",
      "Done with episode 249 in 44569 frames\n",
      "Loss: 0.01738268882036209 Episode total reward: 2.0 Predicted Qs: 0.00135725864674896\n",
      "Actions chosen counts:  {0: 69, 1: 56, 2: 48, 3: 50}\n",
      "----------------\n",
      "Frame:44600 Action 3 Loss: 0.00023 Reward: 0.0 Epsilon: 0.95986\n",
      "Done with episode 250 in 44798 frames\n",
      "Loss: 0.0027371589094400406 Episode total reward: 2.0 Predicted Qs: 0.0018585305660963058\n",
      "Actions chosen counts:  {0: 48, 1: 71, 2: 57, 3: 53}\n",
      "----------------\n",
      "Frame:44800 Action 0 Loss: 6e-05 Reward: 0.0 Epsilon: 0.9596800000000001\n",
      "Done with episode 251 in 44944 frames\n",
      "Loss: 0.0010073741432279348 Episode total reward: 0.0 Predicted Qs: 0.0015149358659982681\n",
      "Actions chosen counts:  {0: 48, 1: 34, 2: 36, 3: 28}\n",
      "----------------\n",
      "Frame:45000 Action 1 Loss: 0.00011 Reward: 0.0 Epsilon: 0.9594999999999999\n",
      "Done with episode 252 in 45118 frames\n",
      "Loss: 0.002326575107872486 Episode total reward: 1.0 Predicted Qs: 0.001478045480325818\n",
      "Actions chosen counts:  {0: 34, 1: 50, 2: 44, 3: 46}\n",
      "----------------\n",
      "Frame:45200 Action 0 Loss: 5e-05 Reward: 0.0 Epsilon: 0.95932\n",
      "Done with episode 253 in 45259 frames\n",
      "Loss: 0.010456583462655544 Episode total reward: 0.0 Predicted Qs: 0.001366223907098174\n",
      "Actions chosen counts:  {0: 36, 1: 37, 2: 38, 3: 30}\n",
      "----------------\n",
      "Frame:45400 Action 1 Loss: 0.00074 Reward: 0.0 Epsilon: 0.95914\n",
      "Done with episode 254 in 45425 frames\n",
      "Loss: 0.005738329607993364 Episode total reward: 1.0 Predicted Qs: 0.0010141939856112003\n",
      "Actions chosen counts:  {0: 37, 1: 38, 2: 50, 3: 41}\n",
      "----------------\n",
      "Frame:45600 Action 2 Loss: 0.00026 Reward: 0.0 Epsilon: 0.95896\n",
      "Done with episode 255 in 45637 frames\n",
      "Loss: 0.004766065161675215 Episode total reward: 2.0 Predicted Qs: 0.001098773442208767\n",
      "Actions chosen counts:  {0: 56, 1: 62, 2: 45, 3: 49}\n",
      "----------------\n",
      "Done with episode 256 in 45770 frames\n",
      "Loss: 0.003795401891693473 Episode total reward: 0.0 Predicted Qs: 0.0009458609856665134\n",
      "Actions chosen counts:  {0: 29, 1: 30, 2: 41, 3: 33}\n",
      "----------------\n",
      "Frame:45800 Action 3 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9587800000000001\n",
      "Frame:46000 Action 3 Loss: 3e-05 Reward: 0.0 Epsilon: 0.9586\n",
      "Done with episode 257 in 46041 frames\n",
      "Loss: 0.011581405065953732 Episode total reward: 3.0 Predicted Qs: 0.0013017936144024134\n",
      "Actions chosen counts:  {0: 80, 1: 62, 2: 67, 3: 62}\n",
      "----------------\n",
      "Frame:46200 Action 2 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9584199999999999\n",
      "Done with episode 258 in 46203 frames\n",
      "Loss: 0.006735959555953741 Episode total reward: 1.0 Predicted Qs: 0.0010100225917994976\n",
      "Actions chosen counts:  {0: 38, 1: 45, 2: 32, 3: 47}\n",
      "----------------\n",
      "Done with episode 259 in 46345 frames\n",
      "Loss: 0.0071696266531944275 Episode total reward: 0.0 Predicted Qs: 0.0007663320284336805\n",
      "Actions chosen counts:  {0: 42, 1: 35, 2: 36, 3: 29}\n",
      "----------------\n",
      "Frame:46400 Action 3 Loss: 0.00056 Reward: 0.0 Epsilon: 0.95824\n",
      "Done with episode 260 in 46549 frames\n",
      "Loss: 0.005295636132359505 Episode total reward: 2.0 Predicted Qs: 0.00092825957108289\n",
      "Actions chosen counts:  {0: 55, 1: 53, 2: 50, 3: 46}\n",
      "----------------\n",
      "Frame:46600 Action 3 Loss: 5e-05 Reward: 0.0 Epsilon: 0.95806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:46800 Action 0 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9578800000000001\n",
      "Done with episode 261 in 46848 frames\n",
      "Loss: 0.0019427418010309339 Episode total reward: 4.0 Predicted Qs: 0.0008339450578205287\n",
      "Actions chosen counts:  {0: 84, 1: 72, 2: 78, 3: 65}\n",
      "----------------\n",
      "Done with episode 262 in 46984 frames\n",
      "Loss: 0.0010005685035139322 Episode total reward: 0.0 Predicted Qs: 0.0008961328421719372\n",
      "Actions chosen counts:  {0: 41, 1: 38, 2: 30, 3: 27}\n",
      "----------------\n",
      "Frame:47000 Action 1 Loss: 0.00014 Reward: 0.0 Epsilon: 0.9577\n",
      "Done with episode 263 in 47170 frames\n",
      "Loss: 0.008509129285812378 Episode total reward: 1.0 Predicted Qs: 0.000991859007626772\n",
      "Actions chosen counts:  {0: 51, 1: 39, 2: 52, 3: 44}\n",
      "----------------\n",
      "Frame:47200 Action 2 Loss: 9e-05 Reward: 0.0 Epsilon: 0.9575199999999999\n",
      "Done with episode 264 in 47383 frames\n",
      "Loss: 0.000986473518423736 Episode total reward: 2.0 Predicted Qs: 0.0006187913240864873\n",
      "Actions chosen counts:  {0: 64, 1: 55, 2: 48, 3: 46}\n",
      "----------------\n",
      "Frame:47400 Action 3 Loss: 0.00032 Reward: 0.0 Epsilon: 0.95734\n",
      "Done with episode 265 in 47592 frames\n",
      "Loss: 0.009548604488372803 Episode total reward: 2.0 Predicted Qs: 0.0008570703794248402\n",
      "Actions chosen counts:  {0: 53, 1: 51, 2: 46, 3: 59}\n",
      "----------------\n",
      "Frame:47600 Action 2 Loss: 9e-05 Reward: 0.0 Epsilon: 0.95716\n",
      "Done with episode 266 in 47783 frames\n",
      "Loss: 0.004283897113054991 Episode total reward: 1.0 Predicted Qs: 0.0006034059915691614\n",
      "Actions chosen counts:  {0: 45, 1: 39, 2: 56, 3: 51}\n",
      "----------------\n",
      "Frame:47800 Action 3 Loss: 2e-05 Reward: 0.0 Epsilon: 0.95698\n",
      "Done with episode 267 in 47911 frames\n",
      "Loss: 0.000896961020771414 Episode total reward: 0.0 Predicted Qs: 0.0002764721866697073\n",
      "Actions chosen counts:  {0: 33, 1: 33, 2: 34, 3: 28}\n",
      "----------------\n",
      "Frame:48000 Action 3 Loss: 8e-05 Reward: 0.0 Epsilon: 0.9568\n",
      "Done with episode 268 in 48094 frames\n",
      "Loss: 0.015585292130708694 Episode total reward: 1.0 Predicted Qs: 0.0005997885600663722\n",
      "Actions chosen counts:  {0: 49, 1: 46, 2: 46, 3: 42}\n",
      "----------------\n",
      "Frame:48200 Action 3 Loss: 0.00012 Reward: 0.0 Epsilon: 0.95662\n",
      "Done with episode 269 in 48233 frames\n",
      "Loss: 0.006817087065428495 Episode total reward: 0.0 Predicted Qs: 0.0008023416739888489\n",
      "Actions chosen counts:  {0: 36, 1: 39, 2: 34, 3: 30}\n",
      "----------------\n",
      "Frame:48400 Action 0 Loss: 0.00015 Reward: 0.0 Epsilon: 0.95644\n",
      "Done with episode 270 in 48432 frames\n",
      "Loss: 0.0037670517340302467 Episode total reward: 2.0 Predicted Qs: 0.000559168285690248\n",
      "Actions chosen counts:  {0: 60, 1: 41, 2: 42, 3: 56}\n",
      "----------------\n",
      "Done with episode 271 in 48572 frames\n",
      "Loss: 0.0011945614824071527 Episode total reward: 0.0 Predicted Qs: 0.0010963084641844034\n",
      "Actions chosen counts:  {0: 43, 1: 28, 2: 32, 3: 37}\n",
      "----------------\n",
      "Frame:48600 Action 2 Loss: 0.0007 Reward: 0.0 Epsilon: 0.95626\n",
      "Done with episode 272 in 48698 frames\n",
      "Loss: 0.0025705904699862003 Episode total reward: 0.0 Predicted Qs: 0.000544223003089428\n",
      "Actions chosen counts:  {0: 40, 1: 27, 2: 32, 3: 27}\n",
      "----------------\n",
      "Frame:48800 Action 1 Loss: 0.00027 Reward: 0.0 Epsilon: 0.95608\n",
      "Done with episode 273 in 48842 frames\n",
      "Loss: 0.0021290709264576435 Episode total reward: 0.0 Predicted Qs: 0.0006599445478059351\n",
      "Actions chosen counts:  {0: 43, 1: 31, 2: 33, 3: 37}\n",
      "----------------\n",
      "Frame:49000 Action 1 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9559\n",
      "Done with episode 274 in 49054 frames\n",
      "Loss: 0.006384578999131918 Episode total reward: 2.0 Predicted Qs: 0.0006373967044055462\n",
      "Actions chosen counts:  {0: 66, 1: 55, 2: 47, 3: 44}\n",
      "----------------\n",
      "Frame:49200 Action 0 Loss: 1e-05 Reward: 0.0 Epsilon: 0.95572\n",
      "Done with episode 275 in 49245 frames\n",
      "Loss: 0.005469892174005508 Episode total reward: 1.0 Predicted Qs: 0.0007253345684148371\n",
      "Actions chosen counts:  {0: 65, 1: 38, 2: 44, 3: 44}\n",
      "----------------\n",
      "Frame:49400 Action 0 Loss: 0.00017 Reward: 0.0 Epsilon: 0.95554\n",
      "Done with episode 276 in 49410 frames\n",
      "Loss: 0.0064218901097774506 Episode total reward: 1.0 Predicted Qs: 0.0009853148367255926\n",
      "Actions chosen counts:  {0: 53, 1: 43, 2: 36, 3: 33}\n",
      "----------------\n",
      "Done with episode 277 in 49588 frames\n",
      "Loss: 0.000827295589260757 Episode total reward: 1.0 Predicted Qs: 0.0006077850121073425\n",
      "Actions chosen counts:  {0: 54, 1: 41, 2: 44, 3: 39}\n",
      "----------------\n",
      "Frame:49600 Action 0 Loss: 3e-05 Reward: 0.0 Epsilon: 0.95536\n",
      "Done with episode 278 in 49800 frames\n",
      "Loss: 0.01082080602645874 Episode total reward: 2.0 Predicted Qs: 0.0007287197513505816\n",
      "Actions chosen counts:  {0: 71, 1: 47, 2: 49, 3: 45}\n",
      "----------------\n",
      "Frame:49800 Action 2 Loss: 0.00031 Reward: 0.0 Epsilon: 0.95518\n",
      "Frame:50000 Action 0 Loss: 6e-05 Reward: 0.0 Epsilon: 0.955\n",
      "Done with episode 279 in 50018 frames\n",
      "Loss: 0.0006417215918190777 Episode total reward: 2.0 Predicted Qs: 0.0006764787249267101\n",
      "Actions chosen counts:  {0: 57, 1: 41, 2: 67, 3: 53}\n",
      "----------------\n",
      "Done with episode 280 in 50158 frames\n",
      "Loss: 0.006763441488146782 Episode total reward: 0.0 Predicted Qs: 0.0009170180419459939\n",
      "Actions chosen counts:  {0: 45, 1: 43, 2: 22, 3: 30}\n",
      "----------------\n",
      "Frame:50200 Action 0 Loss: 5e-05 Reward: 0.0 Epsilon: 0.95482\n",
      "Done with episode 281 in 50379 frames\n",
      "Loss: 0.0028596639167517424 Episode total reward: 2.0 Predicted Qs: 0.0009118395973928273\n",
      "Actions chosen counts:  {0: 79, 1: 47, 2: 53, 3: 42}\n",
      "----------------\n",
      "Frame:50400 Action 1 Loss: 0.00016 Reward: 0.0 Epsilon: 0.95464\n",
      "Done with episode 282 in 50557 frames\n",
      "Loss: 0.0016645307186990976 Episode total reward: 1.0 Predicted Qs: 0.0007206437294371426\n",
      "Actions chosen counts:  {0: 57, 1: 37, 2: 36, 3: 48}\n",
      "----------------\n",
      "Frame:50600 Action 0 Loss: 0.0001 Reward: 0.0 Epsilon: 0.95446\n",
      "Done with episode 283 in 50691 frames\n",
      "Loss: 0.0024028506595641375 Episode total reward: 0.0 Predicted Qs: 0.0007750137592665851\n",
      "Actions chosen counts:  {0: 43, 1: 33, 2: 33, 3: 25}\n",
      "----------------\n",
      "Frame:50800 Action 2 Loss: 4e-05 Reward: 0.0 Epsilon: 0.95428\n",
      "Done with episode 284 in 50974 frames\n",
      "Loss: 0.0054423632100224495 Episode total reward: 3.0 Predicted Qs: 0.0008241088944487274\n",
      "Actions chosen counts:  {0: 75, 1: 75, 2: 75, 3: 58}\n",
      "----------------\n",
      "Frame:51000 Action 2 Loss: 5e-05 Reward: 0.0 Epsilon: 0.9541\n",
      "Done with episode 285 in 51126 frames\n",
      "Loss: 0.00685412622988224 Episode total reward: 0.0 Predicted Qs: 0.0009453604579903185\n",
      "Actions chosen counts:  {0: 49, 1: 33, 2: 35, 3: 35}\n",
      "----------------\n",
      "Frame:51200 Action 0 Loss: 0.00019 Reward: 0.0 Epsilon: 0.95392\n",
      "Done with episode 286 in 51265 frames\n",
      "Loss: 0.006086782086640596 Episode total reward: 0.0 Predicted Qs: 0.00082902837311849\n",
      "Actions chosen counts:  {0: 30, 1: 26, 2: 41, 3: 42}\n",
      "----------------\n",
      "Frame:51400 Action 0 Loss: 0.00017 Reward: 0.0 Epsilon: 0.95374\n",
      "Done with episode 287 in 51472 frames\n",
      "Loss: 0.005688817705959082 Episode total reward: 2.0 Predicted Qs: 0.0012028049677610397\n",
      "Actions chosen counts:  {0: 46, 1: 57, 2: 55, 3: 49}\n",
      "----------------\n",
      "Frame:51600 Action 0 Loss: 7e-05 Reward: 0.0 Epsilon: 0.95356\n",
      "Done with episode 288 in 51728 frames\n",
      "Loss: 0.0035136383958160877 Episode total reward: 3.0 Predicted Qs: 0.0008278529276140034\n",
      "Actions chosen counts:  {0: 71, 1: 57, 2: 63, 3: 65}\n",
      "----------------\n",
      "Frame:51800 Action 0 Loss: 0.00011 Reward: 0.0 Epsilon: 0.95338\n",
      "Done with episode 289 in 51878 frames\n",
      "Loss: 0.0037010039668530226 Episode total reward: 0.0 Predicted Qs: 0.001073164981789887\n",
      "Actions chosen counts:  {0: 44, 1: 38, 2: 32, 3: 36}\n",
      "----------------\n",
      "Frame:52000 Action 2 Loss: 4e-05 Reward: 0.0 Epsilon: 0.9531999999999999\n",
      "Done with episode 290 in 52031 frames\n",
      "Loss: 0.002472933614626527 Episode total reward: 0.0 Predicted Qs: 0.0006648723501712084\n",
      "Actions chosen counts:  {0: 50, 1: 31, 2: 35, 3: 37}\n",
      "----------------\n",
      "Frame:52200 Action 1 Loss: 1e-05 Reward: 0.0 Epsilon: 0.95302\n",
      "Done with episode 291 in 52219 frames\n",
      "Loss: 0.0007416668813675642 Episode total reward: 1.0 Predicted Qs: 0.0003543096245266497\n",
      "Actions chosen counts:  {0: 50, 1: 51, 2: 40, 3: 47}\n",
      "----------------\n",
      "Done with episode 292 in 52389 frames\n",
      "Loss: 0.005363973788917065 Episode total reward: 1.0 Predicted Qs: 0.0006535188294947147\n",
      "Actions chosen counts:  {0: 44, 1: 44, 2: 39, 3: 43}\n",
      "----------------\n",
      "Frame:52400 Action 2 Loss: 6e-05 Reward: 0.0 Epsilon: 0.95284\n",
      "Done with episode 293 in 52528 frames\n",
      "Loss: 0.008752532303333282 Episode total reward: 0.0 Predicted Qs: 0.00036941608414053917\n",
      "Actions chosen counts:  {0: 44, 1: 30, 2: 32, 3: 33}\n",
      "----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:52600 Action 1 Loss: 0.0004 Reward: 0.0 Epsilon: 0.9526600000000001\n",
      "Done with episode 294 in 52731 frames\n",
      "Loss: 0.01003993209451437 Episode total reward: 2.0 Predicted Qs: 0.0007022191421128809\n",
      "Actions chosen counts:  {0: 42, 1: 55, 2: 54, 3: 52}\n",
      "----------------\n",
      "Frame:52800 Action 1 Loss: 4e-05 Reward: 0.0 Epsilon: 0.95248\n",
      "Done with episode 295 in 52889 frames\n",
      "Loss: 0.006224846933037043 Episode total reward: 1.0 Predicted Qs: 0.0011873978655785322\n",
      "Actions chosen counts:  {0: 45, 1: 35, 2: 40, 3: 38}\n",
      "----------------\n",
      "Frame:53000 Action 2 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9522999999999999\n",
      "Done with episode 296 in 53068 frames\n",
      "Loss: 0.0008681528270244598 Episode total reward: 0.0 Predicted Qs: 0.00044978794176131487\n",
      "Actions chosen counts:  {0: 48, 1: 33, 2: 48, 3: 50}\n",
      "----------------\n",
      "Frame:53200 Action 0 Loss: 8e-05 Reward: 0.0 Epsilon: 0.95212\n",
      "Done with episode 297 in 53206 frames\n",
      "Loss: 0.0008021497051231563 Episode total reward: 0.0 Predicted Qs: 0.00041226332541555166\n",
      "Actions chosen counts:  {0: 46, 1: 30, 2: 35, 3: 27}\n",
      "----------------\n",
      "Done with episode 298 in 53335 frames\n",
      "Loss: 0.0015887898625805974 Episode total reward: 0.0 Predicted Qs: 0.00043509312672540545\n",
      "Actions chosen counts:  {0: 35, 1: 36, 2: 28, 3: 30}\n",
      "----------------\n",
      "Frame:53400 Action 2 Loss: 8e-05 Reward: 0.0 Epsilon: 0.95194\n",
      "Done with episode 299 in 53540 frames\n",
      "Loss: 0.0014396366896107793 Episode total reward: 2.0 Predicted Qs: 0.00042882957495748997\n",
      "Actions chosen counts:  {0: 49, 1: 55, 2: 54, 3: 47}\n",
      "----------------\n",
      "Frame:53600 Action 0 Loss: 8e-05 Reward: 0.0 Epsilon: 0.95176\n",
      "Done with episode 300 in 53687 frames\n",
      "Loss: 0.00410428736358881 Episode total reward: 0.0 Predicted Qs: 0.0010205331491306424\n",
      "Actions chosen counts:  {0: 48, 1: 38, 2: 34, 3: 27}\n",
      "----------------\n",
      "Frame:53800 Action 0 Loss: 0.00012 Reward: 0.0 Epsilon: 0.95158\n",
      "Done with episode 301 in 53917 frames\n",
      "Loss: 0.002556252758949995 Episode total reward: 3.0 Predicted Qs: 0.0004570259479805827\n",
      "Actions chosen counts:  {0: 84, 1: 45, 2: 53, 3: 48}\n",
      "----------------\n",
      "Frame:54000 Action 0 Loss: 3e-05 Reward: 0.0 Epsilon: 0.9513999999999999\n",
      "Done with episode 302 in 54088 frames\n",
      "Loss: 0.001640121452510357 Episode total reward: 1.0 Predicted Qs: 0.00037037197034806013\n",
      "Actions chosen counts:  {0: 50, 1: 37, 2: 44, 3: 40}\n",
      "----------------\n",
      "Frame:54200 Action 1 Loss: 0.0001 Reward: 0.0 Epsilon: 0.95122\n",
      "Done with episode 303 in 54237 frames\n",
      "Loss: 0.0005160094588063657 Episode total reward: 0.0 Predicted Qs: 0.00037302536657080054\n",
      "Actions chosen counts:  {0: 41, 1: 34, 2: 40, 3: 34}\n",
      "----------------\n",
      "Done with episode 304 in 54397 frames\n",
      "Loss: 0.0056841690093278885 Episode total reward: 1.0 Predicted Qs: 0.000686654937453568\n",
      "Actions chosen counts:  {0: 39, 1: 44, 2: 38, 3: 39}\n",
      "----------------\n",
      "Frame:54400 Action 3 Loss: 4e-05 Reward: 0.0 Epsilon: 0.95104\n",
      "Done with episode 305 in 54533 frames\n",
      "Loss: 0.0004190510662738234 Episode total reward: 0.0 Predicted Qs: 0.0002577566774562001\n",
      "Actions chosen counts:  {0: 36, 1: 29, 2: 31, 3: 40}\n",
      "----------------\n",
      "Frame:54600 Action 0 Loss: 6e-05 Reward: 0.0 Epsilon: 0.95086\n",
      "Done with episode 306 in 54669 frames\n",
      "Loss: 0.01691758818924427 Episode total reward: 0.0 Predicted Qs: 0.0003272803733125329\n",
      "Actions chosen counts:  {0: 30, 1: 45, 2: 33, 3: 28}\n",
      "----------------\n",
      "Frame:54800 Action 2 Loss: 7e-05 Reward: 0.0 Epsilon: 0.9506800000000001\n",
      "Done with episode 307 in 54900 frames\n",
      "Loss: 0.0005678230081684887 Episode total reward: 3.0 Predicted Qs: 0.0004432119894772768\n",
      "Actions chosen counts:  {0: 57, 1: 67, 2: 59, 3: 48}\n",
      "----------------\n",
      "Frame:55000 Action 1 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9504999999999999\n",
      "Done with episode 308 in 55146 frames\n",
      "Loss: 0.015848489478230476 Episode total reward: 3.0 Predicted Qs: 0.0010958337225019932\n",
      "Actions chosen counts:  {0: 72, 1: 57, 2: 55, 3: 62}\n",
      "----------------\n",
      "Frame:55200 Action 1 Loss: 4e-05 Reward: 0.0 Epsilon: 0.9503199999999999\n",
      "Done with episode 309 in 55352 frames\n",
      "Loss: 0.014356655068695545 Episode total reward: 2.0 Predicted Qs: 0.000876090198289603\n",
      "Actions chosen counts:  {0: 68, 1: 49, 2: 43, 3: 46}\n",
      "----------------\n",
      "Frame:55400 Action 0 Loss: 7e-05 Reward: 0.0 Epsilon: 0.95014\n",
      "Done with episode 310 in 55554 frames\n",
      "Loss: 0.015607771463692188 Episode total reward: 2.0 Predicted Qs: 0.001461979583837092\n",
      "Actions chosen counts:  {0: 56, 1: 50, 2: 50, 3: 46}\n",
      "----------------\n",
      "Frame:55600 Action 3 Loss: 2e-05 Reward: 0.0 Epsilon: 0.94996\n",
      "Done with episode 311 in 55725 frames\n",
      "Loss: 0.007302779238671064 Episode total reward: 1.0 Predicted Qs: 0.0015473790699616075\n",
      "Actions chosen counts:  {0: 37, 1: 47, 2: 39, 3: 48}\n",
      "----------------\n",
      "Frame:55800 Action 1 Loss: 4e-05 Reward: 0.0 Epsilon: 0.9497800000000001\n",
      "Done with episode 312 in 55958 frames\n",
      "Loss: 0.011911208741366863 Episode total reward: 2.0 Predicted Qs: 0.0008052712073549628\n",
      "Actions chosen counts:  {0: 72, 1: 57, 2: 48, 3: 56}\n",
      "----------------\n",
      "Frame:56000 Action 2 Loss: 3e-05 Reward: 0.0 Epsilon: 0.9496\n",
      "Done with episode 313 in 56135 frames\n",
      "Loss: 0.0033849833998829126 Episode total reward: 1.0 Predicted Qs: 0.00046469439985230565\n",
      "Actions chosen counts:  {0: 49, 1: 43, 2: 42, 3: 43}\n",
      "----------------\n",
      "Frame:56200 Action 2 Loss: 4e-05 Reward: 0.0 Epsilon: 0.9494199999999999\n",
      "Done with episode 314 in 56272 frames\n",
      "Loss: 0.013825155794620514 Episode total reward: 0.0 Predicted Qs: 0.0006364691653288901\n",
      "Actions chosen counts:  {0: 41, 1: 36, 2: 30, 3: 30}\n",
      "----------------\n",
      "Frame:56400 Action 0 Loss: 0.0001 Reward: 0.0 Epsilon: 0.94924\n",
      "Done with episode 315 in 56434 frames\n",
      "Loss: 0.004719373770058155 Episode total reward: 1.0 Predicted Qs: 0.0007771606906317174\n",
      "Actions chosen counts:  {0: 48, 1: 36, 2: 33, 3: 45}\n",
      "----------------\n",
      "Frame:56600 Action 1 Loss: 0.00059 Reward: 0.0 Epsilon: 0.94906\n",
      "Done with episode 316 in 56621 frames\n",
      "Loss: 0.009661656804382801 Episode total reward: 1.0 Predicted Qs: 0.0010638391831889749\n",
      "Actions chosen counts:  {0: 50, 1: 55, 2: 39, 3: 43}\n",
      "----------------\n",
      "Frame:56800 Action 2 Loss: 7e-05 Reward: 0.0 Epsilon: 0.9488800000000001\n",
      "Done with episode 317 in 56838 frames\n",
      "Loss: 0.04739931598305702 Episode total reward: 2.0 Predicted Qs: 0.0013180181849747896\n",
      "Actions chosen counts:  {0: 60, 1: 38, 2: 71, 3: 48}\n",
      "----------------\n",
      "Done with episode 318 in 56968 frames\n",
      "Loss: 0.0011330844135954976 Episode total reward: 0.0 Predicted Qs: 0.0010076360777020454\n",
      "Actions chosen counts:  {0: 37, 1: 35, 2: 31, 3: 27}\n",
      "----------------\n",
      "Frame:57000 Action 3 Loss: 0.00037 Reward: 0.0 Epsilon: 0.9487\n",
      "Done with episode 319 in 57142 frames\n",
      "Loss: 0.0018654970917850733 Episode total reward: 1.0 Predicted Qs: 0.0009181865025311708\n",
      "Actions chosen counts:  {0: 54, 1: 39, 2: 36, 3: 45}\n",
      "----------------\n",
      "Frame:57200 Action 0 Loss: 0.00013 Reward: 0.0 Epsilon: 0.9485199999999999\n",
      "Done with episode 320 in 57276 frames\n",
      "Loss: 0.003268187865614891 Episode total reward: 0.0 Predicted Qs: 0.0007644661818630993\n",
      "Actions chosen counts:  {0: 41, 1: 29, 2: 34, 3: 30}\n",
      "----------------\n",
      "Frame:57400 Action 3 Loss: 0.00111 Reward: 0.0 Epsilon: 0.94834\n",
      "Done with episode 321 in 57409 frames\n",
      "Loss: 0.0376303531229496 Episode total reward: 0.0 Predicted Qs: 0.0011150186182931066\n",
      "Actions chosen counts:  {0: 34, 1: 42, 2: 28, 3: 29}\n",
      "----------------\n",
      "Frame:57600 Action 1 Loss: 3e-05 Reward: 0.0 Epsilon: 0.94816\n",
      "Done with episode 322 in 57726 frames\n",
      "Loss: 0.010530121624469757 Episode total reward: 5.0 Predicted Qs: 0.0016546508995816112\n",
      "Actions chosen counts:  {0: 92, 1: 71, 2: 70, 3: 84}\n",
      "----------------\n",
      "Frame:57800 Action 2 Loss: 0.00026 Reward: 0.0 Epsilon: 0.94798\n",
      "Done with episode 323 in 57873 frames\n",
      "Loss: 0.012725265696644783 Episode total reward: 0.0 Predicted Qs: 0.00117987219709903\n",
      "Actions chosen counts:  {0: 43, 1: 40, 2: 32, 3: 32}\n",
      "----------------\n",
      "Frame:58000 Action 0 Loss: 0.00011 Reward: 0.0 Epsilon: 0.9478\n",
      "Done with episode 324 in 58087 frames\n",
      "Loss: 0.013020273298025131 Episode total reward: 2.0 Predicted Qs: 0.0012305853888392448\n",
      "Actions chosen counts:  {0: 67, 1: 47, 2: 60, 3: 40}\n",
      "----------------\n",
      "Frame:58200 Action 2 Loss: 0.00047 Reward: 0.0 Epsilon: 0.94762\n",
      "Done with episode 325 in 58240 frames\n",
      "Loss: 0.007049060892313719 Episode total reward: 0.0 Predicted Qs: 0.0009880494326353073\n",
      "Actions chosen counts:  {0: 47, 1: 26, 2: 41, 3: 39}\n",
      "----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with episode 326 in 58372 frames\n",
      "Loss: 0.03896394744515419 Episode total reward: 0.0 Predicted Qs: 0.0012638140469789505\n",
      "Actions chosen counts:  {0: 37, 1: 32, 2: 33, 3: 30}\n",
      "----------------\n",
      "Frame:58400 Action 0 Loss: 3e-05 Reward: 0.0 Epsilon: 0.94744\n",
      "Done with episode 327 in 58515 frames\n",
      "Loss: 0.01162727177143097 Episode total reward: 0.0 Predicted Qs: 0.0011840250808745623\n",
      "Actions chosen counts:  {0: 48, 1: 35, 2: 31, 3: 29}\n",
      "----------------\n",
      "Frame:58600 Action 0 Loss: 1e-05 Reward: 0.0 Epsilon: 0.94726\n",
      "Done with episode 328 in 58700 frames\n",
      "Loss: 0.002556809224188328 Episode total reward: 1.0 Predicted Qs: 0.0012035054387524724\n",
      "Actions chosen counts:  {0: 67, 1: 44, 2: 36, 3: 38}\n",
      "----------------\n",
      "Frame:58800 Action 3 Loss: 0.0001 Reward: 0.0 Epsilon: 0.94708\n",
      "Done with episode 329 in 58833 frames\n",
      "Loss: 0.00515871262177825 Episode total reward: 0.0 Predicted Qs: 0.000695538183208555\n",
      "Actions chosen counts:  {0: 41, 1: 36, 2: 25, 3: 31}\n",
      "----------------\n",
      "Frame:59000 Action 3 Loss: 3e-05 Reward: 0.0 Epsilon: 0.9469\n",
      "Done with episode 330 in 59053 frames\n",
      "Loss: 0.007626815233379602 Episode total reward: 2.0 Predicted Qs: 0.0005262765334919095\n",
      "Actions chosen counts:  {0: 69, 1: 57, 2: 44, 3: 50}\n",
      "----------------\n",
      "Frame:59200 Action 2 Loss: 3e-05 Reward: 0.0 Epsilon: 0.94672\n",
      "Done with episode 331 in 59297 frames\n",
      "Loss: 0.0046844868920743465 Episode total reward: 3.0 Predicted Qs: 0.00021231960272416472\n",
      "Actions chosen counts:  {0: 67, 1: 70, 2: 44, 3: 63}\n",
      "----------------\n",
      "Frame:59400 Action 1 Loss: 4e-05 Reward: 0.0 Epsilon: 0.9465399999999999\n",
      "Done with episode 332 in 59458 frames\n",
      "Loss: 0.004741098266094923 Episode total reward: 1.0 Predicted Qs: 0.00038830714765936136\n",
      "Actions chosen counts:  {0: 42, 1: 36, 2: 37, 3: 46}\n",
      "----------------\n",
      "Done with episode 333 in 59590 frames\n",
      "Loss: 0.003198412014171481 Episode total reward: 0.0 Predicted Qs: 0.0005028691957704723\n",
      "Actions chosen counts:  {0: 32, 1: 38, 2: 26, 3: 36}\n",
      "----------------\n",
      "Frame:59600 Action 2 Loss: 2e-05 Reward: 0.0 Epsilon: 0.94636\n",
      "Done with episode 334 in 59728 frames\n",
      "Loss: 0.004291866905987263 Episode total reward: 0.0 Predicted Qs: 0.00045259902253746986\n",
      "Actions chosen counts:  {0: 35, 1: 39, 2: 33, 3: 31}\n",
      "----------------\n",
      "Frame:59800 Action 2 Loss: 2e-05 Reward: 0.0 Epsilon: 0.94618\n",
      "Done with episode 335 in 59871 frames\n",
      "Loss: 0.002330060815438628 Episode total reward: 0.0 Predicted Qs: 0.0004621086991392076\n",
      "Actions chosen counts:  {0: 50, 1: 25, 2: 38, 3: 30}\n",
      "----------------\n",
      "Frame:60000 Action 1 Loss: 0.0001 Reward: 0.0 Epsilon: 0.946\n",
      "Done with episode 336 in 60004 frames\n",
      "Loss: 0.0020405447576195 Episode total reward: 0.0 Predicted Qs: 0.0003979468601755798\n",
      "Actions chosen counts:  {0: 27, 1: 34, 2: 35, 3: 37}\n",
      "----------------\n",
      "Done with episode 337 in 60198 frames\n",
      "Loss: 0.011640411801636219 Episode total reward: 2.0 Predicted Qs: 0.0008266395889222622\n",
      "Actions chosen counts:  {0: 64, 1: 43, 2: 43, 3: 44}\n",
      "----------------\n",
      "Frame:60200 Action 1 Loss: 6e-05 Reward: 0.0 Epsilon: 0.94582\n",
      "Done with episode 338 in 60331 frames\n",
      "Loss: 0.0032446570694446564 Episode total reward: 0.0 Predicted Qs: 0.0003816136159002781\n",
      "Actions chosen counts:  {0: 36, 1: 34, 2: 33, 3: 30}\n",
      "----------------\n",
      "Frame:60400 Action 0 Loss: 3e-05 Reward: 0.0 Epsilon: 0.94564\n",
      "Done with episode 339 in 60505 frames\n",
      "Loss: 0.00393695430830121 Episode total reward: 1.0 Predicted Qs: 0.0005997459520585835\n",
      "Actions chosen counts:  {0: 45, 1: 50, 2: 37, 3: 42}\n",
      "----------------\n",
      "Frame:60600 Action 0 Loss: 7e-05 Reward: 0.0 Epsilon: 0.94546\n",
      "Done with episode 340 in 60726 frames\n",
      "Loss: 0.00993473269045353 Episode total reward: 2.0 Predicted Qs: 0.0007723027956672013\n",
      "Actions chosen counts:  {0: 71, 1: 44, 2: 52, 3: 54}\n",
      "----------------\n",
      "Frame:60800 Action 0 Loss: 0.00028 Reward: 0.0 Epsilon: 0.94528\n",
      "Done with episode 341 in 60907 frames\n",
      "Loss: 0.035996418446302414 Episode total reward: 1.0 Predicted Qs: 0.001050103921443224\n",
      "Actions chosen counts:  {0: 45, 1: 43, 2: 50, 3: 43}\n",
      "----------------\n",
      "Frame:61000 Action 1 Loss: 0.00021 Reward: 0.0 Epsilon: 0.9450999999999999\n",
      "Frame:61200 Action 0 Loss: 0.00043 Reward: 0.0 Epsilon: 0.94492\n",
      "Done with episode 342 in 61202 frames\n",
      "Loss: 0.009131347760558128 Episode total reward: 5.0 Predicted Qs: 0.0004397750017233193\n",
      "Actions chosen counts:  {0: 86, 1: 66, 2: 73, 3: 70}\n",
      "----------------\n",
      "Done with episode 343 in 61335 frames\n",
      "Loss: 0.0005878469091840088 Episode total reward: 0.0 Predicted Qs: 0.00019549054559320211\n",
      "Actions chosen counts:  {0: 40, 1: 34, 2: 29, 3: 30}\n",
      "----------------\n",
      "Frame:61400 Action 3 Loss: 0.00014 Reward: 0.0 Epsilon: 0.94474\n",
      "Done with episode 344 in 61511 frames\n",
      "Loss: 0.029747838154435158 Episode total reward: 1.0 Predicted Qs: 0.0008423836552537978\n",
      "Actions chosen counts:  {0: 45, 1: 46, 2: 39, 3: 46}\n",
      "----------------\n",
      "Frame:61600 Action 1 Loss: 2e-05 Reward: 0.0 Epsilon: 0.94456\n",
      "Done with episode 345 in 61677 frames\n",
      "Loss: 0.0027093663811683655 Episode total reward: 1.0 Predicted Qs: 0.0004175269277766347\n",
      "Actions chosen counts:  {0: 55, 1: 36, 2: 35, 3: 40}\n",
      "----------------\n",
      "Frame:61800 Action 2 Loss: 3e-05 Reward: 0.0 Epsilon: 0.94438\n",
      "Done with episode 346 in 61810 frames\n",
      "Loss: 0.024376600980758667 Episode total reward: 0.0 Predicted Qs: 0.0005959807895123959\n",
      "Actions chosen counts:  {0: 29, 1: 31, 2: 37, 3: 36}\n",
      "----------------\n",
      "Done with episode 347 in 61949 frames\n",
      "Loss: 0.0014031118480488658 Episode total reward: 0.0 Predicted Qs: 0.0003564715734682977\n",
      "Actions chosen counts:  {0: 31, 1: 29, 2: 40, 3: 39}\n",
      "----------------\n",
      "Frame:62000 Action 0 Loss: 3e-05 Reward: 0.0 Epsilon: 0.9441999999999999\n",
      "Frame:62200 Action 0 Loss: 2e-05 Reward: 0.0 Epsilon: 0.94402\n",
      "Done with episode 348 in 62230 frames\n",
      "Loss: 0.010156113654375076 Episode total reward: 3.0 Predicted Qs: 0.0010823486372828484\n",
      "Actions chosen counts:  {0: 78, 1: 50, 2: 79, 3: 74}\n",
      "----------------\n",
      "Frame:62400 Action 0 Loss: 3e-05 Reward: 0.0 Epsilon: 0.94384\n",
      "Done with episode 349 in 62405 frames\n",
      "Loss: 0.0005549566703848541 Episode total reward: 1.0 Predicted Qs: 0.0008180757868103683\n",
      "Actions chosen counts:  {0: 53, 1: 52, 2: 30, 3: 40}\n",
      "----------------\n",
      "Frame:62600 Action 0 Loss: 0.00773 Reward: 0.0 Epsilon: 0.94366\n",
      "Done with episode 350 in 62651 frames\n",
      "Loss: 0.007734821643680334 Episode total reward: 3.0 Predicted Qs: 0.0008333783480338752\n",
      "Actions chosen counts:  {0: 72, 1: 70, 2: 47, 3: 57}\n",
      "----------------\n",
      "Frame:62800 Action 0 Loss: 6e-05 Reward: 0.0 Epsilon: 0.94348\n",
      "Done with episode 351 in 62906 frames\n",
      "Loss: 0.02089204452931881 Episode total reward: 3.0 Predicted Qs: 0.0014252583496272564\n",
      "Actions chosen counts:  {0: 81, 1: 45, 2: 61, 3: 68}\n",
      "----------------\n",
      "Frame:63000 Action 1 Loss: 7e-05 Reward: 0.0 Epsilon: 0.9433\n",
      "Done with episode 352 in 63078 frames\n",
      "Loss: 0.002258134074509144 Episode total reward: 1.0 Predicted Qs: 0.0008200277807191014\n",
      "Actions chosen counts:  {0: 54, 1: 39, 2: 33, 3: 46}\n",
      "----------------\n",
      "Frame:63200 Action 2 Loss: 4e-05 Reward: 0.0 Epsilon: 0.94312\n",
      "Done with episode 353 in 63224 frames\n",
      "Loss: 0.017647024244070053 Episode total reward: 0.0 Predicted Qs: 0.0011627699714154005\n",
      "Actions chosen counts:  {0: 47, 1: 25, 2: 24, 3: 50}\n",
      "----------------\n",
      "Frame:63400 Action 2 Loss: 0.00018 Reward: 0.0 Epsilon: 0.94294\n",
      "Done with episode 354 in 63433 frames\n",
      "Loss: 0.008456521667540073 Episode total reward: 2.0 Predicted Qs: 0.001244464423507452\n",
      "Actions chosen counts:  {0: 59, 1: 43, 2: 60, 3: 47}\n",
      "----------------\n",
      "Done with episode 355 in 63568 frames\n",
      "Loss: 0.0009666688274592161 Episode total reward: 0.0 Predicted Qs: 0.0009823014261201024\n",
      "Actions chosen counts:  {0: 25, 1: 34, 2: 38, 3: 38}\n",
      "----------------\n",
      "Frame:63600 Action 2 Loss: 5e-05 Reward: 0.0 Epsilon: 0.94276\n",
      "Done with episode 356 in 63751 frames\n",
      "Loss: 0.0014359562192112207 Episode total reward: 1.0 Predicted Qs: 0.0010795670095831156\n",
      "Actions chosen counts:  {0: 62, 1: 46, 2: 36, 3: 39}\n",
      "----------------\n",
      "Frame:63800 Action 1 Loss: 3e-05 Reward: 0.0 Epsilon: 0.94258\n",
      "Done with episode 357 in 63934 frames\n",
      "Loss: 0.005251323338598013 Episode total reward: 1.0 Predicted Qs: 0.0007734503014944494\n",
      "Actions chosen counts:  {0: 61, 1: 46, 2: 41, 3: 35}\n",
      "----------------\n",
      "Frame:64000 Action 2 Loss: 0.0001 Reward: 0.0 Epsilon: 0.9424\n",
      "Done with episode 358 in 64119 frames\n",
      "Loss: 0.0014954900834709406 Episode total reward: 1.0 Predicted Qs: 0.0011534799123182893\n",
      "Actions chosen counts:  {0: 54, 1: 44, 2: 47, 3: 40}\n",
      "----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:64200 Action 2 Loss: 4e-05 Reward: 0.0 Epsilon: 0.94222\n",
      "Done with episode 359 in 64267 frames\n",
      "Loss: 0.0010930730495601892 Episode total reward: 0.0 Predicted Qs: 0.0008038284140639007\n",
      "Actions chosen counts:  {0: 46, 1: 33, 2: 40, 3: 29}\n",
      "----------------\n",
      "Frame:64400 Action 0 Loss: 9e-05 Reward: 0.0 Epsilon: 0.94204\n",
      "Done with episode 360 in 64473 frames\n",
      "Loss: 0.0011633025715127587 Episode total reward: 2.0 Predicted Qs: 0.0007287762127816677\n",
      "Actions chosen counts:  {0: 46, 1: 50, 2: 54, 3: 56}\n",
      "----------------\n",
      "Frame:64600 Action 0 Loss: 0.00015 Reward: 0.0 Epsilon: 0.94186\n",
      "Done with episode 361 in 64689 frames\n",
      "Loss: 0.00480561563745141 Episode total reward: 2.0 Predicted Qs: 0.0006643248489126563\n",
      "Actions chosen counts:  {0: 67, 1: 51, 2: 39, 3: 59}\n",
      "----------------\n",
      "Frame:64800 Action 0 Loss: 0.00025 Reward: 0.0 Epsilon: 0.9416800000000001\n",
      "Done with episode 362 in 64839 frames\n",
      "Loss: 0.001851835404522717 Episode total reward: 0.0 Predicted Qs: 0.0005297130555845797\n",
      "Actions chosen counts:  {0: 50, 1: 34, 2: 30, 3: 36}\n",
      "----------------\n",
      "Frame:65000 Action 0 Loss: 0.00017 Reward: 0.0 Epsilon: 0.9415\n",
      "Done with episode 363 in 65023 frames\n",
      "Loss: 0.005811530631035566 Episode total reward: 1.0 Predicted Qs: 0.000924020423553884\n",
      "Actions chosen counts:  {0: 56, 1: 39, 2: 40, 3: 49}\n",
      "----------------\n",
      "Frame:65200 Action 1 Loss: 0.00053 Reward: 0.0 Epsilon: 0.9413199999999999\n",
      "Done with episode 364 in 65219 frames\n",
      "Loss: 0.006176071707159281 Episode total reward: 2.0 Predicted Qs: 0.0011269840179011226\n",
      "Actions chosen counts:  {0: 53, 1: 44, 2: 50, 3: 49}\n",
      "----------------\n",
      "Done with episode 365 in 65372 frames\n",
      "Loss: 0.0018913482781499624 Episode total reward: 0.0 Predicted Qs: 0.0008651632815599442\n",
      "Actions chosen counts:  {0: 46, 1: 28, 2: 45, 3: 34}\n",
      "----------------\n",
      "Frame:65400 Action 1 Loss: 5e-05 Reward: 0.0 Epsilon: 0.94114\n",
      "Done with episode 366 in 65556 frames\n",
      "Loss: 0.0037601906806230545 Episode total reward: 1.0 Predicted Qs: 0.0008232734980992973\n",
      "Actions chosen counts:  {0: 53, 1: 44, 2: 43, 3: 44}\n",
      "----------------\n",
      "Frame:65600 Action 1 Loss: 5e-05 Reward: 0.0 Epsilon: 0.94096\n",
      "Frame:65800 Action 0 Loss: 0.00015 Reward: 0.0 Epsilon: 0.9407800000000001\n",
      "Done with episode 367 in 65867 frames\n",
      "Loss: 0.01567157730460167 Episode total reward: 4.0 Predicted Qs: 0.0010427477536723018\n",
      "Actions chosen counts:  {0: 98, 1: 72, 2: 83, 3: 58}\n",
      "----------------\n",
      "Frame:66000 Action 0 Loss: 4e-05 Reward: 0.0 Epsilon: 0.9406\n",
      "Done with episode 368 in 66027 frames\n",
      "Loss: 0.002160086063668132 Episode total reward: 1.0 Predicted Qs: 0.0007540926453657448\n",
      "Actions chosen counts:  {0: 53, 1: 37, 2: 34, 3: 36}\n",
      "----------------\n",
      "Done with episode 369 in 66159 frames\n",
      "Loss: 0.01887039840221405 Episode total reward: 0.0 Predicted Qs: 0.0007698552799411118\n",
      "Actions chosen counts:  {0: 32, 1: 26, 2: 30, 3: 44}\n",
      "----------------\n",
      "Frame:66200 Action 2 Loss: 0.00028 Reward: 0.0 Epsilon: 0.9404199999999999\n",
      "Done with episode 370 in 66375 frames\n",
      "Loss: 0.01298296358436346 Episode total reward: 2.0 Predicted Qs: 0.0005937971291132271\n",
      "Actions chosen counts:  {0: 67, 1: 46, 2: 52, 3: 51}\n",
      "----------------\n",
      "Frame:66400 Action 1 Loss: 0.01321 Reward: 0.0 Epsilon: 0.94024\n",
      "Done with episode 371 in 66515 frames\n",
      "Loss: 0.013212316669523716 Episode total reward: 0.0 Predicted Qs: 0.0007595854694955051\n",
      "Actions chosen counts:  {0: 36, 1: 39, 2: 32, 3: 33}\n",
      "----------------\n",
      "Frame:66600 Action 3 Loss: 0.00014 Reward: 0.0 Epsilon: 0.94006\n",
      "Done with episode 372 in 66693 frames\n",
      "Loss: 0.00220802566036582 Episode total reward: 1.0 Predicted Qs: 0.0010019508190453053\n",
      "Actions chosen counts:  {0: 51, 1: 34, 2: 47, 3: 46}\n",
      "----------------\n",
      "Frame:66800 Action 3 Loss: 0.0 Reward: 0.0 Epsilon: 0.93988\n",
      "Done with episode 373 in 66953 frames\n",
      "Loss: 0.004257443826645613 Episode total reward: 3.0 Predicted Qs: 0.000716466223821044\n",
      "Actions chosen counts:  {0: 86, 1: 63, 2: 57, 3: 54}\n",
      "----------------\n",
      "Frame:67000 Action 1 Loss: 0.00016 Reward: 0.0 Epsilon: 0.9397000000000001\n",
      "Done with episode 374 in 67080 frames\n",
      "Loss: 0.0032863079104572535 Episode total reward: 0.0 Predicted Qs: 0.0004364266060292721\n",
      "Actions chosen counts:  {0: 43, 1: 25, 2: 29, 3: 30}\n",
      "----------------\n",
      "Frame:67200 Action 3 Loss: 7e-05 Reward: 0.0 Epsilon: 0.9395199999999999\n",
      "Done with episode 375 in 67227 frames\n",
      "Loss: 0.007534208707511425 Episode total reward: 0.0 Predicted Qs: 0.0007434964063577354\n",
      "Actions chosen counts:  {0: 56, 1: 34, 2: 33, 3: 24}\n",
      "----------------\n",
      "Done with episode 376 in 67356 frames\n",
      "Loss: 0.00766163133084774 Episode total reward: 0.0 Predicted Qs: 0.0016136898193508387\n",
      "Actions chosen counts:  {0: 36, 1: 32, 2: 24, 3: 37}\n",
      "----------------\n",
      "Frame:67400 Action 1 Loss: 3e-05 Reward: 0.0 Epsilon: 0.93934\n",
      "Done with episode 377 in 67492 frames\n",
      "Loss: 0.0027683258522301912 Episode total reward: 0.0 Predicted Qs: 0.0008447810541838408\n",
      "Actions chosen counts:  {0: 33, 1: 31, 2: 41, 3: 31}\n",
      "----------------\n",
      "Frame:67600 Action 0 Loss: 1e-05 Reward: 0.0 Epsilon: 0.93916\n",
      "Done with episode 378 in 67671 frames\n",
      "Loss: 0.010380303487181664 Episode total reward: 1.0 Predicted Qs: 0.0014391089789569378\n",
      "Actions chosen counts:  {0: 48, 1: 46, 2: 33, 3: 52}\n",
      "----------------\n",
      "Frame:67800 Action 0 Loss: 3e-05 Reward: 0.0 Epsilon: 0.93898\n",
      "Done with episode 379 in 67814 frames\n",
      "Loss: 0.001659335452131927 Episode total reward: 0.0 Predicted Qs: 0.0008943335269577801\n",
      "Actions chosen counts:  {0: 42, 1: 29, 2: 40, 3: 32}\n",
      "----------------\n",
      "Frame:68000 Action 2 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9388000000000001\n",
      "Done with episode 380 in 68034 frames\n",
      "Loss: 0.007300242315977812 Episode total reward: 2.0 Predicted Qs: 0.0011006060522049665\n",
      "Actions chosen counts:  {0: 61, 1: 46, 2: 51, 3: 62}\n",
      "----------------\n",
      "Frame:68200 Action 0 Loss: 4e-05 Reward: 0.0 Epsilon: 0.93862\n",
      "Done with episode 381 in 68204 frames\n",
      "Loss: 0.002132645808160305 Episode total reward: 1.0 Predicted Qs: 0.0007452339632436633\n",
      "Actions chosen counts:  {0: 54, 1: 38, 2: 31, 3: 47}\n",
      "----------------\n",
      "Done with episode 382 in 68384 frames\n",
      "Loss: 0.0030645381193608046 Episode total reward: 1.0 Predicted Qs: 0.0007194982608780265\n",
      "Actions chosen counts:  {0: 58, 1: 46, 2: 37, 3: 39}\n",
      "----------------\n",
      "Frame:68400 Action 1 Loss: 5e-05 Reward: 0.0 Epsilon: 0.9384399999999999\n",
      "Done with episode 383 in 68595 frames\n",
      "Loss: 0.0019872840493917465 Episode total reward: 2.0 Predicted Qs: 0.0008359569474123418\n",
      "Actions chosen counts:  {0: 65, 1: 51, 2: 45, 3: 50}\n",
      "----------------\n",
      "Frame:68600 Action 0 Loss: 2e-05 Reward: 0.0 Epsilon: 0.93826\n",
      "Done with episode 384 in 68769 frames\n",
      "Loss: 0.0023353209253400564 Episode total reward: 1.0 Predicted Qs: 0.0008322284556925297\n",
      "Actions chosen counts:  {0: 57, 1: 36, 2: 32, 3: 49}\n",
      "----------------\n",
      "Frame:68800 Action 1 Loss: 5e-05 Reward: 0.0 Epsilon: 0.93808\n",
      "Done with episode 385 in 68909 frames\n",
      "Loss: 0.0013238814426586032 Episode total reward: 0.0 Predicted Qs: 0.0006775021320208907\n",
      "Actions chosen counts:  {0: 45, 1: 34, 2: 28, 3: 33}\n",
      "----------------\n",
      "Frame:69000 Action 2 Loss: 0.00014 Reward: 0.0 Epsilon: 0.9379000000000001\n",
      "Done with episode 386 in 69116 frames\n",
      "Loss: 0.002632374409586191 Episode total reward: 2.0 Predicted Qs: 0.0006202133372426033\n",
      "Actions chosen counts:  {0: 47, 1: 49, 2: 60, 3: 51}\n",
      "----------------\n",
      "Frame:69200 Action 1 Loss: 3e-05 Reward: 0.0 Epsilon: 0.93772\n",
      "Done with episode 387 in 69269 frames\n",
      "Loss: 0.0006827154429629445 Episode total reward: 0.0 Predicted Qs: 0.0007218159735202789\n",
      "Actions chosen counts:  {0: 51, 1: 37, 2: 36, 3: 29}\n",
      "----------------\n",
      "Frame:69400 Action 0 Loss: 1e-05 Reward: 0.0 Epsilon: 0.9375399999999999\n",
      "Done with episode 388 in 69514 frames\n",
      "Loss: 0.001911065774038434 Episode total reward: 3.0 Predicted Qs: 0.000649785331916064\n",
      "Actions chosen counts:  {0: 74, 1: 61, 2: 51, 3: 59}\n",
      "----------------\n",
      "Frame:69600 Action 2 Loss: 2e-05 Reward: 0.0 Epsilon: 0.93736\n",
      "Done with episode 389 in 69654 frames\n",
      "Loss: 0.0019612303003668785 Episode total reward: 0.0 Predicted Qs: 0.0006735567003488541\n",
      "Actions chosen counts:  {0: 42, 1: 30, 2: 37, 3: 31}\n",
      "----------------\n",
      "Frame:69800 Action 3 Loss: 2e-05 Reward: 0.0 Epsilon: 0.93718\n",
      "Done with episode 390 in 69891 frames\n",
      "Loss: 0.007201986387372017 Episode total reward: 2.0 Predicted Qs: 0.0009625843958929181\n",
      "Actions chosen counts:  {0: 78, 1: 51, 2: 52, 3: 56}\n",
      "----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:70000 Action 2 Loss: 7e-05 Reward: 0.0 Epsilon: 0.937\n",
      "Done with episode 391 in 70154 frames\n",
      "Loss: 0.008376730605959892 Episode total reward: 3.0 Predicted Qs: 0.0009208431583829224\n",
      "Actions chosen counts:  {0: 76, 1: 66, 2: 57, 3: 64}\n",
      "----------------\n",
      "Frame:70200 Action 1 Loss: 0.0005 Reward: 0.0 Epsilon: 0.93682\n",
      "Done with episode 392 in 70281 frames\n",
      "Loss: 0.0020293467678129673 Episode total reward: 0.0 Predicted Qs: 0.0007661276613362134\n",
      "Actions chosen counts:  {0: 34, 1: 33, 2: 26, 3: 34}\n",
      "----------------\n",
      "Frame:70400 Action 0 Loss: 3e-05 Reward: 0.0 Epsilon: 0.93664\n",
      "Frame:70600 Action 0 Loss: 6e-05 Reward: 0.0 Epsilon: 0.93646\n",
      "Done with episode 393 in 70609 frames\n",
      "Loss: 0.00852672103792429 Episode total reward: 5.0 Predicted Qs: 0.0007811374380253255\n",
      "Actions chosen counts:  {0: 87, 1: 69, 2: 71, 3: 101}\n",
      "----------------\n",
      "Done with episode 394 in 70749 frames\n",
      "Loss: 0.0028972369618713856 Episode total reward: 0.0 Predicted Qs: 0.0009292127215303481\n",
      "Actions chosen counts:  {0: 35, 1: 30, 2: 38, 3: 37}\n",
      "----------------\n",
      "Frame:70800 Action 1 Loss: 3e-05 Reward: 0.0 Epsilon: 0.93628\n",
      "Done with episode 395 in 70878 frames\n",
      "Loss: 0.005822439212352037 Episode total reward: 0.0 Predicted Qs: 0.0005262418417260051\n",
      "Actions chosen counts:  {0: 50, 1: 29, 2: 23, 3: 27}\n",
      "----------------\n",
      "Frame:71000 Action 1 Loss: 4e-05 Reward: 0.0 Epsilon: 0.9361\n",
      "Done with episode 396 in 71085 frames\n",
      "Loss: 0.006259730085730553 Episode total reward: 2.0 Predicted Qs: 0.0011573581723496318\n",
      "Actions chosen counts:  {0: 61, 1: 46, 2: 39, 3: 61}\n",
      "----------------\n",
      "Frame:71200 Action 1 Loss: 0.00019 Reward: 0.0 Epsilon: 0.93592\n",
      "Done with episode 397 in 71230 frames\n",
      "Loss: 0.017552614212036133 Episode total reward: 0.0 Predicted Qs: 0.0007353832479566336\n",
      "Actions chosen counts:  {0: 52, 1: 31, 2: 28, 3: 34}\n",
      "----------------\n",
      "Done with episode 398 in 71391 frames\n",
      "Loss: 0.0023928408045321703 Episode total reward: 1.0 Predicted Qs: 0.0005798913771286607\n",
      "Actions chosen counts:  {0: 47, 1: 35, 2: 35, 3: 44}\n",
      "----------------\n",
      "Frame:71400 Action 1 Loss: 0.00023 Reward: 0.0 Epsilon: 0.93574\n",
      "Done with episode 399 in 71548 frames\n",
      "Loss: 0.004473910667002201 Episode total reward: 0.0 Predicted Qs: 0.0004919419880025089\n",
      "Actions chosen counts:  {0: 39, 1: 36, 2: 52, 3: 30}\n",
      "----------------\n",
      "Frame:71600 Action 2 Loss: 1e-05 Reward: 0.0 Epsilon: 0.93556\n",
      "Done with episode 400 in 71707 frames\n",
      "Loss: 0.0029167893808335066 Episode total reward: 1.0 Predicted Qs: 0.0006214838358573616\n",
      "Actions chosen counts:  {0: 47, 1: 36, 2: 39, 3: 37}\n",
      "----------------\n",
      "Frame:71800 Action 2 Loss: 0.00053 Reward: 0.0 Epsilon: 0.93538\n",
      "Done with episode 401 in 71864 frames\n",
      "Loss: 0.0005334451561793685 Episode total reward: 0.0 Predicted Qs: 0.0005978015251457691\n",
      "Actions chosen counts:  {0: 54, 1: 30, 2: 42, 3: 31}\n",
      "----------------\n",
      "Frame:72000 Action 3 Loss: 0.00325 Reward: 0.0 Epsilon: 0.9352\n",
      "Done with episode 402 in 72043 frames\n",
      "Loss: 0.013149351812899113 Episode total reward: 1.0 Predicted Qs: 0.0008012158796191216\n",
      "Actions chosen counts:  {0: 55, 1: 48, 2: 39, 3: 37}\n",
      "----------------\n",
      "Frame:72200 Action 2 Loss: 3e-05 Reward: 0.0 Epsilon: 0.93502\n",
      "Done with episode 403 in 72317 frames\n",
      "Loss: 0.0013981461524963379 Episode total reward: 3.0 Predicted Qs: 0.0007681341958232224\n",
      "Actions chosen counts:  {0: 74, 1: 62, 2: 74, 3: 64}\n",
      "----------------\n",
      "Frame:72400 Action 1 Loss: 1e-05 Reward: 0.0 Epsilon: 0.93484\n",
      "Done with episode 404 in 72525 frames\n",
      "Loss: 0.003269392531365156 Episode total reward: 2.0 Predicted Qs: 0.0008037727093324065\n",
      "Actions chosen counts:  {0: 63, 1: 51, 2: 49, 3: 45}\n",
      "----------------\n",
      "Frame:72600 Action 0 Loss: 8e-05 Reward: 0.0 Epsilon: 0.93466\n",
      "Done with episode 405 in 72662 frames\n",
      "Loss: 0.0012386281741783023 Episode total reward: 0.0 Predicted Qs: 0.0009048414067365229\n",
      "Actions chosen counts:  {0: 41, 1: 36, 2: 33, 3: 27}\n",
      "----------------\n",
      "Frame:72800 Action 1 Loss: 0.00013 Reward: 0.0 Epsilon: 0.93448\n",
      "Done with episode 406 in 72891 frames\n",
      "Loss: 0.0034562968648970127 Episode total reward: 2.0 Predicted Qs: 0.0008174374816007912\n",
      "Actions chosen counts:  {0: 63, 1: 65, 2: 47, 3: 54}\n",
      "----------------\n",
      "Frame:73000 Action 3 Loss: 8e-05 Reward: 0.0 Epsilon: 0.9343\n",
      "Done with episode 407 in 73045 frames\n",
      "Loss: 0.0005853843758814037 Episode total reward: 1.0 Predicted Qs: 0.0006438589771278203\n",
      "Actions chosen counts:  {0: 39, 1: 43, 2: 27, 3: 45}\n",
      "----------------\n",
      "Done with episode 408 in 73181 frames\n",
      "Loss: 0.00580162787809968 Episode total reward: 0.0 Predicted Qs: 0.0006386606255546212\n",
      "Actions chosen counts:  {0: 34, 1: 39, 2: 37, 3: 26}\n",
      "----------------\n",
      "Frame:73200 Action 2 Loss: 0.00023 Reward: 0.0 Epsilon: 0.93412\n",
      "Done with episode 409 in 73376 frames\n",
      "Loss: 0.014081434346735477 Episode total reward: 1.0 Predicted Qs: 0.0007035925518721342\n",
      "Actions chosen counts:  {0: 51, 1: 46, 2: 52, 3: 46}\n",
      "----------------\n",
      "Frame:73400 Action 0 Loss: 0.00027 Reward: 0.0 Epsilon: 0.93394\n",
      "Done with episode 410 in 73533 frames\n",
      "Loss: 0.00037329827318899333 Episode total reward: 1.0 Predicted Qs: 0.0008472263580188155\n",
      "Actions chosen counts:  {0: 52, 1: 34, 2: 30, 3: 41}\n",
      "----------------\n",
      "Frame:73600 Action 3 Loss: 7e-05 Reward: 0.0 Epsilon: 0.93376\n",
      "Done with episode 411 in 73740 frames\n",
      "Loss: 0.0009911132510751486 Episode total reward: 2.0 Predicted Qs: 0.0006405824096873403\n",
      "Actions chosen counts:  {0: 68, 1: 51, 2: 44, 3: 44}\n",
      "----------------\n",
      "Frame:73800 Action 2 Loss: 3e-05 Reward: 0.0 Epsilon: 0.93358\n",
      "Done with episode 412 in 73875 frames\n",
      "Loss: 0.0008555494132451713 Episode total reward: 0.0 Predicted Qs: 0.0006162645295262337\n",
      "Actions chosen counts:  {0: 42, 1: 39, 2: 31, 3: 23}\n",
      "----------------\n",
      "Frame:74000 Action 0 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9334\n",
      "Done with episode 413 in 74041 frames\n",
      "Loss: 0.002541727852076292 Episode total reward: 0.0 Predicted Qs: 0.0006568222306668758\n",
      "Actions chosen counts:  {0: 48, 1: 27, 2: 53, 3: 38}\n",
      "----------------\n",
      "Done with episode 414 in 74184 frames\n",
      "Loss: 0.003440004074946046 Episode total reward: 0.0 Predicted Qs: 0.0008108426118269563\n",
      "Actions chosen counts:  {0: 41, 1: 27, 2: 33, 3: 42}\n",
      "----------------\n",
      "Frame:74200 Action 3 Loss: 0.00019 Reward: 0.0 Epsilon: 0.9332199999999999\n",
      "Done with episode 415 in 74326 frames\n",
      "Loss: 0.003063896903768182 Episode total reward: 0.0 Predicted Qs: 0.0006159518379718065\n",
      "Actions chosen counts:  {0: 51, 1: 34, 2: 30, 3: 27}\n",
      "----------------\n",
      "Frame:74400 Action 1 Loss: 1e-05 Reward: 0.0 Epsilon: 0.93304\n",
      "Done with episode 416 in 74499 frames\n",
      "Loss: 0.011429477483034134 Episode total reward: 1.0 Predicted Qs: 0.000625642656814307\n",
      "Actions chosen counts:  {0: 42, 1: 41, 2: 40, 3: 50}\n",
      "----------------\n",
      "Frame:74600 Action 1 Loss: 6e-05 Reward: 0.0 Epsilon: 0.93286\n",
      "Done with episode 417 in 74739 frames\n",
      "Loss: 0.0019949786365032196 Episode total reward: 2.0 Predicted Qs: 0.0006394787924364209\n",
      "Actions chosen counts:  {0: 87, 1: 51, 2: 52, 3: 50}\n",
      "----------------\n",
      "Frame:74800 Action 3 Loss: 6e-05 Reward: 0.0 Epsilon: 0.9326800000000001\n",
      "Done with episode 418 in 74900 frames\n",
      "Loss: 0.0021902841981500387 Episode total reward: 1.0 Predicted Qs: 0.000535979401320219\n",
      "Actions chosen counts:  {0: 49, 1: 32, 2: 33, 3: 47}\n",
      "----------------\n",
      "Frame:75000 Action 1 Loss: 6e-05 Reward: 0.0 Epsilon: 0.9325\n",
      "Done with episode 419 in 75088 frames\n",
      "Loss: 0.0007135882042348385 Episode total reward: 1.0 Predicted Qs: 0.00034572783624753356\n",
      "Actions chosen counts:  {0: 62, 1: 45, 2: 43, 3: 38}\n",
      "----------------\n",
      "Frame:75200 Action 3 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9323199999999999\n",
      "Done with episode 420 in 75222 frames\n",
      "Loss: 0.001591392676346004 Episode total reward: 0.0 Predicted Qs: 0.0002523111179471016\n",
      "Actions chosen counts:  {0: 38, 1: 40, 2: 30, 3: 26}\n",
      "----------------\n",
      "Done with episode 421 in 75400 frames\n",
      "Loss: 0.0009457030100747943 Episode total reward: 1.0 Predicted Qs: 0.00026999838883057237\n",
      "Actions chosen counts:  {0: 55, 1: 38, 2: 44, 3: 41}\n",
      "----------------\n",
      "Frame:75400 Action 0 Loss: 3e-05 Reward: 0.0 Epsilon: 0.93214\n",
      "Done with episode 422 in 75582 frames\n",
      "Loss: 0.008070044219493866 Episode total reward: 1.0 Predicted Qs: 0.00044189620530232787\n",
      "Actions chosen counts:  {0: 55, 1: 48, 2: 42, 3: 37}\n",
      "----------------\n",
      "Frame:75600 Action 2 Loss: 7e-05 Reward: 0.0 Epsilon: 0.93196\n",
      "Done with episode 423 in 75713 frames\n",
      "Loss: 0.0010332781821489334 Episode total reward: 0.0 Predicted Qs: 0.00031439901795238256\n",
      "Actions chosen counts:  {0: 33, 1: 40, 2: 32, 3: 26}\n",
      "----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:75800 Action 3 Loss: 0.0001 Reward: 0.0 Epsilon: 0.93178\n",
      "Done with episode 424 in 75885 frames\n",
      "Loss: 0.0009829237824305892 Episode total reward: 1.0 Predicted Qs: 0.00022839108714833856\n",
      "Actions chosen counts:  {0: 53, 1: 35, 2: 40, 3: 44}\n",
      "----------------\n",
      "Frame:76000 Action 0 Loss: 7e-05 Reward: 0.0 Epsilon: 0.9316\n",
      "Done with episode 425 in 76109 frames\n",
      "Loss: 0.0021700384095311165 Episode total reward: 2.0 Predicted Qs: 0.0003226214903406799\n",
      "Actions chosen counts:  {0: 73, 1: 46, 2: 52, 3: 53}\n",
      "----------------\n",
      "Frame:76200 Action 0 Loss: 9e-05 Reward: 0.0 Epsilon: 0.9314199999999999\n",
      "Done with episode 426 in 76235 frames\n",
      "Loss: 0.012390438467264175 Episode total reward: 0.0 Predicted Qs: 0.0002495207590982318\n",
      "Actions chosen counts:  {0: 33, 1: 31, 2: 30, 3: 32}\n",
      "----------------\n",
      "Done with episode 427 in 76394 frames\n",
      "Loss: 0.0005388647550716996 Episode total reward: 1.0 Predicted Qs: 0.00021567713702097535\n",
      "Actions chosen counts:  {0: 44, 1: 44, 2: 33, 3: 38}\n",
      "----------------\n",
      "Frame:76400 Action 1 Loss: 0.00072 Reward: 0.0 Epsilon: 0.93124\n",
      "Done with episode 428 in 76534 frames\n",
      "Loss: 0.0012761970283463597 Episode total reward: 0.0 Predicted Qs: 0.0002321787178516388\n",
      "Actions chosen counts:  {0: 45, 1: 34, 2: 31, 3: 30}\n",
      "----------------\n",
      "Frame:76600 Action 2 Loss: 4e-05 Reward: 0.0 Epsilon: 0.93106\n",
      "Done with episode 429 in 76712 frames\n",
      "Loss: 0.006558932829648256 Episode total reward: 1.0 Predicted Qs: 0.0003279866650700569\n",
      "Actions chosen counts:  {0: 55, 1: 39, 2: 43, 3: 41}\n",
      "----------------\n",
      "Frame:76800 Action 2 Loss: 0.00035 Reward: 0.0 Epsilon: 0.93088\n",
      "Done with episode 430 in 76942 frames\n",
      "Loss: 0.008628328330814838 Episode total reward: 2.0 Predicted Qs: 0.00037501880433410406\n",
      "Actions chosen counts:  {0: 83, 1: 50, 2: 50, 3: 47}\n",
      "----------------\n",
      "Frame:77000 Action 1 Loss: 6e-05 Reward: 0.0 Epsilon: 0.9307000000000001\n",
      "Done with episode 431 in 77120 frames\n",
      "Loss: 0.006432707421481609 Episode total reward: 1.0 Predicted Qs: 0.0003685678238980472\n",
      "Actions chosen counts:  {0: 71, 1: 39, 2: 37, 3: 31}\n",
      "----------------\n",
      "Frame:77200 Action 1 Loss: 0.00012 Reward: 0.0 Epsilon: 0.9305199999999999\n",
      "Done with episode 432 in 77250 frames\n",
      "Loss: 0.006879566702991724 Episode total reward: 0.0 Predicted Qs: 0.00044649449409916997\n",
      "Actions chosen counts:  {0: 30, 1: 30, 2: 32, 3: 38}\n",
      "----------------\n",
      "Frame:77400 Action 3 Loss: 3e-05 Reward: 0.0 Epsilon: 0.93034\n",
      "Done with episode 433 in 77409 frames\n",
      "Loss: 0.0014425109839066863 Episode total reward: 1.0 Predicted Qs: 0.0003033708781003952\n",
      "Actions chosen counts:  {0: 52, 1: 31, 2: 29, 3: 47}\n",
      "----------------\n",
      "Frame:77600 Action 2 Loss: 3e-05 Reward: 0.0 Epsilon: 0.93016\n",
      "Done with episode 434 in 77602 frames\n",
      "Loss: 0.004119387362152338 Episode total reward: 2.0 Predicted Qs: 0.0005986231262795627\n",
      "Actions chosen counts:  {0: 67, 1: 48, 2: 36, 3: 42}\n",
      "----------------\n",
      "Frame:77800 Action 3 Loss: 0.00115 Reward: 0.0 Epsilon: 0.92998\n",
      "Done with episode 435 in 77815 frames\n",
      "Loss: 0.0015310236485674977 Episode total reward: 2.0 Predicted Qs: 0.0006899078143760562\n",
      "Actions chosen counts:  {0: 58, 1: 57, 2: 47, 3: 51}\n",
      "----------------\n",
      "Frame:78000 Action 2 Loss: 0.00021 Reward: 0.0 Epsilon: 0.9298000000000001\n",
      "Done with episode 436 in 78008 frames\n",
      "Loss: 0.007017791271209717 Episode total reward: 2.0 Predicted Qs: 0.00041245727334171534\n",
      "Actions chosen counts:  {0: 61, 1: 43, 2: 42, 3: 47}\n",
      "----------------\n",
      "Done with episode 437 in 78153 frames\n",
      "Loss: 0.004168760497123003 Episode total reward: 0.0 Predicted Qs: 3.622856456786394e-05\n",
      "Actions chosen counts:  {0: 42, 1: 33, 2: 38, 3: 32}\n",
      "----------------\n",
      "Frame:78200 Action 1 Loss: 2e-05 Reward: 0.0 Epsilon: 0.92962\n",
      "Done with episode 438 in 78279 frames\n",
      "Loss: 0.005251696333289146 Episode total reward: 0.0 Predicted Qs: 8.842675015330315e-05\n",
      "Actions chosen counts:  {0: 24, 1: 39, 2: 32, 3: 31}\n",
      "----------------\n",
      "Frame:78400 Action 0 Loss: 4e-05 Reward: 0.0 Epsilon: 0.9294399999999999\n",
      "Done with episode 439 in 78412 frames\n",
      "Loss: 0.002751304768025875 Episode total reward: 0.0 Predicted Qs: 0.0006556681473739445\n",
      "Actions chosen counts:  {0: 44, 1: 35, 2: 27, 3: 27}\n",
      "----------------\n",
      "Frame:78600 Action 2 Loss: 0.00022 Reward: 0.0 Epsilon: 0.92926\n",
      "Done with episode 440 in 78614 frames\n",
      "Loss: 0.0057846130803227425 Episode total reward: 2.0 Predicted Qs: 0.0004775706911459565\n",
      "Actions chosen counts:  {0: 63, 1: 36, 2: 47, 3: 56}\n",
      "----------------\n",
      "Done with episode 441 in 78741 frames\n",
      "Loss: 0.002178118098527193 Episode total reward: 0.0 Predicted Qs: 0.0003520149039104581\n",
      "Actions chosen counts:  {0: 34, 1: 33, 2: 29, 3: 31}\n",
      "----------------\n",
      "Frame:78800 Action 1 Loss: 6e-05 Reward: 0.0 Epsilon: 0.92908\n",
      "Done with episode 442 in 78875 frames\n",
      "Loss: 0.0010063140653073788 Episode total reward: 0.0 Predicted Qs: 0.0002956909593194723\n",
      "Actions chosen counts:  {0: 39, 1: 37, 2: 31, 3: 27}\n",
      "----------------\n",
      "Frame:79000 Action 2 Loss: 4e-05 Reward: 0.0 Epsilon: 0.9289000000000001\n",
      "Done with episode 443 in 79063 frames\n",
      "Loss: 0.0019332446390762925 Episode total reward: 1.0 Predicted Qs: 0.0003019829746335745\n",
      "Actions chosen counts:  {0: 61, 1: 33, 2: 50, 3: 44}\n",
      "----------------\n",
      "Frame:79200 Action 0 Loss: 1e-05 Reward: 0.0 Epsilon: 0.92872\n",
      "Done with episode 444 in 79236 frames\n",
      "Loss: 0.001053452491760254 Episode total reward: 1.0 Predicted Qs: 0.0004307531635276973\n",
      "Actions chosen counts:  {0: 57, 1: 44, 2: 38, 3: 34}\n",
      "----------------\n",
      "Done with episode 445 in 79379 frames\n",
      "Loss: 0.0005012989277020097 Episode total reward: 0.0 Predicted Qs: 0.0004875098238699138\n",
      "Actions chosen counts:  {0: 39, 1: 27, 2: 37, 3: 40}\n",
      "----------------\n",
      "Frame:79400 Action 2 Loss: 6e-05 Reward: 0.0 Epsilon: 0.9285399999999999\n",
      "Done with episode 446 in 79519 frames\n",
      "Loss: 0.0013542290544137359 Episode total reward: 0.0 Predicted Qs: 0.0004676509415730834\n",
      "Actions chosen counts:  {0: 41, 1: 36, 2: 31, 3: 32}\n",
      "----------------\n",
      "Frame:79600 Action 3 Loss: 7e-05 Reward: 0.0 Epsilon: 0.92836\n",
      "Done with episode 447 in 79682 frames\n",
      "Loss: 0.0004980897065252066 Episode total reward: 1.0 Predicted Qs: 0.00046118086902424693\n",
      "Actions chosen counts:  {0: 59, 1: 26, 2: 35, 3: 43}\n",
      "----------------\n",
      "Frame:79800 Action 3 Loss: 4e-05 Reward: 0.0 Epsilon: 0.92818\n",
      "Done with episode 448 in 79811 frames\n",
      "Loss: 0.0005753028090111911 Episode total reward: 0.0 Predicted Qs: 0.0001530537847429514\n",
      "Actions chosen counts:  {0: 39, 1: 25, 2: 33, 3: 32}\n",
      "----------------\n",
      "Frame:80000 Action 2 Loss: 0.00011 Reward: 0.0 Epsilon: 0.928\n",
      "Done with episode 449 in 80043 frames\n",
      "Loss: 0.0006050904048606753 Episode total reward: 2.0 Predicted Qs: 0.00034749292535707355\n",
      "Actions chosen counts:  {0: 75, 1: 61, 2: 56, 3: 40}\n",
      "----------------\n",
      "Done with episode 450 in 80175 frames\n",
      "Loss: 0.0008766298415139318 Episode total reward: 0.0 Predicted Qs: 0.00045683461939916015\n",
      "Actions chosen counts:  {0: 37, 1: 37, 2: 26, 3: 32}\n",
      "----------------\n",
      "Frame:80200 Action 3 Loss: 4e-05 Reward: 0.0 Epsilon: 0.92782\n",
      "Done with episode 451 in 80359 frames\n",
      "Loss: 0.0003337068483233452 Episode total reward: 1.0 Predicted Qs: 0.00044154166243970394\n",
      "Actions chosen counts:  {0: 52, 1: 45, 2: 48, 3: 39}\n",
      "----------------\n",
      "Frame:80400 Action 2 Loss: 3e-05 Reward: 0.0 Epsilon: 0.92764\n",
      "Done with episode 452 in 80572 frames\n",
      "Loss: 0.001089502708055079 Episode total reward: 2.0 Predicted Qs: 0.000288335548248142\n",
      "Actions chosen counts:  {0: 71, 1: 48, 2: 39, 3: 55}\n",
      "----------------\n",
      "Frame:80600 Action 1 Loss: 3e-05 Reward: 0.0 Epsilon: 0.92746\n",
      "Done with episode 453 in 80744 frames\n",
      "Loss: 0.012603326700627804 Episode total reward: 1.0 Predicted Qs: 0.00033925793832167983\n",
      "Actions chosen counts:  {0: 45, 1: 34, 2: 52, 3: 41}\n",
      "----------------\n",
      "Frame:80800 Action 3 Loss: 0.00019 Reward: 0.0 Epsilon: 0.92728\n",
      "Done with episode 454 in 80882 frames\n",
      "Loss: 0.003691526362672448 Episode total reward: 0.0 Predicted Qs: 0.0003250682493671775\n",
      "Actions chosen counts:  {0: 46, 1: 33, 2: 27, 3: 32}\n",
      "----------------\n",
      "Frame:81000 Action 2 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9271\n",
      "Done with episode 455 in 81116 frames\n",
      "Loss: 0.0004537247586995363 Episode total reward: 2.0 Predicted Qs: 0.0001634800573810935\n",
      "Actions chosen counts:  {0: 71, 1: 53, 2: 52, 3: 58}\n",
      "----------------\n",
      "Frame:81200 Action 2 Loss: 4e-05 Reward: 0.0 Epsilon: 0.92692\n",
      "Done with episode 456 in 81354 frames\n",
      "Loss: 0.0011998701374977827 Episode total reward: 3.0 Predicted Qs: 0.00035221787402406335\n",
      "Actions chosen counts:  {0: 78, 1: 57, 2: 33, 3: 70}\n",
      "----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:81400 Action 2 Loss: 3e-05 Reward: 0.0 Epsilon: 0.92674\n",
      "Done with episode 457 in 81497 frames\n",
      "Loss: 0.0006647406844422221 Episode total reward: 0.0 Predicted Qs: 0.0004965394618920982\n",
      "Actions chosen counts:  {0: 49, 1: 27, 2: 35, 3: 32}\n",
      "----------------\n",
      "Frame:81600 Action 2 Loss: 0.0001 Reward: 0.0 Epsilon: 0.9265599999999999\n",
      "Done with episode 458 in 81716 frames\n",
      "Loss: 0.0005809856811538339 Episode total reward: 2.0 Predicted Qs: 0.0005409655859693885\n",
      "Actions chosen counts:  {0: 79, 1: 51, 2: 43, 3: 46}\n",
      "----------------\n",
      "Frame:81800 Action 2 Loss: 0.00025 Reward: 0.0 Epsilon: 0.92638\n",
      "Done with episode 459 in 81924 frames\n",
      "Loss: 0.00852247141301632 Episode total reward: 2.0 Predicted Qs: 0.0005421178648248315\n",
      "Actions chosen counts:  {0: 61, 1: 53, 2: 57, 3: 37}\n",
      "----------------\n",
      "Frame:82000 Action 0 Loss: 4e-05 Reward: 0.0 Epsilon: 0.9262\n",
      "Done with episode 460 in 82093 frames\n",
      "Loss: 0.0005443055415526032 Episode total reward: 1.0 Predicted Qs: 0.0001684302114881575\n",
      "Actions chosen counts:  {0: 48, 1: 42, 2: 36, 3: 43}\n",
      "----------------\n",
      "Frame:82200 Action 2 Loss: 2e-05 Reward: 0.0 Epsilon: 0.92602\n",
      "Done with episode 461 in 82311 frames\n",
      "Loss: 0.005502419546246529 Episode total reward: 2.0 Predicted Qs: 0.000506438547745347\n",
      "Actions chosen counts:  {0: 67, 1: 49, 2: 49, 3: 53}\n",
      "----------------\n",
      "Frame:82400 Action 3 Loss: 1e-05 Reward: 0.0 Epsilon: 0.92584\n",
      "Done with episode 462 in 82542 frames\n",
      "Loss: 0.0016617330256849527 Episode total reward: 2.0 Predicted Qs: 0.00022642273688688874\n",
      "Actions chosen counts:  {0: 63, 1: 53, 2: 62, 3: 53}\n",
      "----------------\n",
      "Frame:82600 Action 0 Loss: 3e-05 Reward: 0.0 Epsilon: 0.92566\n",
      "Done with episode 463 in 82694 frames\n",
      "Loss: 0.004001230467110872 Episode total reward: 0.0 Predicted Qs: 0\n",
      "Actions chosen counts:  {0: 52, 1: 29, 2: 40, 3: 31}\n",
      "----------------\n",
      "Frame:82800 Action 3 Loss: 8e-05 Reward: 0.0 Epsilon: 0.92548\n",
      "Done with episode 464 in 82908 frames\n",
      "Loss: 0.0006574623403139412 Episode total reward: 2.0 Predicted Qs: 0.00028835813282057643\n",
      "Actions chosen counts:  {0: 52, 1: 51, 2: 58, 3: 53}\n",
      "----------------\n",
      "Frame:83000 Action 1 Loss: 1e-05 Reward: 0.0 Epsilon: 0.9253\n",
      "Done with episode 465 in 83054 frames\n",
      "Loss: 0.0007685759337618947 Episode total reward: 0.0 Predicted Qs: 0.00017619668506085873\n",
      "Actions chosen counts:  {0: 47, 1: 25, 2: 40, 3: 34}\n",
      "----------------\n",
      "Done with episode 466 in 83195 frames\n",
      "Loss: 0.0003282936231698841 Episode total reward: 0.0 Predicted Qs: 0.00019564060494303703\n",
      "Actions chosen counts:  {0: 34, 1: 24, 2: 41, 3: 42}\n",
      "----------------\n",
      "Frame:83200 Action 3 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9251199999999999\n",
      "Done with episode 467 in 83373 frames\n",
      "Loss: 0.0008121852297335863 Episode total reward: 1.0 Predicted Qs: 0.00022344995522871614\n",
      "Actions chosen counts:  {0: 58, 1: 40, 2: 43, 3: 37}\n",
      "----------------\n",
      "Frame:83400 Action 3 Loss: 3e-05 Reward: 0.0 Epsilon: 0.92494\n",
      "Done with episode 468 in 83588 frames\n",
      "Loss: 0.0012765413848683238 Episode total reward: 3.0 Predicted Qs: 7.712823571637273e-05\n",
      "Actions chosen counts:  {0: 49, 1: 62, 2: 43, 3: 61}\n",
      "----------------\n",
      "Frame:83600 Action 3 Loss: 3e-05 Reward: 0.0 Epsilon: 0.92476\n",
      "Done with episode 469 in 83729 frames\n",
      "Loss: 0.0003754018689505756 Episode total reward: 0.0 Predicted Qs: 0.00025108217960223556\n",
      "Actions chosen counts:  {0: 40, 1: 34, 2: 38, 3: 29}\n",
      "----------------\n",
      "Frame:83800 Action 2 Loss: 4e-05 Reward: 0.0 Epsilon: 0.92458\n",
      "Done with episode 470 in 83954 frames\n",
      "Loss: 0.0017010150477290154 Episode total reward: 2.0 Predicted Qs: 0.00017872866010293365\n",
      "Actions chosen counts:  {0: 74, 1: 51, 2: 54, 3: 46}\n",
      "----------------\n",
      "Frame:84000 Action 0 Loss: 4e-05 Reward: 0.0 Epsilon: 0.9244\n",
      "Done with episode 471 in 84155 frames\n",
      "Loss: 0.00040691017056815326 Episode total reward: 1.0 Predicted Qs: 0.00023143325233832002\n",
      "Actions chosen counts:  {0: 64, 1: 42, 2: 40, 3: 55}\n",
      "----------------\n",
      "Frame:84200 Action 2 Loss: 5e-05 Reward: 0.0 Epsilon: 0.9242199999999999\n",
      "Done with episode 472 in 84306 frames\n",
      "Loss: 0.0005928564351052046 Episode total reward: 0.0 Predicted Qs: 0.0002757559414021671\n",
      "Actions chosen counts:  {0: 53, 1: 27, 2: 36, 3: 35}\n",
      "----------------\n",
      "Frame:84400 Action 0 Loss: 0.00014 Reward: 0.0 Epsilon: 0.92404\n",
      "Done with episode 473 in 84565 frames\n",
      "Loss: 0.00037205233820714056 Episode total reward: 3.0 Predicted Qs: 3.2613694202154875e-05\n",
      "Actions chosen counts:  {0: 86, 1: 62, 2: 51, 3: 60}\n",
      "----------------\n",
      "Frame:84600 Action 2 Loss: 1e-05 Reward: 0.0 Epsilon: 0.92386\n",
      "Done with episode 474 in 84701 frames\n",
      "Loss: 0.00023204191529657692 Episode total reward: 0.0 Predicted Qs: 0.00033911631908267736\n",
      "Actions chosen counts:  {0: 39, 1: 36, 2: 27, 3: 34}\n",
      "----------------\n",
      "Frame:84800 Action 3 Loss: 1e-05 Reward: 0.0 Epsilon: 0.9236800000000001\n",
      "Done with episode 475 in 84904 frames\n",
      "Loss: 0.00033076584804803133 Episode total reward: 2.0 Predicted Qs: 2.5802815798670053e-05\n",
      "Actions chosen counts:  {0: 63, 1: 49, 2: 47, 3: 44}\n",
      "----------------\n",
      "Frame:85000 Action 2 Loss: 5e-05 Reward: 0.0 Epsilon: 0.9235\n",
      "Done with episode 476 in 85067 frames\n",
      "Loss: 0.0006289659650065005 Episode total reward: 1.0 Predicted Qs: 0.00034079450415447354\n",
      "Actions chosen counts:  {0: 55, 1: 37, 2: 38, 3: 33}\n",
      "----------------\n",
      "Done with episode 477 in 85200 frames\n",
      "Loss: 0.0007688177865929902 Episode total reward: 0.0 Predicted Qs: 4.576647188514471e-05\n",
      "Actions chosen counts:  {0: 54, 1: 28, 2: 27, 3: 24}\n",
      "----------------\n",
      "Frame:85200 Action 0 Loss: 6e-05 Reward: 0.0 Epsilon: 0.9233199999999999\n",
      "Done with episode 478 in 85373 frames\n",
      "Loss: 0.0005850098677910864 Episode total reward: 1.0 Predicted Qs: 0.00021813344210386276\n",
      "Actions chosen counts:  {0: 55, 1: 39, 2: 39, 3: 40}\n",
      "----------------\n",
      "Frame:85400 Action 2 Loss: 0.00022 Reward: 0.0 Epsilon: 0.92314\n",
      "Done with episode 479 in 85536 frames\n",
      "Loss: 0.004376403521746397 Episode total reward: 1.0 Predicted Qs: 0.00048664293717592955\n",
      "Actions chosen counts:  {0: 52, 1: 33, 2: 36, 3: 42}\n",
      "----------------\n",
      "Frame:85600 Action 0 Loss: 7e-05 Reward: 0.0 Epsilon: 0.92296\n",
      "Done with episode 480 in 85669 frames\n",
      "Loss: 0.0016202257247641683 Episode total reward: 0.0 Predicted Qs: 0\n",
      "Actions chosen counts:  {0: 39, 1: 35, 2: 34, 3: 25}\n",
      "----------------\n",
      "Frame:85800 Action 0 Loss: 4e-05 Reward: 0.0 Epsilon: 0.92278\n",
      "Done with episode 481 in 85831 frames\n",
      "Loss: 0.0013781922170892358 Episode total reward: 0.0 Predicted Qs: 0\n",
      "Actions chosen counts:  {0: 63, 1: 29, 2: 41, 3: 29}\n",
      "----------------\n",
      "Frame:86000 Action 3 Loss: 1e-05 Reward: 0.0 Epsilon: 0.9226\n",
      "Done with episode 482 in 86033 frames\n",
      "Loss: 0.0010766017949208617 Episode total reward: 1.0 Predicted Qs: 7.860956247895956e-05\n",
      "Actions chosen counts:  {0: 65, 1: 31, 2: 57, 3: 49}\n",
      "----------------\n",
      "Frame:86200 Action 0 Loss: 1e-05 Reward: 0.0 Epsilon: 0.9224199999999999\n",
      "Done with episode 483 in 86271 frames\n",
      "Loss: 0.0005554615636356175 Episode total reward: 3.0 Predicted Qs: 0.0005108858458697796\n",
      "Actions chosen counts:  {0: 80, 1: 41, 2: 50, 3: 67}\n",
      "----------------\n",
      "Frame:86400 Action 2 Loss: 2e-05 Reward: 0.0 Epsilon: 0.92224\n",
      "Done with episode 484 in 86487 frames\n",
      "Loss: 0.0006453617243096232 Episode total reward: 2.0 Predicted Qs: 0.00021409301552921534\n",
      "Actions chosen counts:  {0: 75, 1: 45, 2: 53, 3: 43}\n",
      "----------------\n",
      "Frame:86600 Action 1 Loss: 7e-05 Reward: 0.0 Epsilon: 0.92206\n",
      "Done with episode 485 in 86679 frames\n",
      "Loss: 0.006588758435100317 Episode total reward: 2.0 Predicted Qs: 0.0011978463735431433\n",
      "Actions chosen counts:  {0: 58, 1: 60, 2: 30, 3: 44}\n",
      "----------------\n",
      "Frame:86800 Action 0 Loss: 8e-05 Reward: 0.0 Epsilon: 0.92188\n",
      "Done with episode 486 in 86819 frames\n",
      "Loss: 0.0005373214953579009 Episode total reward: 0.0 Predicted Qs: 0.00019869202515110373\n",
      "Actions chosen counts:  {0: 39, 1: 34, 2: 41, 3: 26}\n",
      "----------------\n",
      "Done with episode 487 in 86957 frames\n",
      "Loss: 0.0003113181737717241 Episode total reward: 0.0 Predicted Qs: 0\n",
      "Actions chosen counts:  {0: 51, 1: 30, 2: 29, 3: 28}\n",
      "----------------\n",
      "Frame:87000 Action 0 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9217000000000001\n",
      "Done with episode 488 in 87121 frames\n",
      "Loss: 0.00043519408791325986 Episode total reward: 1.0 Predicted Qs: 0.0001900342176668346\n",
      "Actions chosen counts:  {0: 52, 1: 35, 2: 34, 3: 43}\n",
      "----------------\n",
      "Frame:87200 Action 0 Loss: 4e-05 Reward: 0.0 Epsilon: 0.9215199999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with episode 489 in 87367 frames\n",
      "Loss: 0.004699732642620802 Episode total reward: 3.0 Predicted Qs: 0.0006232528248801827\n",
      "Actions chosen counts:  {0: 73, 1: 66, 2: 53, 3: 54}\n",
      "----------------\n",
      "Frame:87400 Action 0 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9213399999999999\n",
      "Done with episode 490 in 87568 frames\n",
      "Loss: 0.00020033000328112394 Episode total reward: 1.0 Predicted Qs: 0.0005374168395064771\n",
      "Actions chosen counts:  {0: 74, 1: 37, 2: 41, 3: 49}\n",
      "----------------\n",
      "Frame:87600 Action 2 Loss: 3e-05 Reward: 0.0 Epsilon: 0.92116\n",
      "Done with episode 491 in 87777 frames\n",
      "Loss: 0.002001119079068303 Episode total reward: 2.0 Predicted Qs: 0.0006841832655481994\n",
      "Actions chosen counts:  {0: 77, 1: 42, 2: 53, 3: 37}\n",
      "----------------\n",
      "Frame:87800 Action 2 Loss: 3e-05 Reward: 0.0 Epsilon: 0.92098\n",
      "Done with episode 492 in 87994 frames\n",
      "Loss: 0.0007833285490050912 Episode total reward: 2.0 Predicted Qs: 0.0003944049240089953\n",
      "Actions chosen counts:  {0: 65, 1: 56, 2: 51, 3: 45}\n",
      "----------------\n",
      "Frame:88000 Action 3 Loss: 5e-05 Reward: 0.0 Epsilon: 0.9208000000000001\n",
      "Done with episode 493 in 88196 frames\n",
      "Loss: 0.004879679065197706 Episode total reward: 1.0 Predicted Qs: 0.0005119391717016697\n",
      "Actions chosen counts:  {0: 59, 1: 44, 2: 44, 3: 55}\n",
      "----------------\n",
      "Frame:88200 Action 0 Loss: 2e-05 Reward: 0.0 Epsilon: 0.92062\n",
      "Frame:88400 Action 3 Loss: 1e-05 Reward: 0.0 Epsilon: 0.9204399999999999\n",
      "Done with episode 494 in 88432 frames\n",
      "Loss: 0.0006353580974973738 Episode total reward: 2.0 Predicted Qs: 0.0006769633037038147\n",
      "Actions chosen counts:  {0: 72, 1: 59, 2: 52, 3: 53}\n",
      "----------------\n",
      "Done with episode 495 in 88565 frames\n",
      "Loss: 0.003175631631165743 Episode total reward: 0.0 Predicted Qs: 0.0004128481959924102\n",
      "Actions chosen counts:  {0: 51, 1: 27, 2: 24, 3: 31}\n",
      "----------------\n",
      "Frame:88600 Action 2 Loss: 9e-05 Reward: 0.0 Epsilon: 0.92026\n",
      "Done with episode 496 in 88792 frames\n",
      "Loss: 0.001151682692579925 Episode total reward: 3.0 Predicted Qs: 0.0007940555224195123\n",
      "Actions chosen counts:  {0: 70, 1: 50, 2: 53, 3: 54}\n",
      "----------------\n",
      "Frame:88800 Action 0 Loss: 2e-05 Reward: 0.0 Epsilon: 0.92008\n",
      "Done with episode 497 in 88962 frames\n",
      "Loss: 0.0007993683102540672 Episode total reward: 1.0 Predicted Qs: 0.0006171879940666258\n",
      "Actions chosen counts:  {0: 51, 1: 44, 2: 34, 3: 41}\n",
      "----------------\n",
      "Frame:89000 Action 3 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9199\n",
      "Done with episode 498 in 89124 frames\n",
      "Loss: 0.0013191868783906102 Episode total reward: 1.0 Predicted Qs: 0.0006435778923332691\n",
      "Actions chosen counts:  {0: 49, 1: 38, 2: 35, 3: 40}\n",
      "----------------\n",
      "Frame:89200 Action 1 Loss: 8e-05 Reward: 0.0 Epsilon: 0.9197200000000001\n",
      "Done with episode 499 in 89337 frames\n",
      "Loss: 0.019495733082294464 Episode total reward: 2.0 Predicted Qs: 0.000770852027926594\n",
      "Actions chosen counts:  {0: 63, 1: 47, 2: 40, 3: 63}\n",
      "----------------\n",
      "Frame:89400 Action 0 Loss: 0.00012 Reward: 0.0 Epsilon: 0.9195399999999999\n",
      "Done with episode 500 in 89535 frames\n",
      "Loss: 0.001661052810959518 Episode total reward: 2.0 Predicted Qs: 0.0005199996521696448\n",
      "Actions chosen counts:  {0: 70, 1: 38, 2: 44, 3: 46}\n",
      "----------------\n",
      "Frame:89600 Action 2 Loss: 4e-05 Reward: 0.0 Epsilon: 0.91936\n",
      "Done with episode 501 in 89730 frames\n",
      "Loss: 0.0118844760581851 Episode total reward: 1.0 Predicted Qs: 0.00036531308433040977\n",
      "Actions chosen counts:  {0: 69, 1: 42, 2: 48, 3: 36}\n",
      "----------------\n",
      "Frame:89800 Action 0 Loss: 3e-05 Reward: 0.0 Epsilon: 0.91918\n",
      "Done with episode 502 in 89916 frames\n",
      "Loss: 0.000270972988801077 Episode total reward: 1.0 Predicted Qs: 0.00038262177258729935\n",
      "Actions chosen counts:  {0: 56, 1: 35, 2: 44, 3: 51}\n",
      "----------------\n",
      "Frame:90000 Action 3 Loss: 3e-05 Reward: 0.0 Epsilon: 0.919\n",
      "Done with episode 503 in 90082 frames\n",
      "Loss: 0.0004836375010199845 Episode total reward: 0.0 Predicted Qs: 0.00020861515076830983\n",
      "Actions chosen counts:  {0: 58, 1: 28, 2: 42, 3: 38}\n",
      "----------------\n",
      "Frame:90200 Action 0 Loss: 6e-05 Reward: 0.0 Epsilon: 0.9188200000000001\n",
      "Done with episode 504 in 90338 frames\n",
      "Loss: 0.0006186440004967153 Episode total reward: 3.0 Predicted Qs: 0.0005684095085598528\n",
      "Actions chosen counts:  {0: 85, 1: 56, 2: 71, 3: 44}\n",
      "----------------\n",
      "Frame:90400 Action 0 Loss: 3e-05 Reward: 0.0 Epsilon: 0.91864\n",
      "Frame:90600 Action 0 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9184599999999999\n",
      "Done with episode 505 in 90616 frames\n",
      "Loss: 0.0009170932462438941 Episode total reward: 3.0 Predicted Qs: 0.0007375500863417983\n",
      "Actions chosen counts:  {0: 97, 1: 43, 2: 72, 3: 66}\n",
      "----------------\n",
      "Done with episode 506 in 90745 frames\n",
      "Loss: 0.0004630266921594739 Episode total reward: 0.0 Predicted Qs: 0.00047817715676501393\n",
      "Actions chosen counts:  {0: 43, 1: 34, 2: 29, 3: 23}\n",
      "----------------\n",
      "Frame:90800 Action 1 Loss: 3e-05 Reward: 0.0 Epsilon: 0.91828\n",
      "Done with episode 507 in 90899 frames\n",
      "Loss: 0.00045356154441833496 Episode total reward: 0.0 Predicted Qs: 0.0004951859591528773\n",
      "Actions chosen counts:  {0: 55, 1: 32, 2: 40, 3: 27}\n",
      "----------------\n",
      "Frame:91000 Action 0 Loss: 2e-05 Reward: 0.0 Epsilon: 0.9181\n",
      "Done with episode 508 in 91044 frames\n",
      "Loss: 0.0006776333902962506 Episode total reward: 0.0 Predicted Qs: 0.0005917164380662143\n",
      "Actions chosen counts:  {0: 48, 1: 44, 2: 29, 3: 24}\n",
      "----------------\n",
      "Frame:91200 Action 3 Loss: 0.00016 Reward: 0.0 Epsilon: 0.9179200000000001\n",
      "Done with episode 509 in 91217 frames\n",
      "Loss: 0.0008918477687984705 Episode total reward: 1.0 Predicted Qs: 0.0003933800617232919\n",
      "Actions chosen counts:  {0: 53, 1: 37, 2: 38, 3: 45}\n",
      "----------------\n",
      "Done with episode 510 in 91367 frames\n",
      "Loss: 0.0001874969166237861 Episode total reward: 0.0 Predicted Qs: 0.000434913847129792\n",
      "Actions chosen counts:  {0: 57, 1: 25, 2: 37, 3: 31}\n",
      "----------------\n",
      "Frame:91400 Action 0 Loss: 1e-05 Reward: 0.0 Epsilon: 0.91774\n"
     ]
    }
   ],
   "source": [
    "# main training loop\n",
    "for i in range(EPISODES):\n",
    "    curr_state = env.reset()\n",
    "    curr_state = np.asarray(curr_state) #convert to np array\n",
    "    loss_val = 0\n",
    "    reward_val = 0\n",
    "    pred_q_val = 0\n",
    "    # keep track of actions chosen during episode\n",
    "    action_count = {i:0 for i in range(env.action_space.n)}\n",
    "    \n",
    "    while True:\n",
    "        # decay over the first million frames then stay at 0.1\n",
    "        decay = (DECAY_FRAMES - frames)/DECAY_FRAMES if frames < DECAY_FRAMES else 0\n",
    "        epsilon = END_EPSILON + decay*(START_EPSILON-END_EPSILON)\n",
    "        action = choose_action(model, curr_state, device, epsilon=epsilon)\n",
    "        # execute action\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        observation = np.asarray(observation) #convert to np array\n",
    "        # save observation\n",
    "        replay_memory.push(curr_state, action, reward, observation, done)\n",
    "        \n",
    "        # update curr_state\n",
    "        curr_state = observation\n",
    "        \n",
    "        # sample and compute loss\n",
    "        loss, pred_q = loss_fn(model, replay_memory, BATCH_SIZE, DISCOUNT, target_model=target_model, device=device)\n",
    "        \n",
    "        # zero out gradient before backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if frames%200==0:\n",
    "            # print loss and reward every 200 frames\n",
    "            print(f\"Frame:{frames} Action {action} Loss: {round(loss.item(),5)} Reward: {reward} Epsilon: {epsilon}\")\n",
    "        \n",
    "        # update target model if available\n",
    "        if USE_TARGET_MODEL:\n",
    "            if frames%UPDATE_TARGET:\n",
    "                target_model.load_state_dict(model.state_dict())\n",
    "        \n",
    "        # add frames count for epsilon decay\n",
    "        frames+=1\n",
    "        \n",
    "        # update total reward of episode\n",
    "        reward_val += reward\n",
    "        \n",
    "        # update loss as the max loss during episode\n",
    "        loss_val = max(loss.item(), loss_val)\n",
    "        \n",
    "        # update predicted q in training\n",
    "        pred_q_val = max(pred_q.mean().item(), pred_q_val)\n",
    "        \n",
    "        # update action count\n",
    "        action_count[action]+=1\n",
    "        \n",
    "        if done: \n",
    "#             loss_val = loss.item()\n",
    "            count+=1\n",
    "            # finish an episode\n",
    "            break\n",
    "    print(f\"Done with episode {count} in {frames} frames\")\n",
    "    print(f\"Loss: {loss_val} Episode total reward: {reward_val} Predicted Qs: {pred_q_val}\")\n",
    "    print(\"Actions chosen counts: \", action_count)\n",
    "    print(\"----------------\")\n",
    "    if count%SAVE_FREQ==0:\n",
    "        episodes.append(count)\n",
    "        losses.append(loss_val)\n",
    "        rewards.append(reward_val)\n",
    "        pred_qs.append(pred_q_val)\n",
    "        \n",
    "print(\"FINISH TRAINING PROCESS\")\n",
    "print(f\"Finish in {frames} frames, Highest reward {max(rewards)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot reward and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x339f4f400>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episodes, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x3811dcdc0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episodes, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dqn_model_sgd_1100000.pt', 'wb') as f:\n",
    "    torch.save(model.state_dict(), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
